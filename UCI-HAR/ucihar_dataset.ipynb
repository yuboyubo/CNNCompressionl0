{"cells":[{"cell_type":"markdown","metadata":{"id":"JD_16kJ_BWqg"},"source":["## Connect Google Drive and GPU\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4893,"status":"ok","timestamp":1639680418001,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"},"user_tz":300},"id":"neFdxlyCA4Wt","outputId":"ea2986d5-75bc-4b67-e6a1-63a4e67a4996"},"outputs":[{"output_type":"stream","name":"stdout","text":["Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n","Mounted at /content/drive\n","Fri Dec 17 06:01:37 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P0    40W / 250W |   1191MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["%reset\n","\n","# connect google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# connect colab gpu\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"RE7AbBJmBjJo"},"source":["## Import Needed Libraries, Paramaters and Functions"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":153,"status":"ok","timestamp":1639680420553,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"},"user_tz":300},"id":"0HZHzTwBs4Nl"},"outputs":[],"source":["import sys\n","import time\n","import os.path\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.nn.utils import prune\n","import torchvision\n","import matplotlib.pyplot as plt\n","from torch.utils.mobile_optimizer import optimize_for_mobile\n","from scipy import stats\n","from sklearn.utils import shuffle\n","\n","SEED = 10\n","WINDOW_SIZE = 128\n","FEATURE_SIZE = 9\n","LABEL_SIZE = 6\n","BATCH_SIZE = 32\n","PATH = '/content/drive/MyDrive/CNNPaper'\n","TRAIN_LOADER_PATH = PATH + '/model/final/loader/train_loader'\n","VALID_LOAER_PATH = PATH + '/model/final/loader/valid_loader'\n","TEST_LOADER_PATH = PATH + '/model/final/loader/test_loader'\n","TRAIN_DATA_DIR_PATH = PATH + '/data/UCIHAR/train/'\n","TEST_DATA_DIR_PATH = PATH + '/data/UCIHAR/test/'\n","TRAIN_DATA_PATH = PATH + '/data/UCIHAR/train_data.cvs'\n","TEST_DATA_PATH = PATH + '/data/UCIHAR/test_data.cvs'"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":530,"status":"ok","timestamp":1639680430672,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"},"user_tz":300},"id":"RtMUnj56BjlX"},"outputs":[],"source":["def read_data(file_path, TYPE):\n","  \"\"\"\n","    Read data from file_path\n","    Paramater:\n","      file_path: str\n","    Return:\n","      a DataFrame with the data and labels \n","  \"\"\"\n","  if os.path.isfile(TRAIN_DATA_PATH) and TYPE == 'train':\n","    print(\"Start reading data ...\")\n","    df = pd.read_csv(TRAIN_DATA_PATH)\n","    print(\"Finish reading data ...\")\n","  elif os.path.isfile(TEST_DATA_PATH) and TYPE == 'test':\n","    print(\"Start reading data ...\")\n","    df = pd.read_csv(TEST_DATA_PATH)\n","    print(\"Finish reading data ...\")\n","  else:\n","    print(\"Start reading data ...\")\n","    x_accel = pd.read_csv(file_path + 'Inertial Signals/body_acc_x_'+TYPE+'.txt', header=None, names=['x-accel'])\n","    y_accel = pd.read_csv(file_path + 'Inertial Signals/body_acc_y_'+TYPE+'.txt', header=None, names=['y-accel'])\n","    z_accel = pd.read_csv(file_path + 'Inertial Signals/body_acc_z_'+TYPE+'.txt', header=None, names=['z-accel'])\n","    x_gyro = pd.read_csv(file_path + 'Inertial Signals/body_gyro_x_'+TYPE+'.txt', header=None, names=['x-gyro'])\n","    y_gyro = pd.read_csv(file_path + 'Inertial Signals/body_gyro_y_'+TYPE+'.txt', header=None, names=['y-gyro'])\n","    z_gyro = pd.read_csv(file_path + 'Inertial Signals/body_gyro_z_'+TYPE+'.txt', header=None, names=['z-gyro'])\n","    x_gyro_total = pd.read_csv(file_path + 'Inertial Signals/total_acc_x_'+TYPE+'.txt', header=None, names=['total-x-gyro'])\n","    y_gyro_total = pd.read_csv(file_path + 'Inertial Signals/total_acc_y_'+TYPE+'.txt', header=None, names=['total-y-gyro'])\n","    z_gyro_total = pd.read_csv(file_path + 'Inertial Signals/total_acc_z_'+TYPE+'.txt', header=None, names=['total-z-gyro'])\n","    activity = pd.read_csv(file_path + 'y_'+TYPE+'.txt', header=None, names=['activity'])\n","    length = len(x_accel)\n","    df = pd.DataFrame(columns=['user', 'activity', 'timestamp', 'x-accel', 'y-accel', 'z-accel', 'total-x-gyro', 'total-y-gyro', 'total-z-gyro'])\n","    \n","    for i in range(length):\n","      x_acc_data = x_accel['x-accel'][i].split()\n","      y_acc_data = y_accel['y-accel'][i].split()\n","      z_acc_data = z_accel['z-accel'][i].split()\n","      x_gyro_data = x_gyro['x-gyro'][i].split()\n","      y_gyro_data = y_gyro['y-gyro'][i].split()\n","      z_gyro_data = z_gyro['z-gyro'][i].split()\n","      total_gyro_x_data = x_gyro_total['total-x-gyro'][i].split()\n","      total_gyro_y_data = y_gyro_total['total-y-gyro'][i].split()\n","      total_gyro_z_data = z_gyro_total['total-z-gyro'][i].split()\n","      activity_data = activity['activity'][i]\n","      print(\"index \" + str(i))\n","      size = len(x_acc_data)\n","      for j in range(size):\n","        df = df.append({'user': i, 'activity': activity_data, 'timestamp': j, \n","                                'x-accel': float(x_acc_data[j]),\n","                                'y-accel': float(y_acc_data[j]),\n","                                'z-accel': float(z_acc_data[j]),\n","                                'x-gyro': float(x_gyro_data[j]),\n","                                'y-gyro': float(y_gyro_data[j]),\n","                                'z-gyro': float(z_gyro_data[j]),\n","                                'total-x-gyro': float(total_gyro_x_data[j]),\n","                                'total-y-gyro': float(total_gyro_y_data[j]),\n","                                'total-z-gyro': float(total_gyro_z_data[j])}, ignore_index=True)\n","    print(\"Finish reading data ...\")\n","    if TYPE == 'train':\n","      df.to_csv('train_data.cvs', index=False)\n","    else:\n","      df.to_csv('test_data.cvs', index=False)\n","  return df\n","\n","def feature_normalize(data):\n","  \"\"\"\n","    Normalize the feature data\n","    Paramater:\n","      data: a list of floats\n","    Return:\n","      a list of floats with normalized data\n","  \"\"\"\n","  mu = np.mean(data, axis=0)\n","  sigma = np.std(data, axis=0)\n","  return (data - mu) / sigma\n","\n","def dataset_normalize(dataset):\n","  \"\"\"\n","    Normalize the whole dataset\n","    Paramater:\n","      dataset: a DataFrame with the data and labels \n","    Return:\n","      a DataFrame with the normalized data and labels \n","  \"\"\"\n","  dataset.dropna(axis=0, how='any', inplace=True)\n","  print(\"Normalizing x-accel ...\")\n","  dataset['x-accel'] = feature_normalize(dataset['x-accel'])\n","  print(\"Normalizing y-accel ...\")\n","  dataset['y-accel'] = feature_normalize(dataset['y-accel'])\n","  print(\"Normalizing z-accel ...\")\n","  dataset['z-accel'] = feature_normalize(dataset['z-accel'])\n","  print(\"Normalizing x-gyro ...\")\n","  dataset['x-gyro'] = feature_normalize(dataset['x-gyro'])\n","  print(\"Normalizing y-gyro ...\")\n","  dataset['y-gyro'] = feature_normalize(dataset['y-gyro'])\n","  print(\"Normalizing z-gyro ...\")\n","  dataset['z-gyro'] = feature_normalize(dataset['z-gyro'])\n","  print(\"Normalizing total-x-gyro ...\")\n","  dataset['total-x-gyro'] = feature_normalize(dataset['total-x-gyro'])\n","  print(\"Normalizing total-y-gyro ...\")\n","  dataset['total-x-gyro'] = feature_normalize(dataset['total-x-gyro'])\n","  print(\"Normalizing total-z-gyro ...\")\n","  dataset['total-x-gyro'] = feature_normalize(dataset['total-x-gyro'])\n","  return dataset\n","\n","def dataset_segmentation(data):\n","  \"\"\"\n","    Dataset segmentation according the window size\n","    Paramater:\n","      data: a list of floats\n","    Return:\n","      segments and labels \n","  \"\"\"\n","  print(\"Start segmentation with window size: \", WINDOW_SIZE)\n","  segments = np.empty((0, WINDOW_SIZE, FEATURE_SIZE))\n","  labels = np.empty((0))\n","  size = data['timestamp'].count()\n","  for start in range(0, size, WINDOW_SIZE):\n","      x1 = data[\"x-accel\"][start:start+WINDOW_SIZE]\n","      y1 = data[\"y-accel\"][start:start+WINDOW_SIZE]\n","      z1 = data[\"z-accel\"][start:start+WINDOW_SIZE]\n","      x2 = data[\"x-gyro\"][start:start+WINDOW_SIZE]\n","      y2 = data[\"y-gyro\"][start:start+WINDOW_SIZE]\n","      z2 = data[\"z-gyro\"][start:start+WINDOW_SIZE]\n","      x3 = data[\"total-x-gyro\"][start:start+WINDOW_SIZE]\n","      y3 = data[\"total-y-gyro\"][start:start+WINDOW_SIZE]\n","      z3 = data[\"total-z-gyro\"][start:start+WINDOW_SIZE]\n","      if len(data[\"timestamp\"][start:start+WINDOW_SIZE]) == WINDOW_SIZE:\n","        segments = np.vstack([segments, np.dstack([x1,y1,z1,x2,y2,z2,x3,y3,z3])])\n","        labels = np.append(labels, stats.mode(data[\"activity\"][start:start+WINDOW_SIZE])[0][0])\n","  labels = np.asarray(pd.get_dummies(labels), dtype = np.int8)\n","  segments = segments.reshape(len(segments), FEATURE_SIZE, WINDOW_SIZE)\n","  print(\"Finish segmentation ...\")\n","  return segments, labels\n","\n","def train_valid_test_split(segments, classes, test_x, test_y, k_fold):\n","  \"\"\"\n","    Split train, valid and test datase\n","    Paramater:\n","      segments: a list of input data\n","      classes: a list of classes data\n","      k: k fold cross validation\n","    Return:\n","      segments and labels \n","  \"\"\"\n","  print(\"Start dataset split... \")\n","  seg_len = len(segments)\n","  idx_val = [0, int(seg_len/5*1), int(seg_len/5*2), int(seg_len/5*3), int(seg_len/5*4), seg_len]\n","  train_range1 = range(0, idx_val[k_fold])\n","  valid_range = range(idx_val[k_fold], idx_val[k_fold+1])\n","  train_range2 = range(idx_val[k_fold+1], seg_len)\n","\n","  train_x = np.concatenate((segments[train_range1], segments[train_range2]), axis=0)\n","  train_y = np.concatenate((classes[train_range1], classes[train_range2]), axis=0)\n","  valid_x = segments[valid_range]\n","  valid_y = classes[valid_range]\n","\n","  # get train data\n","  train_data = []\n","  for i in range(len(train_x)):\n","    train_data.append([train_x[i], train_y[i]])\n","  \n","  # get valid data\n","  valid_data = []\n","  for i in range(len(valid_x)):\n","    valid_data.append([valid_x[i], valid_y[i]])\n","  \n","  # get test data\n","  test_data = []\n","  for i in range(len(test_x)):\n","    test_data.append([test_x[i], test_y[i]])\n","  print(len(train_data))\n","  print(len(valid_data))\n","  print(len(test_data))\n","\n","  # generate DataLoader for each dataset\n","  trainloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n","  validloader = torch.utils.data.DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE)\n","  testloader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE)\n","  \n","  print(\"Finish dataset split... \")\n","  return trainloader, validloader, testloader\n"]},{"cell_type":"markdown","metadata":{"id":"ZBGhSZcP1DwW"},"source":["## Load and Save Train, Test, Valid Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sEpJxsFGtlxM"},"outputs":[],"source":["train_dataset = dataset_normalize(read_data(TRAIN_DATA_DIR_PATH, 'train'))\n","test_dataset = dataset_normalize(read_data(TEST_DATA_DIR_PATH, 'test'))\n","segments, classes = dataset_segmentation(train_dataset)\n","test_x, test_y = dataset_segmentation(test_dataset)\n","np.random.seed(SEED)\n","total_x, total_y = shuffle(segments, classes)\n","print(len(test_x))\n","print(len(test_y))\n","print(len(total_x))\n","print(len(total_y))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfzoKAPptmBU"},"outputs":[],"source":["cross_valid_range = 5\n","\n","for k in range(cross_valid_range):\n","  print(\"Start spliting for k = \" + str(k))\n","  trainloader, validloader, testloader = train_valid_test_split(total_x, total_y, test_x, test_y, k)\n","  CROSS_TRAIN_LOADER_PATH = TRAIN_LOADER_PATH + str(k) + '.pkl'\n","  CROSS_VALID_LOADER_PATH = VALID_LOAER_PATH + str(k) + '.pkl'\n","  CROSS_TEST_LOADER_PATH = TEST_LOADER_PATH + str(k) + '.pkl'\n","  torch.save(trainloader, CROSS_TRAIN_LOADER_PATH)\n","  torch.save(validloader, CROSS_VALID_LOADER_PATH)\n","  torch.save(testloader, CROSS_TEST_LOADER_PATH)\n","  print(\"Finish data loading...\")"]},{"cell_type":"markdown","metadata":{"id":"ggHEAvHi1Hib"},"source":["## Load CNN Model and Other Helper Functions\n"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":1622,"status":"ok","timestamp":1639706039108,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"},"user_tz":300},"id":"rd1t0tSTvTuA"},"outputs":[],"source":["KERNAL_SIZE = 5\n","LEARNING_RATE = 0.00015\n","NODE_SIZE = 128\n","\n","k = 4 # modify this number for k-fold cross validation\n","\n","CROSS_TRAIN_LOADER_PATH = TRAIN_LOADER_PATH + str(k) + '.pkl'\n","CROSS_VALID_LOADER_PATH = VALID_LOAER_PATH + str(k) + '.pkl'\n","CROSS_TEST_LOADER_PATH = TEST_LOADER_PATH + str(k) + '.pkl'\n","trainloader = torch.load(CROSS_TRAIN_LOADER_PATH)\n","validloader = torch.load(CROSS_VALID_LOADER_PATH)\n","testloader = torch.load(CROSS_TEST_LOADER_PATH)\n","\n","class CNN(nn.Module):\n","  def __init__(self):\n","    super(CNN, self).__init__()\n","\n","    # Convolutional Layers\n","    self.features = nn.Sequential(\n","      nn.Conv1d(FEATURE_SIZE, NODE_SIZE, kernel_size=KERNAL_SIZE, bias=False),\n","      nn.ReLU(),\n","      nn.Conv1d(NODE_SIZE, NODE_SIZE, kernel_size=KERNAL_SIZE, bias=False),\n","      nn.ReLU(),\n","      nn.Conv1d(NODE_SIZE, NODE_SIZE, kernel_size=KERNAL_SIZE, bias=False),\n","      nn.ReLU(),\n","      nn.Conv1d(NODE_SIZE, NODE_SIZE, kernel_size=KERNAL_SIZE, bias=False),\n","      nn.ReLU(),\n","      nn.Conv1d(NODE_SIZE, NODE_SIZE, kernel_size=KERNAL_SIZE, bias=False),\n","      nn.ReLU(),\n","    )\n","  \n","    self.fc1 = nn.Linear(NODE_SIZE*(WINDOW_SIZE-5*(KERNAL_SIZE-1)), 100)\n","    self.fc2 = nn.Linear(100, LABEL_SIZE)\n","    self.max = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = self.features(x)\n","    x = x.view(x.shape[0], -1)\n","    x = F.relu(self.fc1(x))\n","    x = self.fc2(x)\n","    x = self.max(x)\n","    return x\n","\n","def train_save_CNN_model(TYPE, EPOCH_SIZE):\n","  # manually set random seed\n","  torch.backends.cudnn.deterministic = True\n","  torch.manual_seed(SEED)\n","\n","  # set gpu device\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  net = CNN().double().to(device)\n","\n","  # pick the criterion and optimizer\n","  criterion = nn.MultiLabelSoftMarginLoss()\n","  optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n","\n","  print(\"Learning rate %.5f, batch size %d, node size %d, kernal size %d\" % (LEARNING_RATE, BATCH_SIZE, NODE_SIZE, KERNAL_SIZE))\n","\n","  # initialization\n","  train_acc_list = []\n","  val_acc_list = []\n","  test_acc_list = []\n","  accuray = 0\n","\n","  # start to train with epoches\n","  for epoch in range(EPOCH_SIZE):\n","    running_loss = 0.0\n","    train_total = 0\n","    train_correct = 0\n","    valid_total = 0\n","    valid_correct = 0\n","    test_total = 0\n","    test_correct = 0\n","\n","    # for the training dataset\n","    for i, data in enumerate(trainloader, 0):\n","      inputs, labels = data\n","      inputs, labels = inputs.cuda(0), labels.cuda(0)\n","      optimizer.zero_grad()\n","      outputs = net(inputs)\n","      train_total += labels.size(0)\n","      train_correct += (torch.max(outputs, 1)[1] == torch.max(labels, 1)[1]).sum().item()\n","      loss = criterion(outputs, labels)\n","      if TYPE == 'l0_norm':\n","        # add group lasso regularization\n","        lgl = 1e-10\n","        cnt = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            cnt = cnt + param.detach().nonzero().size(0)\n","            #cnt = cnt + len(param.detach()[param.detach() > 1e-2]) + len(param.detach()[param.detach() < -1e-2])\n","        loss = loss + lgl * cnt\n","      elif TYPE == 'l1_norm':\n","        # add group lasso regularization\n","        lgl = 1e-8\n","        regularization = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            regularization = regularization + torch.norm(param, 1)\n","        loss = loss + lgl * regularization\n","      elif TYPE == 'l2_norm':\n","        lgl = 1e-8\n","        regularization = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            regularization = regularization + torch.norm(param)\n","        loss = loss + lgl * regularization\n","      elif TYPE == 'group_lasso':\n","        # add group lasso regularization\n","        lgl = 1e-8\n","        regularization = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            for i in range(param.shape[0]):\n","              regularization = regularization + torch.norm(param[i,:,:])\n","        loss = loss + lgl * regularization\n","      elif TYPE == 'l1_group_lasso':\n","        lgl = 1e-8\n","        alpha = 0.5\n","        group_lasso_regularization = torch.tensor([0]).cuda(0)\n","        lasso_regularization = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            for i in range(param.shape[0]):\n","              group_lasso_regularization = group_lasso_regularization + torch.norm(param[i,:,:])\n","            lasso_regularization = lasso_regularization + torch.norm(param, 1)\n","        loss = loss + (1-alpha) * lgl * group_lasso_regularization + alpha * lgl * lasso_regularization\n","      elif TYPE == 'l0_group_lasso':\n","        #lgl = 0.000001\n","        #alpha = 0.90\n","        l0 = 1e-12\n","        lg = 0.4*1e-10\n","        cnt = torch.tensor([0]).cuda(0)\n","        group_lasso_regularization = torch.tensor([0]).cuda(0)\n","        lasso_regularization = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            for i in range(param.shape[0]):\n","              group_lasso_regularization = group_lasso_regularization + torch.norm(param[i,:,:])\n","            cnt += param.detach().nonzero().size(0)\n","            #cnt = cnt + len(param.detach()[param.detach() > 2*1e-2]) + len(param.detach()[param.detach() < 2*-1e-2])\n","            #lasso_regularization = lasso_regularization + torch.norm(param, 0)\n","        loss = loss + lg * group_lasso_regularization + l0 * cnt\n","        #loss = loss + (1-alpha) * lgl * group_lasso_regularization + alpha * lgl * lasso_regularization\n","      loss.backward()\n","      optimizer.step()\n","      running_loss += loss.item()\n","\n","    # for the validation dataset\n","    for data in validloader:\n","      inputs, labels = data\n","      inputs, labels = inputs.cuda(0), labels.cuda(0)\n","      outputs = net(inputs)\n","      _, predicted = torch.max(outputs.data, 1)\n","      valid_total += labels.size(0)\n","      valid_correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n","    \n","    # for the test dataset\n","    for data in testloader:\n","      inputs, labels = data\n","      inputs, labels = inputs.cuda(0), labels.cuda(0)\n","      outputs = net(inputs)\n","      _, predicted = torch.max(outputs.data, 1)\n","      test_total += labels.size(0)\n","      test_correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n","    \n","    # obtain the results for training, validation, test dataset\n","    train_acc = 100 * train_correct / train_total\n","    valid_acc = 100 * valid_correct / valid_total\n","    test_acc = 100 * test_correct / test_total\n","    train_acc_list.append(train_acc)\n","    val_acc_list.append(valid_acc)\n","    test_acc_list.append(test_acc)\n","    print(\"epoch %d, loss %.3f, train acc %.2f%%, valid acc %.2f%%, test acc %.2f%%\" % (epoch+1, running_loss, train_acc, valid_acc, test_acc))\n","    \n","    # save the best model\n","    if valid_acc >= accuray:\n","      accuray = valid_acc\n","      torch.save(net, PATH + '/model/' + TYPE + str(k) + \".ptl\")\n","      torch.jit.save(torch.jit.script(net), PATH + '/model/' + TYPE + str(k) + \"_git.ptl\")\n","    \n","  return train_acc_list, val_acc_list, test_acc_list"]},{"cell_type":"markdown","metadata":{"id":"QvBRzZPo1Qqb"},"source":["## Results for CNN Model"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"6lmjtMiIvcJ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639680844770,"user_tz":300,"elapsed":257182,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"}},"outputId":"625a4da1-9f5a-467b-97fa-f2bc57e7c3f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate 0.00010, batch size 32, node size 128, kernal size 5\n","epoch 1, loss 131.752, train acc 44.65%, valid acc 62.61%, test acc 61.79%\n","epoch 2, loss 126.765, train acc 64.24%, valid acc 66.28%, test acc 63.90%\n","epoch 3, loss 124.801, train acc 70.65%, valid acc 74.03%, test acc 71.50%\n","epoch 4, loss 123.413, train acc 75.21%, valid acc 74.64%, test acc 71.26%\n","epoch 5, loss 122.908, train acc 77.18%, valid acc 75.39%, test acc 72.38%\n","epoch 6, loss 122.684, train acc 77.74%, valid acc 75.73%, test acc 71.29%\n","epoch 7, loss 122.587, train acc 78.13%, valid acc 76.82%, test acc 73.67%\n","epoch 8, loss 120.063, train acc 86.63%, valid acc 89.26%, test acc 85.68%\n","epoch 9, loss 118.766, train acc 90.95%, valid acc 90.14%, test acc 86.29%\n","epoch 10, loss 118.303, train acc 92.23%, valid acc 91.50%, test acc 86.63%\n","epoch 11, loss 118.146, train acc 92.79%, valid acc 91.71%, test acc 87.61%\n","epoch 12, loss 117.924, train acc 93.54%, valid acc 92.32%, test acc 86.83%\n","epoch 13, loss 117.693, train acc 94.25%, valid acc 93.27%, test acc 88.56%\n","epoch 14, loss 117.659, train acc 94.35%, valid acc 92.39%, test acc 86.83%\n","epoch 15, loss 117.566, train acc 94.73%, valid acc 93.47%, test acc 87.89%\n","epoch 16, loss 117.513, train acc 94.81%, valid acc 92.79%, test acc 88.12%\n","epoch 17, loss 117.564, train acc 94.66%, valid acc 93.54%, test acc 89.04%\n","epoch 18, loss 117.385, train acc 95.19%, valid acc 92.59%, test acc 88.12%\n","epoch 19, loss 117.361, train acc 95.26%, valid acc 93.61%, test acc 88.43%\n","epoch 20, loss 117.280, train acc 95.51%, valid acc 93.41%, test acc 88.09%\n","epoch 21, loss 117.379, train acc 95.20%, valid acc 93.34%, test acc 88.02%\n","epoch 22, loss 117.381, train acc 95.19%, valid acc 93.47%, test acc 88.77%\n","epoch 23, loss 117.163, train acc 95.89%, valid acc 92.79%, test acc 88.09%\n","epoch 24, loss 117.308, train acc 95.46%, valid acc 92.05%, test acc 88.16%\n","epoch 25, loss 117.277, train acc 95.54%, valid acc 93.54%, test acc 88.33%\n","epoch 26, loss 117.236, train acc 95.58%, valid acc 93.95%, test acc 89.35%\n","epoch 27, loss 117.232, train acc 95.63%, valid acc 94.09%, test acc 89.18%\n","epoch 28, loss 117.093, train acc 96.07%, valid acc 93.88%, test acc 89.38%\n","epoch 29, loss 117.144, train acc 95.99%, valid acc 92.05%, test acc 87.24%\n","epoch 30, loss 117.129, train acc 96.00%, valid acc 93.61%, test acc 89.55%\n","epoch 31, loss 117.132, train acc 95.99%, valid acc 93.61%, test acc 89.68%\n","epoch 32, loss 117.051, train acc 96.29%, valid acc 94.15%, test acc 89.31%\n","epoch 33, loss 117.060, train acc 96.28%, valid acc 94.49%, test acc 90.23%\n","epoch 34, loss 117.142, train acc 95.92%, valid acc 94.02%, test acc 89.68%\n","epoch 35, loss 117.114, train acc 96.06%, valid acc 94.09%, test acc 89.62%\n","epoch 36, loss 117.001, train acc 96.38%, valid acc 94.63%, test acc 89.62%\n","epoch 37, loss 116.962, train acc 96.55%, valid acc 94.15%, test acc 89.51%\n","epoch 38, loss 116.947, train acc 96.58%, valid acc 94.83%, test acc 89.99%\n","epoch 39, loss 117.116, train acc 96.02%, valid acc 92.11%, test acc 88.63%\n","epoch 40, loss 117.009, train acc 96.36%, valid acc 93.75%, test acc 89.21%\n","epoch 41, loss 117.118, train acc 95.92%, valid acc 93.54%, test acc 89.99%\n","epoch 42, loss 117.068, train acc 96.17%, valid acc 93.88%, test acc 89.65%\n","epoch 43, loss 117.029, train acc 96.23%, valid acc 94.09%, test acc 88.84%\n","epoch 44, loss 117.035, train acc 96.23%, valid acc 91.71%, test acc 88.84%\n","epoch 45, loss 117.111, train acc 96.04%, valid acc 93.81%, test acc 89.62%\n","epoch 46, loss 117.135, train acc 95.97%, valid acc 94.36%, test acc 89.75%\n","epoch 47, loss 117.014, train acc 96.29%, valid acc 93.47%, test acc 89.82%\n","epoch 48, loss 116.987, train acc 96.41%, valid acc 94.43%, test acc 90.06%\n","epoch 49, loss 116.941, train acc 96.60%, valid acc 94.02%, test acc 90.30%\n","epoch 50, loss 116.894, train acc 96.70%, valid acc 94.02%, test acc 90.02%\n","epoch 51, loss 117.076, train acc 96.16%, valid acc 93.95%, test acc 89.48%\n","epoch 52, loss 116.966, train acc 96.48%, valid acc 93.88%, test acc 90.33%\n","epoch 53, loss 116.930, train acc 96.60%, valid acc 94.63%, test acc 90.02%\n","epoch 54, loss 116.946, train acc 96.58%, valid acc 94.22%, test acc 90.02%\n","epoch 55, loss 117.003, train acc 96.36%, valid acc 93.54%, test acc 89.89%\n","epoch 56, loss 116.963, train acc 96.55%, valid acc 94.02%, test acc 90.40%\n","epoch 57, loss 116.948, train acc 96.53%, valid acc 93.68%, test acc 88.90%\n","epoch 58, loss 116.977, train acc 96.45%, valid acc 93.81%, test acc 90.06%\n","epoch 59, loss 117.023, train acc 96.31%, valid acc 94.15%, test acc 89.89%\n","epoch 60, loss 116.904, train acc 96.70%, valid acc 94.09%, test acc 89.11%\n","epoch 61, loss 116.926, train acc 96.58%, valid acc 94.09%, test acc 89.72%\n","epoch 62, loss 116.979, train acc 96.43%, valid acc 94.43%, test acc 89.38%\n","epoch 63, loss 116.932, train acc 96.63%, valid acc 94.70%, test acc 90.13%\n","epoch 64, loss 116.908, train acc 96.68%, valid acc 94.49%, test acc 90.43%\n","epoch 65, loss 116.892, train acc 96.68%, valid acc 94.22%, test acc 90.26%\n","epoch 66, loss 116.867, train acc 96.84%, valid acc 94.29%, test acc 89.11%\n","epoch 67, loss 116.898, train acc 96.74%, valid acc 94.36%, test acc 89.21%\n","epoch 68, loss 117.048, train acc 96.23%, valid acc 93.81%, test acc 89.31%\n","epoch 69, loss 116.885, train acc 96.72%, valid acc 94.22%, test acc 89.21%\n","epoch 70, loss 117.029, train acc 96.24%, valid acc 94.77%, test acc 90.46%\n","epoch 71, loss 116.839, train acc 96.89%, valid acc 94.77%, test acc 90.74%\n","epoch 72, loss 116.830, train acc 96.92%, valid acc 95.04%, test acc 90.87%\n","epoch 73, loss 116.855, train acc 96.84%, valid acc 94.90%, test acc 89.75%\n","epoch 74, loss 116.941, train acc 96.58%, valid acc 94.15%, test acc 90.87%\n","epoch 75, loss 116.996, train acc 96.40%, valid acc 93.20%, test acc 88.87%\n","epoch 76, loss 116.964, train acc 96.45%, valid acc 94.56%, test acc 89.85%\n","epoch 77, loss 116.846, train acc 96.91%, valid acc 94.70%, test acc 89.85%\n","epoch 78, loss 116.779, train acc 97.11%, valid acc 94.56%, test acc 90.06%\n","epoch 79, loss 116.772, train acc 97.16%, valid acc 94.43%, test acc 90.26%\n","epoch 80, loss 116.870, train acc 96.85%, valid acc 94.22%, test acc 89.92%\n","epoch 81, loss 117.080, train acc 96.11%, valid acc 93.47%, test acc 88.70%\n","epoch 82, loss 116.911, train acc 96.67%, valid acc 93.61%, test acc 88.67%\n","epoch 83, loss 116.910, train acc 96.63%, valid acc 94.63%, test acc 91.01%\n","epoch 84, loss 116.764, train acc 97.18%, valid acc 94.70%, test acc 90.74%\n","epoch 85, loss 116.764, train acc 97.19%, valid acc 94.63%, test acc 90.60%\n","epoch 86, loss 116.765, train acc 97.09%, valid acc 94.22%, test acc 89.62%\n","epoch 87, loss 116.799, train acc 97.01%, valid acc 94.70%, test acc 90.19%\n","epoch 88, loss 116.892, train acc 96.67%, valid acc 93.75%, test acc 89.38%\n","epoch 89, loss 116.805, train acc 96.97%, valid acc 94.70%, test acc 90.80%\n","epoch 90, loss 116.772, train acc 97.09%, valid acc 94.77%, test acc 90.94%\n","epoch 91, loss 116.683, train acc 97.42%, valid acc 94.22%, test acc 89.75%\n","epoch 92, loss 116.672, train acc 97.45%, valid acc 95.04%, test acc 90.26%\n","epoch 93, loss 116.711, train acc 97.33%, valid acc 94.97%, test acc 91.04%\n","epoch 94, loss 116.644, train acc 97.59%, valid acc 94.90%, test acc 90.43%\n","epoch 95, loss 116.714, train acc 97.28%, valid acc 93.54%, test acc 89.72%\n","epoch 96, loss 116.809, train acc 96.99%, valid acc 94.22%, test acc 90.67%\n","epoch 97, loss 116.787, train acc 97.04%, valid acc 94.56%, test acc 91.25%\n","epoch 98, loss 116.770, train acc 97.09%, valid acc 94.63%, test acc 90.26%\n","epoch 99, loss 116.637, train acc 97.55%, valid acc 94.97%, test acc 91.18%\n","epoch 100, loss 116.727, train acc 97.26%, valid acc 94.56%, test acc 90.84%\n","epoch 101, loss 116.874, train acc 96.80%, valid acc 94.77%, test acc 89.38%\n","epoch 102, loss 116.753, train acc 97.26%, valid acc 94.02%, test acc 89.55%\n","epoch 103, loss 116.712, train acc 97.35%, valid acc 94.56%, test acc 90.84%\n","epoch 104, loss 116.641, train acc 97.59%, valid acc 94.70%, test acc 89.96%\n","epoch 105, loss 116.672, train acc 97.40%, valid acc 94.97%, test acc 91.11%\n","epoch 106, loss 116.621, train acc 97.67%, valid acc 94.70%, test acc 90.33%\n","epoch 107, loss 116.677, train acc 97.45%, valid acc 94.63%, test acc 91.08%\n","epoch 108, loss 116.813, train acc 96.96%, valid acc 93.95%, test acc 90.26%\n","epoch 109, loss 116.669, train acc 97.45%, valid acc 94.56%, test acc 89.99%\n","epoch 110, loss 116.654, train acc 97.48%, valid acc 94.63%, test acc 90.50%\n","epoch 111, loss 116.714, train acc 97.28%, valid acc 94.77%, test acc 91.28%\n","epoch 112, loss 116.639, train acc 97.57%, valid acc 94.83%, test acc 91.21%\n","epoch 113, loss 116.747, train acc 97.18%, valid acc 94.70%, test acc 91.62%\n","epoch 114, loss 116.590, train acc 97.74%, valid acc 94.63%, test acc 90.63%\n","epoch 115, loss 116.639, train acc 97.59%, valid acc 94.97%, test acc 91.45%\n","epoch 116, loss 116.628, train acc 97.60%, valid acc 95.31%, test acc 90.50%\n","epoch 117, loss 116.656, train acc 97.50%, valid acc 94.90%, test acc 90.19%\n","epoch 118, loss 116.635, train acc 97.59%, valid acc 93.54%, test acc 89.45%\n","epoch 119, loss 116.805, train acc 97.06%, valid acc 94.15%, test acc 91.21%\n","epoch 120, loss 116.709, train acc 97.30%, valid acc 94.29%, test acc 90.53%\n","epoch 121, loss 116.695, train acc 97.36%, valid acc 95.17%, test acc 90.02%\n","epoch 122, loss 116.684, train acc 97.42%, valid acc 94.22%, test acc 90.97%\n","epoch 123, loss 116.631, train acc 97.60%, valid acc 94.83%, test acc 90.91%\n","epoch 124, loss 116.674, train acc 97.47%, valid acc 94.77%, test acc 90.06%\n","epoch 125, loss 116.628, train acc 97.60%, valid acc 95.04%, test acc 91.31%\n","epoch 126, loss 116.612, train acc 97.67%, valid acc 94.70%, test acc 90.97%\n","epoch 127, loss 116.709, train acc 97.31%, valid acc 95.11%, test acc 90.87%\n","epoch 128, loss 116.680, train acc 97.45%, valid acc 94.97%, test acc 90.57%\n","epoch 129, loss 116.652, train acc 97.50%, valid acc 95.04%, test acc 89.96%\n","epoch 130, loss 116.647, train acc 97.50%, valid acc 93.95%, test acc 91.41%\n","epoch 131, loss 116.612, train acc 97.64%, valid acc 94.97%, test acc 91.48%\n","epoch 132, loss 116.682, train acc 97.38%, valid acc 94.70%, test acc 91.55%\n","epoch 133, loss 116.573, train acc 97.77%, valid acc 95.11%, test acc 91.45%\n","epoch 134, loss 116.580, train acc 97.77%, valid acc 95.24%, test acc 91.55%\n","epoch 135, loss 116.670, train acc 97.45%, valid acc 94.97%, test acc 91.01%\n","epoch 136, loss 116.884, train acc 96.67%, valid acc 94.97%, test acc 91.38%\n","epoch 137, loss 116.647, train acc 97.55%, valid acc 93.47%, test acc 90.23%\n","epoch 138, loss 116.650, train acc 97.52%, valid acc 95.38%, test acc 91.52%\n","epoch 139, loss 116.563, train acc 97.82%, valid acc 95.17%, test acc 91.41%\n","epoch 140, loss 116.631, train acc 97.57%, valid acc 94.70%, test acc 91.48%\n","epoch 141, loss 116.572, train acc 97.76%, valid acc 94.97%, test acc 91.58%\n","epoch 142, loss 116.588, train acc 97.70%, valid acc 94.77%, test acc 91.69%\n","epoch 143, loss 116.599, train acc 97.69%, valid acc 94.90%, test acc 90.60%\n","epoch 144, loss 116.689, train acc 97.38%, valid acc 94.97%, test acc 91.25%\n","epoch 145, loss 116.587, train acc 97.74%, valid acc 94.90%, test acc 90.63%\n","epoch 146, loss 116.615, train acc 97.60%, valid acc 94.77%, test acc 90.33%\n","epoch 147, loss 116.674, train acc 97.40%, valid acc 93.81%, test acc 90.67%\n","epoch 148, loss 116.637, train acc 97.57%, valid acc 95.31%, test acc 91.28%\n","epoch 149, loss 116.661, train acc 97.47%, valid acc 94.43%, test acc 90.53%\n","epoch 150, loss 116.586, train acc 97.72%, valid acc 94.49%, test acc 90.77%\n"]}],"source":["TYPE = 'no_penalty'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7YmnxB-RLWPZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639675970336,"user_tz":300,"elapsed":277172,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"}},"outputId":"7f3cfa6b-b879-4dbb-e194-cc9014517aa8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate 0.00010, batch size 32, node size 128, kernal size 5\n","epoch 1, loss 131.758, train acc 44.65%, valid acc 62.61%, test acc 61.79%\n","epoch 2, loss 126.771, train acc 64.24%, valid acc 66.28%, test acc 63.90%\n","epoch 3, loss 124.807, train acc 70.65%, valid acc 74.03%, test acc 71.50%\n","epoch 4, loss 123.419, train acc 75.21%, valid acc 74.64%, test acc 71.26%\n","epoch 5, loss 122.914, train acc 77.18%, valid acc 75.39%, test acc 72.38%\n","epoch 6, loss 122.690, train acc 77.74%, valid acc 75.73%, test acc 71.29%\n","epoch 7, loss 122.593, train acc 78.13%, valid acc 76.82%, test acc 73.67%\n","epoch 8, loss 120.069, train acc 86.63%, valid acc 89.26%, test acc 85.68%\n","epoch 9, loss 118.772, train acc 90.95%, valid acc 90.14%, test acc 86.29%\n","epoch 10, loss 118.309, train acc 92.23%, valid acc 91.50%, test acc 86.63%\n","epoch 11, loss 118.152, train acc 92.79%, valid acc 91.71%, test acc 87.61%\n","epoch 12, loss 117.930, train acc 93.54%, valid acc 92.32%, test acc 86.83%\n","epoch 13, loss 117.699, train acc 94.25%, valid acc 93.27%, test acc 88.56%\n","epoch 14, loss 117.665, train acc 94.35%, valid acc 92.39%, test acc 86.83%\n","epoch 15, loss 117.572, train acc 94.73%, valid acc 93.47%, test acc 87.89%\n","epoch 16, loss 117.519, train acc 94.81%, valid acc 92.79%, test acc 88.12%\n","epoch 17, loss 117.570, train acc 94.66%, valid acc 93.54%, test acc 89.04%\n","epoch 18, loss 117.391, train acc 95.19%, valid acc 92.59%, test acc 88.12%\n","epoch 19, loss 117.367, train acc 95.26%, valid acc 93.61%, test acc 88.43%\n","epoch 20, loss 117.287, train acc 95.51%, valid acc 93.41%, test acc 88.09%\n","epoch 21, loss 117.385, train acc 95.20%, valid acc 93.34%, test acc 88.02%\n","epoch 22, loss 117.387, train acc 95.19%, valid acc 93.47%, test acc 88.77%\n","epoch 23, loss 117.170, train acc 95.89%, valid acc 92.79%, test acc 88.09%\n","epoch 24, loss 117.314, train acc 95.46%, valid acc 92.05%, test acc 88.16%\n","epoch 25, loss 117.284, train acc 95.54%, valid acc 93.54%, test acc 88.33%\n","epoch 26, loss 117.242, train acc 95.58%, valid acc 93.95%, test acc 89.35%\n","epoch 27, loss 117.239, train acc 95.63%, valid acc 94.09%, test acc 89.18%\n","epoch 28, loss 117.100, train acc 96.07%, valid acc 93.88%, test acc 89.38%\n","epoch 29, loss 117.150, train acc 95.99%, valid acc 92.05%, test acc 87.24%\n","epoch 30, loss 117.135, train acc 96.00%, valid acc 93.61%, test acc 89.55%\n","epoch 31, loss 117.139, train acc 95.99%, valid acc 93.61%, test acc 89.68%\n","epoch 32, loss 117.057, train acc 96.29%, valid acc 94.15%, test acc 89.31%\n","epoch 33, loss 117.066, train acc 96.28%, valid acc 94.49%, test acc 90.23%\n","epoch 34, loss 117.148, train acc 95.92%, valid acc 94.02%, test acc 89.68%\n","epoch 35, loss 117.120, train acc 96.06%, valid acc 94.09%, test acc 89.62%\n","epoch 36, loss 117.007, train acc 96.38%, valid acc 94.63%, test acc 89.62%\n","epoch 37, loss 116.969, train acc 96.55%, valid acc 94.15%, test acc 89.51%\n","epoch 38, loss 116.953, train acc 96.58%, valid acc 94.83%, test acc 89.99%\n","epoch 39, loss 117.122, train acc 96.02%, valid acc 92.11%, test acc 88.63%\n","epoch 40, loss 117.015, train acc 96.36%, valid acc 93.75%, test acc 89.21%\n","epoch 41, loss 117.124, train acc 95.92%, valid acc 93.54%, test acc 89.99%\n","epoch 42, loss 117.074, train acc 96.17%, valid acc 93.88%, test acc 89.65%\n","epoch 43, loss 117.035, train acc 96.23%, valid acc 94.09%, test acc 88.84%\n","epoch 44, loss 117.042, train acc 96.23%, valid acc 91.71%, test acc 88.84%\n","epoch 45, loss 117.117, train acc 96.04%, valid acc 93.81%, test acc 89.62%\n","epoch 46, loss 117.141, train acc 95.97%, valid acc 94.36%, test acc 89.75%\n","epoch 47, loss 117.020, train acc 96.29%, valid acc 93.47%, test acc 89.82%\n","epoch 48, loss 116.993, train acc 96.41%, valid acc 94.43%, test acc 90.06%\n","epoch 49, loss 116.947, train acc 96.60%, valid acc 94.02%, test acc 90.30%\n","epoch 50, loss 116.900, train acc 96.70%, valid acc 94.02%, test acc 90.02%\n","epoch 51, loss 117.082, train acc 96.16%, valid acc 93.95%, test acc 89.48%\n","epoch 52, loss 116.972, train acc 96.48%, valid acc 93.88%, test acc 90.33%\n","epoch 53, loss 116.936, train acc 96.60%, valid acc 94.63%, test acc 90.02%\n","epoch 54, loss 116.952, train acc 96.58%, valid acc 94.22%, test acc 90.02%\n","epoch 55, loss 117.009, train acc 96.36%, valid acc 93.54%, test acc 89.89%\n","epoch 56, loss 116.969, train acc 96.55%, valid acc 94.02%, test acc 90.40%\n","epoch 57, loss 116.954, train acc 96.53%, valid acc 93.68%, test acc 88.90%\n","epoch 58, loss 116.983, train acc 96.45%, valid acc 93.81%, test acc 90.06%\n","epoch 59, loss 117.029, train acc 96.31%, valid acc 94.15%, test acc 89.89%\n","epoch 60, loss 116.910, train acc 96.70%, valid acc 94.09%, test acc 89.11%\n","epoch 61, loss 116.932, train acc 96.58%, valid acc 94.09%, test acc 89.72%\n","epoch 62, loss 116.985, train acc 96.43%, valid acc 94.43%, test acc 89.38%\n","epoch 63, loss 116.938, train acc 96.63%, valid acc 94.70%, test acc 90.13%\n","epoch 64, loss 116.914, train acc 96.68%, valid acc 94.49%, test acc 90.43%\n","epoch 65, loss 116.898, train acc 96.68%, valid acc 94.22%, test acc 90.26%\n","epoch 66, loss 116.873, train acc 96.84%, valid acc 94.29%, test acc 89.11%\n","epoch 67, loss 116.905, train acc 96.74%, valid acc 94.36%, test acc 89.21%\n","epoch 68, loss 117.055, train acc 96.23%, valid acc 93.81%, test acc 89.31%\n","epoch 69, loss 116.891, train acc 96.72%, valid acc 94.22%, test acc 89.21%\n","epoch 70, loss 117.035, train acc 96.24%, valid acc 94.77%, test acc 90.46%\n","epoch 71, loss 116.845, train acc 96.89%, valid acc 94.77%, test acc 90.74%\n","epoch 72, loss 116.836, train acc 96.92%, valid acc 95.04%, test acc 90.87%\n","epoch 73, loss 116.861, train acc 96.84%, valid acc 94.90%, test acc 89.75%\n","epoch 74, loss 116.948, train acc 96.58%, valid acc 94.15%, test acc 90.87%\n","epoch 75, loss 117.002, train acc 96.40%, valid acc 93.20%, test acc 88.87%\n","epoch 76, loss 116.970, train acc 96.45%, valid acc 94.56%, test acc 89.85%\n","epoch 77, loss 116.853, train acc 96.91%, valid acc 94.70%, test acc 89.85%\n","epoch 78, loss 116.785, train acc 97.11%, valid acc 94.56%, test acc 90.06%\n","epoch 79, loss 116.778, train acc 97.16%, valid acc 94.43%, test acc 90.26%\n","epoch 80, loss 116.876, train acc 96.85%, valid acc 94.22%, test acc 89.92%\n","epoch 81, loss 117.086, train acc 96.11%, valid acc 93.47%, test acc 88.70%\n","epoch 82, loss 116.917, train acc 96.67%, valid acc 93.61%, test acc 88.67%\n","epoch 83, loss 116.916, train acc 96.63%, valid acc 94.63%, test acc 91.01%\n","epoch 84, loss 116.770, train acc 97.18%, valid acc 94.70%, test acc 90.74%\n","epoch 85, loss 116.770, train acc 97.19%, valid acc 94.63%, test acc 90.60%\n","epoch 86, loss 116.771, train acc 97.09%, valid acc 94.22%, test acc 89.62%\n","epoch 87, loss 116.805, train acc 97.01%, valid acc 94.70%, test acc 90.19%\n","epoch 88, loss 116.899, train acc 96.67%, valid acc 93.75%, test acc 89.38%\n","epoch 89, loss 116.811, train acc 96.97%, valid acc 94.70%, test acc 90.80%\n","epoch 90, loss 116.778, train acc 97.09%, valid acc 94.77%, test acc 90.94%\n","epoch 91, loss 116.689, train acc 97.42%, valid acc 94.22%, test acc 89.75%\n","epoch 92, loss 116.678, train acc 97.45%, valid acc 95.04%, test acc 90.26%\n","epoch 93, loss 116.717, train acc 97.33%, valid acc 94.97%, test acc 91.04%\n","epoch 94, loss 116.650, train acc 97.59%, valid acc 94.90%, test acc 90.43%\n","epoch 95, loss 116.720, train acc 97.28%, valid acc 93.54%, test acc 89.72%\n","epoch 96, loss 116.815, train acc 96.99%, valid acc 94.22%, test acc 90.67%\n","epoch 97, loss 116.793, train acc 97.04%, valid acc 94.56%, test acc 91.25%\n","epoch 98, loss 116.776, train acc 97.09%, valid acc 94.63%, test acc 90.26%\n","epoch 99, loss 116.643, train acc 97.55%, valid acc 94.97%, test acc 91.18%\n","epoch 100, loss 116.734, train acc 97.26%, valid acc 94.56%, test acc 90.84%\n","epoch 101, loss 116.880, train acc 96.80%, valid acc 94.77%, test acc 89.38%\n","epoch 102, loss 116.759, train acc 97.26%, valid acc 94.02%, test acc 89.55%\n","epoch 103, loss 116.718, train acc 97.35%, valid acc 94.56%, test acc 90.84%\n","epoch 104, loss 116.647, train acc 97.59%, valid acc 94.70%, test acc 89.96%\n","epoch 105, loss 116.679, train acc 97.40%, valid acc 94.97%, test acc 91.11%\n","epoch 106, loss 116.627, train acc 97.67%, valid acc 94.70%, test acc 90.33%\n","epoch 107, loss 116.683, train acc 97.45%, valid acc 94.63%, test acc 91.08%\n","epoch 108, loss 116.819, train acc 96.96%, valid acc 93.95%, test acc 90.26%\n","epoch 109, loss 116.675, train acc 97.45%, valid acc 94.56%, test acc 89.99%\n","epoch 110, loss 116.660, train acc 97.48%, valid acc 94.63%, test acc 90.50%\n","epoch 111, loss 116.721, train acc 97.28%, valid acc 94.77%, test acc 91.28%\n","epoch 112, loss 116.645, train acc 97.57%, valid acc 94.83%, test acc 91.21%\n","epoch 113, loss 116.753, train acc 97.18%, valid acc 94.70%, test acc 91.62%\n","epoch 114, loss 116.596, train acc 97.74%, valid acc 94.63%, test acc 90.63%\n","epoch 115, loss 116.645, train acc 97.59%, valid acc 94.97%, test acc 91.45%\n","epoch 116, loss 116.634, train acc 97.60%, valid acc 95.31%, test acc 90.50%\n","epoch 117, loss 116.662, train acc 97.50%, valid acc 94.90%, test acc 90.19%\n","epoch 118, loss 116.641, train acc 97.59%, valid acc 93.54%, test acc 89.45%\n","epoch 119, loss 116.812, train acc 97.06%, valid acc 94.15%, test acc 91.21%\n","epoch 120, loss 116.715, train acc 97.30%, valid acc 94.29%, test acc 90.53%\n","epoch 121, loss 116.702, train acc 97.36%, valid acc 95.17%, test acc 90.02%\n","epoch 122, loss 116.690, train acc 97.42%, valid acc 94.22%, test acc 90.97%\n","epoch 123, loss 116.637, train acc 97.60%, valid acc 94.83%, test acc 90.91%\n","epoch 124, loss 116.680, train acc 97.47%, valid acc 94.77%, test acc 90.06%\n","epoch 125, loss 116.634, train acc 97.60%, valid acc 95.04%, test acc 91.31%\n","epoch 126, loss 116.618, train acc 97.67%, valid acc 94.70%, test acc 90.97%\n","epoch 127, loss 116.715, train acc 97.31%, valid acc 95.11%, test acc 90.87%\n","epoch 128, loss 116.686, train acc 97.45%, valid acc 94.97%, test acc 90.57%\n","epoch 129, loss 116.658, train acc 97.50%, valid acc 95.04%, test acc 89.96%\n","epoch 130, loss 116.653, train acc 97.50%, valid acc 93.95%, test acc 91.41%\n","epoch 131, loss 116.619, train acc 97.64%, valid acc 94.97%, test acc 91.48%\n","epoch 132, loss 116.688, train acc 97.38%, valid acc 94.70%, test acc 91.55%\n","epoch 133, loss 116.579, train acc 97.77%, valid acc 95.11%, test acc 91.45%\n","epoch 134, loss 116.586, train acc 97.77%, valid acc 95.24%, test acc 91.55%\n","epoch 135, loss 116.676, train acc 97.45%, valid acc 94.97%, test acc 91.01%\n","epoch 136, loss 116.891, train acc 96.67%, valid acc 94.97%, test acc 91.38%\n","epoch 137, loss 116.653, train acc 97.55%, valid acc 93.47%, test acc 90.23%\n","epoch 138, loss 116.657, train acc 97.52%, valid acc 95.38%, test acc 91.52%\n","epoch 139, loss 116.569, train acc 97.82%, valid acc 95.17%, test acc 91.41%\n","epoch 140, loss 116.637, train acc 97.57%, valid acc 94.70%, test acc 91.48%\n","epoch 141, loss 116.578, train acc 97.76%, valid acc 94.97%, test acc 91.58%\n","epoch 142, loss 116.594, train acc 97.70%, valid acc 94.77%, test acc 91.69%\n","epoch 143, loss 116.605, train acc 97.69%, valid acc 94.90%, test acc 90.60%\n","epoch 144, loss 116.695, train acc 97.38%, valid acc 94.97%, test acc 91.25%\n","epoch 145, loss 116.593, train acc 97.74%, valid acc 94.90%, test acc 90.63%\n","epoch 146, loss 116.621, train acc 97.60%, valid acc 94.77%, test acc 90.33%\n","epoch 147, loss 116.680, train acc 97.40%, valid acc 93.81%, test acc 90.67%\n","epoch 148, loss 116.644, train acc 97.57%, valid acc 95.31%, test acc 91.28%\n","epoch 149, loss 116.667, train acc 97.47%, valid acc 94.43%, test acc 90.53%\n","epoch 150, loss 116.592, train acc 97.72%, valid acc 94.49%, test acc 90.77%\n"]}],"source":["TYPE = 'l0_norm'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XyuH3sWELbS6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639675693184,"user_tz":300,"elapsed":280338,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"}},"outputId":"af7e81a4-65c8-40d9-e895-1a180a128286"},"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate 0.00010, batch size 32, node size 128, kernal size 5\n","epoch 1, loss 131.725, train acc 44.43%, valid acc 69.75%, test acc 66.30%\n","epoch 2, loss 125.565, train acc 68.78%, valid acc 72.94%, test acc 67.80%\n","epoch 3, loss 124.587, train acc 71.84%, valid acc 75.32%, test acc 69.09%\n","epoch 4, loss 123.367, train acc 75.74%, valid acc 80.83%, test acc 76.86%\n","epoch 5, loss 121.551, train acc 81.75%, valid acc 85.38%, test acc 80.52%\n","epoch 6, loss 119.788, train acc 87.71%, valid acc 89.46%, test acc 84.15%\n","epoch 7, loss 118.870, train acc 90.60%, valid acc 91.16%, test acc 85.14%\n","epoch 8, loss 118.458, train acc 91.92%, valid acc 91.09%, test acc 85.85%\n","epoch 9, loss 118.139, train acc 92.96%, valid acc 91.64%, test acc 87.24%\n","epoch 10, loss 118.101, train acc 93.06%, valid acc 91.77%, test acc 86.66%\n","epoch 11, loss 117.814, train acc 93.91%, valid acc 92.52%, test acc 87.68%\n","epoch 12, loss 117.797, train acc 93.93%, valid acc 92.79%, test acc 87.34%\n","epoch 13, loss 117.607, train acc 94.61%, valid acc 92.66%, test acc 87.89%\n","epoch 14, loss 117.586, train acc 94.54%, valid acc 92.73%, test acc 88.56%\n","epoch 15, loss 117.661, train acc 94.29%, valid acc 93.54%, test acc 87.99%\n","epoch 16, loss 117.574, train acc 94.66%, valid acc 92.86%, test acc 87.55%\n","epoch 17, loss 117.469, train acc 94.92%, valid acc 92.52%, test acc 88.97%\n","epoch 18, loss 117.449, train acc 95.00%, valid acc 93.13%, test acc 87.65%\n","epoch 19, loss 117.365, train acc 95.29%, valid acc 93.41%, test acc 88.26%\n","epoch 20, loss 117.315, train acc 95.39%, valid acc 93.47%, test acc 88.77%\n","epoch 21, loss 117.356, train acc 95.22%, valid acc 93.68%, test acc 89.45%\n","epoch 22, loss 117.274, train acc 95.68%, valid acc 94.36%, test acc 89.14%\n","epoch 23, loss 117.347, train acc 95.31%, valid acc 93.27%, test acc 89.01%\n","epoch 24, loss 117.377, train acc 95.15%, valid acc 92.73%, test acc 88.60%\n","epoch 25, loss 117.204, train acc 95.83%, valid acc 94.22%, test acc 89.79%\n","epoch 26, loss 117.212, train acc 95.77%, valid acc 93.07%, test acc 89.45%\n","epoch 27, loss 117.251, train acc 95.70%, valid acc 93.95%, test acc 88.53%\n","epoch 28, loss 117.238, train acc 95.70%, valid acc 94.09%, test acc 89.58%\n","epoch 29, loss 117.193, train acc 95.75%, valid acc 92.59%, test acc 88.33%\n","epoch 30, loss 117.153, train acc 95.94%, valid acc 94.29%, test acc 88.67%\n","epoch 31, loss 117.198, train acc 95.77%, valid acc 93.95%, test acc 89.18%\n","epoch 32, loss 117.113, train acc 96.04%, valid acc 94.22%, test acc 88.56%\n","epoch 33, loss 117.116, train acc 96.04%, valid acc 94.36%, test acc 90.19%\n","epoch 34, loss 117.116, train acc 96.11%, valid acc 93.61%, test acc 89.55%\n","epoch 35, loss 117.205, train acc 95.73%, valid acc 94.02%, test acc 88.70%\n","epoch 36, loss 117.013, train acc 96.40%, valid acc 94.97%, test acc 89.99%\n","epoch 37, loss 117.056, train acc 96.28%, valid acc 93.47%, test acc 89.07%\n","epoch 38, loss 117.089, train acc 96.16%, valid acc 94.09%, test acc 90.09%\n","epoch 39, loss 117.063, train acc 96.21%, valid acc 93.20%, test acc 89.58%\n","epoch 40, loss 117.037, train acc 96.34%, valid acc 94.15%, test acc 88.63%\n","epoch 41, loss 117.006, train acc 96.46%, valid acc 94.70%, test acc 89.24%\n","epoch 42, loss 117.029, train acc 96.33%, valid acc 94.70%, test acc 90.26%\n","epoch 43, loss 117.081, train acc 96.17%, valid acc 94.56%, test acc 89.96%\n","epoch 44, loss 117.040, train acc 96.28%, valid acc 94.29%, test acc 89.72%\n","epoch 45, loss 117.090, train acc 96.11%, valid acc 94.63%, test acc 89.45%\n","epoch 46, loss 116.964, train acc 96.57%, valid acc 94.15%, test acc 88.80%\n","epoch 47, loss 117.058, train acc 96.31%, valid acc 94.15%, test acc 89.85%\n","epoch 48, loss 116.970, train acc 96.55%, valid acc 94.70%, test acc 90.36%\n","epoch 49, loss 116.935, train acc 96.63%, valid acc 93.95%, test acc 89.18%\n","epoch 50, loss 117.134, train acc 95.95%, valid acc 94.22%, test acc 89.51%\n","epoch 51, loss 117.001, train acc 96.41%, valid acc 94.90%, test acc 90.30%\n","epoch 52, loss 117.067, train acc 96.24%, valid acc 93.61%, test acc 88.73%\n","epoch 53, loss 117.099, train acc 96.09%, valid acc 94.15%, test acc 89.92%\n","epoch 54, loss 117.077, train acc 96.21%, valid acc 94.09%, test acc 89.31%\n","epoch 55, loss 117.002, train acc 96.41%, valid acc 95.04%, test acc 90.60%\n","epoch 56, loss 116.930, train acc 96.72%, valid acc 94.49%, test acc 89.85%\n","epoch 57, loss 116.954, train acc 96.55%, valid acc 94.77%, test acc 90.77%\n","epoch 58, loss 116.958, train acc 96.55%, valid acc 93.41%, test acc 89.14%\n","epoch 59, loss 117.023, train acc 96.36%, valid acc 94.63%, test acc 89.82%\n","epoch 60, loss 116.953, train acc 96.62%, valid acc 94.77%, test acc 90.50%\n","epoch 61, loss 116.934, train acc 96.63%, valid acc 94.09%, test acc 90.30%\n","epoch 62, loss 116.957, train acc 96.57%, valid acc 94.02%, test acc 90.26%\n","epoch 63, loss 117.103, train acc 96.12%, valid acc 94.70%, test acc 89.96%\n","epoch 64, loss 116.985, train acc 96.46%, valid acc 94.29%, test acc 89.96%\n","epoch 65, loss 116.954, train acc 96.51%, valid acc 94.56%, test acc 90.67%\n","epoch 66, loss 116.853, train acc 96.91%, valid acc 94.63%, test acc 90.36%\n","epoch 67, loss 116.905, train acc 96.75%, valid acc 93.81%, test acc 90.46%\n","epoch 68, loss 116.918, train acc 96.75%, valid acc 94.43%, test acc 90.23%\n","epoch 69, loss 116.867, train acc 96.84%, valid acc 94.29%, test acc 91.04%\n","epoch 70, loss 116.842, train acc 96.94%, valid acc 94.43%, test acc 91.11%\n","epoch 71, loss 116.858, train acc 96.85%, valid acc 94.29%, test acc 91.21%\n","epoch 72, loss 116.858, train acc 96.91%, valid acc 94.49%, test acc 90.91%\n","epoch 73, loss 116.868, train acc 96.89%, valid acc 94.77%, test acc 90.09%\n","epoch 74, loss 116.805, train acc 97.08%, valid acc 94.43%, test acc 90.43%\n","epoch 75, loss 116.811, train acc 97.02%, valid acc 94.63%, test acc 90.46%\n","epoch 76, loss 116.898, train acc 96.80%, valid acc 94.43%, test acc 89.41%\n","epoch 77, loss 116.957, train acc 96.62%, valid acc 94.70%, test acc 90.70%\n","epoch 78, loss 116.831, train acc 96.99%, valid acc 94.22%, test acc 90.06%\n","epoch 79, loss 116.869, train acc 96.87%, valid acc 93.81%, test acc 91.08%\n","epoch 80, loss 116.822, train acc 96.99%, valid acc 94.36%, test acc 90.06%\n","epoch 81, loss 116.904, train acc 96.77%, valid acc 93.34%, test acc 89.82%\n","epoch 82, loss 116.832, train acc 97.01%, valid acc 94.43%, test acc 90.23%\n","epoch 83, loss 116.738, train acc 97.31%, valid acc 94.56%, test acc 91.48%\n","epoch 84, loss 116.747, train acc 97.26%, valid acc 94.70%, test acc 90.63%\n","epoch 85, loss 116.805, train acc 97.01%, valid acc 94.83%, test acc 89.96%\n","epoch 86, loss 116.843, train acc 96.96%, valid acc 94.56%, test acc 90.33%\n","epoch 87, loss 116.866, train acc 96.89%, valid acc 93.95%, test acc 90.67%\n","epoch 88, loss 116.744, train acc 97.25%, valid acc 95.04%, test acc 90.53%\n","epoch 89, loss 116.751, train acc 97.19%, valid acc 93.95%, test acc 89.55%\n","epoch 90, loss 116.731, train acc 97.30%, valid acc 94.77%, test acc 90.84%\n","epoch 91, loss 116.688, train acc 97.45%, valid acc 94.77%, test acc 91.45%\n","epoch 92, loss 116.703, train acc 97.36%, valid acc 94.43%, test acc 90.43%\n","epoch 93, loss 116.747, train acc 97.26%, valid acc 94.77%, test acc 91.45%\n","epoch 94, loss 116.690, train acc 97.45%, valid acc 93.54%, test acc 88.43%\n","epoch 95, loss 116.763, train acc 97.18%, valid acc 94.43%, test acc 90.77%\n","epoch 96, loss 116.709, train acc 97.36%, valid acc 94.63%, test acc 90.63%\n","epoch 97, loss 116.708, train acc 97.40%, valid acc 94.36%, test acc 90.53%\n","epoch 98, loss 116.835, train acc 96.97%, valid acc 93.95%, test acc 89.11%\n","epoch 99, loss 116.944, train acc 96.62%, valid acc 94.09%, test acc 90.40%\n","epoch 100, loss 116.720, train acc 97.33%, valid acc 94.43%, test acc 91.01%\n","epoch 101, loss 116.728, train acc 97.33%, valid acc 93.34%, test acc 90.40%\n","epoch 102, loss 116.783, train acc 97.14%, valid acc 94.43%, test acc 90.19%\n","epoch 103, loss 116.748, train acc 97.25%, valid acc 93.68%, test acc 89.07%\n","epoch 104, loss 116.799, train acc 97.13%, valid acc 94.02%, test acc 90.60%\n","epoch 105, loss 116.746, train acc 97.28%, valid acc 94.49%, test acc 89.72%\n","epoch 106, loss 116.752, train acc 97.25%, valid acc 94.49%, test acc 90.36%\n","epoch 107, loss 116.734, train acc 97.31%, valid acc 94.43%, test acc 91.04%\n","epoch 108, loss 116.720, train acc 97.30%, valid acc 94.09%, test acc 91.18%\n","epoch 109, loss 116.733, train acc 97.28%, valid acc 93.88%, test acc 90.09%\n","epoch 110, loss 116.860, train acc 96.89%, valid acc 94.22%, test acc 90.67%\n","epoch 111, loss 116.710, train acc 97.40%, valid acc 94.63%, test acc 90.63%\n","epoch 112, loss 116.674, train acc 97.52%, valid acc 94.83%, test acc 90.97%\n","epoch 113, loss 116.721, train acc 97.33%, valid acc 94.56%, test acc 89.31%\n","epoch 114, loss 116.659, train acc 97.50%, valid acc 94.29%, test acc 89.89%\n","epoch 115, loss 116.652, train acc 97.57%, valid acc 94.77%, test acc 89.65%\n","epoch 116, loss 116.706, train acc 97.38%, valid acc 94.43%, test acc 90.13%\n","epoch 117, loss 116.801, train acc 97.13%, valid acc 93.95%, test acc 89.75%\n","epoch 118, loss 116.768, train acc 97.09%, valid acc 94.22%, test acc 90.74%\n","epoch 119, loss 116.633, train acc 97.62%, valid acc 94.36%, test acc 90.57%\n","epoch 120, loss 116.632, train acc 97.64%, valid acc 94.90%, test acc 90.30%\n","epoch 121, loss 116.614, train acc 97.65%, valid acc 94.29%, test acc 90.23%\n","epoch 122, loss 116.587, train acc 97.82%, valid acc 94.49%, test acc 91.25%\n","epoch 123, loss 116.635, train acc 97.60%, valid acc 93.54%, test acc 90.30%\n","epoch 124, loss 116.696, train acc 97.43%, valid acc 93.61%, test acc 90.97%\n","epoch 125, loss 116.709, train acc 97.33%, valid acc 94.63%, test acc 90.16%\n","epoch 126, loss 116.591, train acc 97.74%, valid acc 95.04%, test acc 90.63%\n","epoch 127, loss 116.638, train acc 97.59%, valid acc 94.63%, test acc 91.01%\n","epoch 128, loss 116.564, train acc 97.82%, valid acc 94.90%, test acc 90.97%\n","epoch 129, loss 116.641, train acc 97.59%, valid acc 94.83%, test acc 89.75%\n","epoch 130, loss 116.597, train acc 97.77%, valid acc 94.09%, test acc 90.50%\n","epoch 131, loss 116.638, train acc 97.60%, valid acc 94.43%, test acc 91.04%\n","epoch 132, loss 116.624, train acc 97.64%, valid acc 93.81%, test acc 90.43%\n","epoch 133, loss 116.826, train acc 96.96%, valid acc 93.13%, test acc 89.21%\n","epoch 134, loss 116.666, train acc 97.47%, valid acc 94.63%, test acc 90.97%\n","epoch 135, loss 116.658, train acc 97.55%, valid acc 94.36%, test acc 90.70%\n","epoch 136, loss 116.613, train acc 97.69%, valid acc 94.63%, test acc 91.55%\n","epoch 137, loss 116.607, train acc 97.72%, valid acc 94.90%, test acc 91.69%\n","epoch 138, loss 116.558, train acc 97.84%, valid acc 94.97%, test acc 91.18%\n","epoch 139, loss 116.558, train acc 97.89%, valid acc 95.11%, test acc 90.26%\n","epoch 140, loss 116.562, train acc 97.86%, valid acc 94.83%, test acc 90.63%\n","epoch 141, loss 116.667, train acc 97.52%, valid acc 95.11%, test acc 90.46%\n","epoch 142, loss 116.592, train acc 97.76%, valid acc 94.63%, test acc 89.82%\n","epoch 143, loss 116.668, train acc 97.50%, valid acc 94.36%, test acc 88.80%\n","epoch 144, loss 116.746, train acc 97.30%, valid acc 93.75%, test acc 89.55%\n","epoch 145, loss 116.675, train acc 97.48%, valid acc 94.36%, test acc 88.87%\n","epoch 146, loss 116.627, train acc 97.69%, valid acc 94.56%, test acc 90.33%\n","epoch 147, loss 116.646, train acc 97.57%, valid acc 94.83%, test acc 90.53%\n","epoch 148, loss 116.597, train acc 97.72%, valid acc 94.83%, test acc 90.91%\n","epoch 149, loss 116.567, train acc 97.84%, valid acc 94.63%, test acc 90.33%\n","epoch 150, loss 116.599, train acc 97.70%, valid acc 94.15%, test acc 89.11%\n"]}],"source":["TYPE = 'l1_norm'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nXMs5bpPLcpe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639675412865,"user_tz":300,"elapsed":285120,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"}},"outputId":"0d9a892b-84a6-44dd-9c9a-c01ee26e161d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate 0.00010, batch size 32, node size 128, kernal size 5\n","epoch 1, loss 131.729, train acc 44.65%, valid acc 59.89%, test acc 58.19%\n","epoch 2, loss 126.827, train acc 64.17%, valid acc 69.20%, test acc 65.93%\n","epoch 3, loss 124.475, train acc 71.91%, valid acc 74.44%, test acc 71.02%\n","epoch 4, loss 123.246, train acc 75.75%, valid acc 74.37%, test acc 71.12%\n","epoch 5, loss 122.957, train acc 77.03%, valid acc 75.59%, test acc 72.92%\n","epoch 6, loss 122.686, train acc 77.66%, valid acc 76.41%, test acc 73.67%\n","epoch 7, loss 122.476, train acc 78.37%, valid acc 76.61%, test acc 73.84%\n","epoch 8, loss 122.491, train acc 78.32%, valid acc 77.09%, test acc 74.45%\n","epoch 9, loss 122.230, train acc 79.10%, valid acc 80.90%, test acc 78.52%\n","epoch 10, loss 119.475, train acc 88.62%, valid acc 90.07%, test acc 85.00%\n","epoch 11, loss 118.447, train acc 91.80%, valid acc 90.28%, test acc 86.53%\n","epoch 12, loss 118.149, train acc 92.77%, valid acc 91.91%, test acc 86.26%\n","epoch 13, loss 117.879, train acc 93.81%, valid acc 93.34%, test acc 88.23%\n","epoch 14, loss 117.636, train acc 94.52%, valid acc 92.79%, test acc 87.44%\n","epoch 15, loss 117.579, train acc 94.56%, valid acc 92.73%, test acc 87.99%\n","epoch 16, loss 117.496, train acc 94.83%, valid acc 92.59%, test acc 88.29%\n","epoch 17, loss 117.375, train acc 95.29%, valid acc 93.68%, test acc 88.06%\n","epoch 18, loss 117.487, train acc 94.83%, valid acc 93.54%, test acc 88.73%\n","epoch 19, loss 117.418, train acc 95.05%, valid acc 93.20%, test acc 88.84%\n","epoch 20, loss 117.429, train acc 94.98%, valid acc 93.00%, test acc 87.82%\n","epoch 21, loss 117.287, train acc 95.46%, valid acc 94.09%, test acc 88.77%\n","epoch 22, loss 117.511, train acc 94.76%, valid acc 93.95%, test acc 87.95%\n","epoch 23, loss 117.191, train acc 95.73%, valid acc 92.93%, test acc 87.92%\n","epoch 24, loss 117.382, train acc 95.26%, valid acc 93.47%, test acc 88.67%\n","epoch 25, loss 117.139, train acc 96.02%, valid acc 93.95%, test acc 88.73%\n","epoch 26, loss 117.129, train acc 96.00%, valid acc 93.81%, test acc 89.45%\n","epoch 27, loss 117.183, train acc 95.77%, valid acc 93.68%, test acc 88.97%\n","epoch 28, loss 117.160, train acc 95.89%, valid acc 94.43%, test acc 90.02%\n","epoch 29, loss 117.117, train acc 96.09%, valid acc 93.54%, test acc 88.23%\n","epoch 30, loss 117.153, train acc 95.95%, valid acc 94.43%, test acc 89.07%\n","epoch 31, loss 117.003, train acc 96.45%, valid acc 93.68%, test acc 89.07%\n","epoch 32, loss 117.021, train acc 96.34%, valid acc 94.63%, test acc 89.72%\n","epoch 33, loss 117.030, train acc 96.33%, valid acc 94.43%, test acc 90.40%\n","epoch 34, loss 116.997, train acc 96.40%, valid acc 94.02%, test acc 89.48%\n","epoch 35, loss 117.114, train acc 96.06%, valid acc 92.11%, test acc 88.80%\n","epoch 36, loss 117.035, train acc 96.28%, valid acc 93.88%, test acc 88.97%\n","epoch 37, loss 117.031, train acc 96.31%, valid acc 94.02%, test acc 89.68%\n","epoch 38, loss 117.151, train acc 95.90%, valid acc 92.79%, test acc 87.68%\n","epoch 39, loss 117.176, train acc 95.78%, valid acc 94.56%, test acc 90.02%\n","epoch 40, loss 116.952, train acc 96.51%, valid acc 94.22%, test acc 90.06%\n","epoch 41, loss 117.060, train acc 96.23%, valid acc 93.68%, test acc 89.51%\n","epoch 42, loss 117.324, train acc 95.27%, valid acc 92.05%, test acc 87.17%\n","epoch 43, loss 117.264, train acc 95.54%, valid acc 93.81%, test acc 90.26%\n","epoch 44, loss 117.114, train acc 96.02%, valid acc 93.07%, test acc 88.12%\n","epoch 45, loss 117.161, train acc 95.85%, valid acc 94.83%, test acc 90.09%\n","epoch 46, loss 116.950, train acc 96.58%, valid acc 94.97%, test acc 90.60%\n","epoch 47, loss 116.933, train acc 96.58%, valid acc 94.90%, test acc 90.30%\n","epoch 48, loss 116.954, train acc 96.55%, valid acc 94.83%, test acc 89.82%\n","epoch 49, loss 116.897, train acc 96.74%, valid acc 94.22%, test acc 89.72%\n","epoch 50, loss 116.975, train acc 96.48%, valid acc 94.02%, test acc 90.30%\n","epoch 51, loss 116.877, train acc 96.75%, valid acc 95.04%, test acc 90.33%\n","epoch 52, loss 116.914, train acc 96.68%, valid acc 94.43%, test acc 90.09%\n","epoch 53, loss 117.005, train acc 96.38%, valid acc 94.29%, test acc 90.33%\n","epoch 54, loss 117.043, train acc 96.24%, valid acc 94.09%, test acc 89.96%\n","epoch 55, loss 116.919, train acc 96.67%, valid acc 94.09%, test acc 90.60%\n","epoch 56, loss 116.906, train acc 96.70%, valid acc 94.70%, test acc 90.70%\n","epoch 57, loss 116.958, train acc 96.48%, valid acc 94.49%, test acc 89.48%\n","epoch 58, loss 116.898, train acc 96.74%, valid acc 94.97%, test acc 89.75%\n","epoch 59, loss 116.896, train acc 96.72%, valid acc 94.29%, test acc 90.43%\n","epoch 60, loss 116.990, train acc 96.36%, valid acc 94.15%, test acc 90.57%\n","epoch 61, loss 116.959, train acc 96.55%, valid acc 94.49%, test acc 90.63%\n","epoch 62, loss 116.959, train acc 96.46%, valid acc 94.02%, test acc 90.36%\n","epoch 63, loss 117.080, train acc 96.06%, valid acc 93.07%, test acc 90.13%\n","epoch 64, loss 117.002, train acc 96.31%, valid acc 94.29%, test acc 89.65%\n","epoch 65, loss 116.819, train acc 96.94%, valid acc 94.36%, test acc 89.92%\n","epoch 66, loss 116.824, train acc 96.96%, valid acc 94.56%, test acc 90.23%\n","epoch 67, loss 116.853, train acc 96.82%, valid acc 93.75%, test acc 88.56%\n","epoch 68, loss 116.886, train acc 96.79%, valid acc 93.81%, test acc 88.36%\n","epoch 69, loss 116.840, train acc 96.87%, valid acc 94.77%, test acc 90.16%\n","epoch 70, loss 116.887, train acc 96.74%, valid acc 93.88%, test acc 90.36%\n","epoch 71, loss 116.894, train acc 96.74%, valid acc 94.09%, test acc 90.60%\n","epoch 72, loss 116.817, train acc 96.97%, valid acc 94.49%, test acc 90.87%\n","epoch 73, loss 116.746, train acc 97.26%, valid acc 94.70%, test acc 89.79%\n","epoch 74, loss 116.726, train acc 97.25%, valid acc 94.36%, test acc 89.79%\n","epoch 75, loss 116.779, train acc 97.06%, valid acc 94.43%, test acc 90.50%\n","epoch 76, loss 116.813, train acc 96.94%, valid acc 93.75%, test acc 89.62%\n","epoch 77, loss 116.930, train acc 96.58%, valid acc 94.49%, test acc 89.68%\n","epoch 78, loss 116.742, train acc 97.25%, valid acc 93.47%, test acc 89.68%\n","epoch 79, loss 116.774, train acc 97.09%, valid acc 94.22%, test acc 90.02%\n","epoch 80, loss 116.830, train acc 96.92%, valid acc 94.70%, test acc 89.51%\n","epoch 81, loss 116.731, train acc 97.30%, valid acc 95.45%, test acc 90.33%\n","epoch 82, loss 116.715, train acc 97.28%, valid acc 94.90%, test acc 90.84%\n","epoch 83, loss 116.662, train acc 97.50%, valid acc 94.70%, test acc 91.31%\n","epoch 84, loss 116.632, train acc 97.62%, valid acc 94.43%, test acc 90.94%\n","epoch 85, loss 116.697, train acc 97.33%, valid acc 94.83%, test acc 90.40%\n","epoch 86, loss 116.871, train acc 96.77%, valid acc 94.22%, test acc 89.11%\n","epoch 87, loss 116.723, train acc 97.31%, valid acc 94.09%, test acc 90.06%\n","epoch 88, loss 116.816, train acc 97.02%, valid acc 94.43%, test acc 90.60%\n","epoch 89, loss 116.673, train acc 97.43%, valid acc 94.63%, test acc 90.77%\n","epoch 90, loss 116.691, train acc 97.38%, valid acc 94.49%, test acc 90.94%\n","epoch 91, loss 116.664, train acc 97.48%, valid acc 94.56%, test acc 91.01%\n","epoch 92, loss 116.666, train acc 97.48%, valid acc 95.11%, test acc 90.67%\n","epoch 93, loss 116.668, train acc 97.47%, valid acc 94.97%, test acc 91.28%\n","epoch 94, loss 116.650, train acc 97.50%, valid acc 94.83%, test acc 90.46%\n","epoch 95, loss 116.717, train acc 97.33%, valid acc 94.63%, test acc 90.97%\n","epoch 96, loss 116.683, train acc 97.42%, valid acc 94.90%, test acc 90.43%\n","epoch 97, loss 116.763, train acc 97.18%, valid acc 93.13%, test acc 89.72%\n","epoch 98, loss 116.844, train acc 96.85%, valid acc 93.95%, test acc 90.84%\n","epoch 99, loss 116.671, train acc 97.45%, valid acc 94.77%, test acc 91.18%\n","epoch 100, loss 116.651, train acc 97.52%, valid acc 94.97%, test acc 90.87%\n","epoch 101, loss 116.634, train acc 97.55%, valid acc 94.49%, test acc 90.50%\n","epoch 102, loss 116.631, train acc 97.59%, valid acc 95.11%, test acc 90.77%\n","epoch 103, loss 116.643, train acc 97.50%, valid acc 93.13%, test acc 88.94%\n","epoch 104, loss 116.694, train acc 97.40%, valid acc 94.63%, test acc 90.57%\n","epoch 105, loss 116.791, train acc 97.09%, valid acc 94.49%, test acc 90.67%\n","epoch 106, loss 116.684, train acc 97.38%, valid acc 94.36%, test acc 90.97%\n","epoch 107, loss 116.646, train acc 97.50%, valid acc 94.29%, test acc 90.77%\n","epoch 108, loss 116.747, train acc 97.21%, valid acc 93.68%, test acc 89.96%\n","epoch 109, loss 116.683, train acc 97.38%, valid acc 95.04%, test acc 91.18%\n","epoch 110, loss 116.599, train acc 97.72%, valid acc 95.11%, test acc 91.45%\n","epoch 111, loss 116.575, train acc 97.77%, valid acc 95.04%, test acc 91.58%\n","epoch 112, loss 116.620, train acc 97.64%, valid acc 94.70%, test acc 90.53%\n","epoch 113, loss 116.660, train acc 97.47%, valid acc 93.54%, test acc 89.55%\n","epoch 114, loss 116.611, train acc 97.64%, valid acc 94.97%, test acc 91.18%\n","epoch 115, loss 116.716, train acc 97.30%, valid acc 94.63%, test acc 91.04%\n","epoch 116, loss 116.736, train acc 97.21%, valid acc 94.02%, test acc 90.19%\n","epoch 117, loss 116.596, train acc 97.74%, valid acc 94.22%, test acc 89.48%\n","epoch 118, loss 116.664, train acc 97.47%, valid acc 94.15%, test acc 91.04%\n","epoch 119, loss 116.690, train acc 97.36%, valid acc 94.36%, test acc 91.01%\n","epoch 120, loss 116.665, train acc 97.48%, valid acc 93.95%, test acc 89.72%\n","epoch 121, loss 116.659, train acc 97.52%, valid acc 94.97%, test acc 90.57%\n","epoch 122, loss 116.583, train acc 97.79%, valid acc 95.04%, test acc 91.45%\n","epoch 123, loss 116.639, train acc 97.50%, valid acc 95.17%, test acc 90.26%\n","epoch 124, loss 116.702, train acc 97.33%, valid acc 94.77%, test acc 91.28%\n","epoch 125, loss 116.654, train acc 97.43%, valid acc 94.70%, test acc 90.50%\n","epoch 126, loss 116.619, train acc 97.60%, valid acc 93.88%, test acc 89.72%\n","epoch 127, loss 116.717, train acc 97.28%, valid acc 95.04%, test acc 91.18%\n","epoch 128, loss 116.623, train acc 97.59%, valid acc 94.02%, test acc 90.63%\n","epoch 129, loss 116.645, train acc 97.59%, valid acc 95.04%, test acc 90.33%\n","epoch 130, loss 116.617, train acc 97.62%, valid acc 94.83%, test acc 90.87%\n","epoch 131, loss 116.603, train acc 97.67%, valid acc 94.63%, test acc 90.74%\n","epoch 132, loss 116.581, train acc 97.77%, valid acc 94.77%, test acc 90.23%\n","epoch 133, loss 116.721, train acc 97.28%, valid acc 94.56%, test acc 90.09%\n","epoch 134, loss 116.571, train acc 97.79%, valid acc 95.17%, test acc 90.74%\n","epoch 135, loss 116.629, train acc 97.62%, valid acc 94.77%, test acc 90.40%\n","epoch 136, loss 116.549, train acc 97.84%, valid acc 94.63%, test acc 90.94%\n","epoch 137, loss 116.599, train acc 97.67%, valid acc 94.36%, test acc 90.67%\n","epoch 138, loss 116.596, train acc 97.70%, valid acc 95.31%, test acc 91.18%\n","epoch 139, loss 116.732, train acc 97.25%, valid acc 95.11%, test acc 90.77%\n","epoch 140, loss 116.584, train acc 97.76%, valid acc 95.17%, test acc 91.38%\n","epoch 141, loss 116.567, train acc 97.79%, valid acc 94.83%, test acc 91.04%\n","epoch 142, loss 116.562, train acc 97.81%, valid acc 94.49%, test acc 90.74%\n","epoch 143, loss 116.648, train acc 97.53%, valid acc 93.41%, test acc 86.60%\n","epoch 144, loss 116.661, train acc 97.52%, valid acc 94.02%, test acc 89.72%\n","epoch 145, loss 116.603, train acc 97.65%, valid acc 95.24%, test acc 90.80%\n","epoch 146, loss 116.561, train acc 97.82%, valid acc 94.63%, test acc 90.23%\n","epoch 147, loss 116.626, train acc 97.57%, valid acc 94.63%, test acc 91.04%\n","epoch 148, loss 116.565, train acc 97.81%, valid acc 95.45%, test acc 91.01%\n","epoch 149, loss 116.581, train acc 97.79%, valid acc 94.97%, test acc 91.18%\n","epoch 150, loss 116.577, train acc 97.77%, valid acc 94.29%, test acc 89.58%\n"]}],"source":["TYPE = 'l2_norm'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vAMlleZxLdCx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639675127759,"user_tz":300,"elapsed":4849817,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"}},"outputId":"c5da7614-e0f0-4f34-d665-d0979e5a93be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate 0.00010, batch size 32, node size 128, kernal size 5\n","epoch 1, loss 131.698, train acc 44.77%, valid acc 61.45%, test acc 61.76%\n","epoch 2, loss 126.648, train acc 64.75%, valid acc 67.85%, test acc 65.15%\n","epoch 3, loss 124.632, train acc 71.35%, valid acc 73.96%, test acc 70.51%\n","epoch 4, loss 123.467, train acc 75.29%, valid acc 74.37%, test acc 71.02%\n","epoch 5, loss 123.070, train acc 76.57%, valid acc 75.12%, test acc 72.41%\n","epoch 6, loss 122.730, train acc 77.66%, valid acc 76.61%, test acc 73.43%\n","epoch 7, loss 122.567, train acc 78.23%, valid acc 76.27%, test acc 73.23%\n","epoch 8, loss 120.297, train acc 85.95%, valid acc 90.14%, test acc 85.34%\n","epoch 9, loss 118.791, train acc 90.95%, valid acc 90.89%, test acc 86.80%\n","epoch 10, loss 118.408, train acc 92.03%, valid acc 90.62%, test acc 84.29%\n","epoch 11, loss 118.096, train acc 92.93%, valid acc 92.52%, test acc 87.55%\n","epoch 12, loss 117.789, train acc 93.93%, valid acc 93.00%, test acc 88.16%\n","epoch 13, loss 117.699, train acc 94.22%, valid acc 92.93%, test acc 88.12%\n","epoch 14, loss 117.557, train acc 94.63%, valid acc 93.20%, test acc 88.63%\n","epoch 15, loss 117.513, train acc 94.83%, valid acc 92.73%, test acc 86.90%\n","epoch 16, loss 117.343, train acc 95.43%, valid acc 93.27%, test acc 88.73%\n","epoch 17, loss 117.469, train acc 94.88%, valid acc 93.47%, test acc 89.51%\n","epoch 18, loss 117.385, train acc 95.17%, valid acc 93.20%, test acc 88.87%\n","epoch 19, loss 117.276, train acc 95.60%, valid acc 93.34%, test acc 88.39%\n","epoch 20, loss 117.319, train acc 95.44%, valid acc 93.95%, test acc 88.97%\n","epoch 21, loss 117.190, train acc 95.87%, valid acc 93.34%, test acc 88.63%\n","epoch 22, loss 117.245, train acc 95.65%, valid acc 93.47%, test acc 89.41%\n","epoch 23, loss 117.321, train acc 95.27%, valid acc 93.47%, test acc 89.72%\n","epoch 24, loss 117.289, train acc 95.43%, valid acc 92.73%, test acc 89.11%\n","epoch 25, loss 117.130, train acc 95.99%, valid acc 93.61%, test acc 89.45%\n","epoch 26, loss 117.273, train acc 95.53%, valid acc 93.41%, test acc 90.02%\n","epoch 27, loss 117.513, train acc 94.68%, valid acc 93.95%, test acc 89.14%\n","epoch 28, loss 117.069, train acc 96.17%, valid acc 94.02%, test acc 89.65%\n","epoch 29, loss 117.128, train acc 96.02%, valid acc 94.36%, test acc 89.14%\n","epoch 30, loss 117.042, train acc 96.26%, valid acc 94.02%, test acc 89.96%\n","epoch 31, loss 117.134, train acc 96.00%, valid acc 94.43%, test acc 89.38%\n","epoch 32, loss 117.183, train acc 95.87%, valid acc 93.54%, test acc 89.07%\n","epoch 33, loss 117.169, train acc 95.77%, valid acc 93.95%, test acc 89.11%\n","epoch 34, loss 117.191, train acc 95.80%, valid acc 93.61%, test acc 89.65%\n","epoch 35, loss 117.131, train acc 95.92%, valid acc 93.54%, test acc 89.51%\n","epoch 36, loss 117.153, train acc 95.82%, valid acc 94.56%, test acc 88.43%\n","epoch 37, loss 117.234, train acc 95.58%, valid acc 93.81%, test acc 90.09%\n","epoch 38, loss 117.040, train acc 96.31%, valid acc 94.70%, test acc 89.79%\n","epoch 39, loss 116.954, train acc 96.55%, valid acc 93.81%, test acc 88.94%\n","epoch 40, loss 117.057, train acc 96.23%, valid acc 94.70%, test acc 90.26%\n","epoch 41, loss 117.031, train acc 96.40%, valid acc 94.90%, test acc 89.89%\n","epoch 42, loss 117.078, train acc 96.14%, valid acc 94.43%, test acc 89.85%\n","epoch 43, loss 116.994, train acc 96.43%, valid acc 94.29%, test acc 90.26%\n","epoch 44, loss 117.033, train acc 96.29%, valid acc 94.02%, test acc 89.99%\n","epoch 45, loss 117.080, train acc 96.14%, valid acc 94.83%, test acc 89.55%\n","epoch 46, loss 116.933, train acc 96.60%, valid acc 94.90%, test acc 89.99%\n","epoch 47, loss 116.956, train acc 96.51%, valid acc 94.90%, test acc 90.02%\n","epoch 48, loss 116.996, train acc 96.38%, valid acc 93.47%, test acc 88.29%\n","epoch 49, loss 117.236, train acc 95.58%, valid acc 94.70%, test acc 90.06%\n","epoch 50, loss 117.003, train acc 96.38%, valid acc 94.02%, test acc 89.48%\n","epoch 51, loss 117.036, train acc 96.29%, valid acc 94.77%, test acc 89.89%\n","epoch 52, loss 117.166, train acc 95.87%, valid acc 94.09%, test acc 88.73%\n","epoch 53, loss 116.967, train acc 96.51%, valid acc 94.63%, test acc 89.85%\n","epoch 54, loss 116.925, train acc 96.63%, valid acc 94.77%, test acc 90.36%\n","epoch 55, loss 116.914, train acc 96.67%, valid acc 94.15%, test acc 89.82%\n","epoch 56, loss 117.000, train acc 96.38%, valid acc 93.81%, test acc 89.28%\n","epoch 57, loss 116.998, train acc 96.38%, valid acc 94.49%, test acc 89.41%\n","epoch 58, loss 117.118, train acc 95.99%, valid acc 94.29%, test acc 90.19%\n","epoch 59, loss 117.072, train acc 96.07%, valid acc 94.63%, test acc 89.65%\n","epoch 60, loss 117.011, train acc 96.33%, valid acc 94.83%, test acc 89.99%\n","epoch 61, loss 117.047, train acc 96.19%, valid acc 94.36%, test acc 90.09%\n","epoch 62, loss 116.958, train acc 96.53%, valid acc 94.49%, test acc 91.11%\n","epoch 63, loss 116.885, train acc 96.77%, valid acc 94.77%, test acc 91.21%\n","epoch 64, loss 116.945, train acc 96.58%, valid acc 94.90%, test acc 90.36%\n","epoch 65, loss 117.025, train acc 96.26%, valid acc 94.22%, test acc 91.04%\n","epoch 66, loss 117.122, train acc 96.02%, valid acc 93.81%, test acc 89.65%\n","epoch 67, loss 116.984, train acc 96.43%, valid acc 94.22%, test acc 89.92%\n","epoch 68, loss 117.024, train acc 96.34%, valid acc 94.02%, test acc 90.30%\n","epoch 69, loss 116.975, train acc 96.41%, valid acc 94.49%, test acc 90.80%\n","epoch 70, loss 116.961, train acc 96.48%, valid acc 94.83%, test acc 91.25%\n","epoch 71, loss 116.872, train acc 96.80%, valid acc 94.70%, test acc 90.09%\n","epoch 72, loss 116.948, train acc 96.53%, valid acc 94.70%, test acc 90.46%\n","epoch 73, loss 116.908, train acc 96.68%, valid acc 94.02%, test acc 89.75%\n","epoch 74, loss 117.087, train acc 96.11%, valid acc 94.90%, test acc 90.77%\n","epoch 75, loss 116.911, train acc 96.65%, valid acc 95.04%, test acc 90.94%\n","epoch 76, loss 116.905, train acc 96.72%, valid acc 95.04%, test acc 90.67%\n","epoch 77, loss 116.875, train acc 96.79%, valid acc 95.04%, test acc 90.87%\n","epoch 78, loss 116.853, train acc 96.85%, valid acc 94.83%, test acc 89.79%\n","epoch 79, loss 116.878, train acc 96.79%, valid acc 94.83%, test acc 90.50%\n","epoch 80, loss 117.074, train acc 96.12%, valid acc 94.09%, test acc 89.14%\n","epoch 81, loss 117.256, train acc 95.56%, valid acc 94.15%, test acc 89.48%\n","epoch 82, loss 116.924, train acc 96.63%, valid acc 94.70%, test acc 90.84%\n","epoch 83, loss 116.868, train acc 96.82%, valid acc 94.77%, test acc 90.16%\n","epoch 84, loss 116.867, train acc 96.80%, valid acc 94.70%, test acc 91.69%\n","epoch 85, loss 116.885, train acc 96.77%, valid acc 94.70%, test acc 91.01%\n","epoch 86, loss 117.004, train acc 96.33%, valid acc 94.09%, test acc 89.07%\n","epoch 87, loss 116.984, train acc 96.41%, valid acc 93.81%, test acc 89.62%\n","epoch 88, loss 116.859, train acc 96.82%, valid acc 94.36%, test acc 89.85%\n","epoch 89, loss 117.127, train acc 95.99%, valid acc 94.02%, test acc 90.50%\n","epoch 90, loss 117.059, train acc 96.19%, valid acc 94.02%, test acc 91.41%\n","epoch 91, loss 116.842, train acc 96.91%, valid acc 94.77%, test acc 91.41%\n","epoch 92, loss 116.856, train acc 96.84%, valid acc 94.83%, test acc 90.43%\n","epoch 93, loss 116.854, train acc 96.87%, valid acc 93.81%, test acc 89.58%\n","epoch 94, loss 116.828, train acc 96.92%, valid acc 94.56%, test acc 91.55%\n","epoch 95, loss 116.795, train acc 97.01%, valid acc 94.29%, test acc 91.89%\n","epoch 96, loss 116.809, train acc 97.01%, valid acc 94.49%, test acc 91.14%\n","epoch 97, loss 116.837, train acc 96.89%, valid acc 94.83%, test acc 90.94%\n","epoch 98, loss 116.779, train acc 97.09%, valid acc 95.04%, test acc 91.58%\n","epoch 99, loss 116.822, train acc 96.96%, valid acc 93.81%, test acc 89.99%\n","epoch 100, loss 116.913, train acc 96.65%, valid acc 94.09%, test acc 90.70%\n","epoch 101, loss 116.903, train acc 96.72%, valid acc 94.02%, test acc 89.92%\n","epoch 102, loss 116.811, train acc 97.01%, valid acc 94.56%, test acc 90.63%\n","epoch 103, loss 116.794, train acc 97.06%, valid acc 93.13%, test acc 89.85%\n","epoch 104, loss 116.748, train acc 97.19%, valid acc 94.63%, test acc 90.84%\n","epoch 105, loss 116.714, train acc 97.31%, valid acc 94.70%, test acc 90.94%\n","epoch 106, loss 116.686, train acc 97.40%, valid acc 94.36%, test acc 90.97%\n","epoch 107, loss 116.740, train acc 97.21%, valid acc 93.95%, test acc 90.40%\n","epoch 108, loss 116.893, train acc 96.74%, valid acc 93.07%, test acc 88.90%\n","epoch 109, loss 116.808, train acc 97.01%, valid acc 93.95%, test acc 91.08%\n","epoch 110, loss 116.916, train acc 96.63%, valid acc 94.56%, test acc 90.13%\n","epoch 111, loss 116.840, train acc 96.91%, valid acc 94.29%, test acc 90.09%\n","epoch 112, loss 116.811, train acc 97.02%, valid acc 94.43%, test acc 90.57%\n","epoch 113, loss 116.737, train acc 97.21%, valid acc 94.63%, test acc 89.99%\n","epoch 114, loss 116.735, train acc 97.25%, valid acc 94.09%, test acc 89.48%\n","epoch 115, loss 116.806, train acc 96.97%, valid acc 94.22%, test acc 90.63%\n","epoch 116, loss 116.704, train acc 97.35%, valid acc 94.90%, test acc 91.35%\n","epoch 117, loss 116.728, train acc 97.28%, valid acc 94.63%, test acc 90.67%\n","epoch 118, loss 116.747, train acc 97.21%, valid acc 94.70%, test acc 90.36%\n","epoch 119, loss 116.681, train acc 97.42%, valid acc 94.70%, test acc 90.50%\n","epoch 120, loss 116.646, train acc 97.53%, valid acc 94.43%, test acc 91.08%\n","epoch 121, loss 116.719, train acc 97.31%, valid acc 94.22%, test acc 89.75%\n","epoch 122, loss 116.719, train acc 97.35%, valid acc 94.22%, test acc 90.43%\n","epoch 123, loss 116.756, train acc 97.16%, valid acc 94.36%, test acc 90.97%\n","epoch 124, loss 116.653, train acc 97.50%, valid acc 93.68%, test acc 90.09%\n","epoch 125, loss 116.771, train acc 97.14%, valid acc 92.52%, test acc 89.72%\n","epoch 126, loss 116.821, train acc 96.97%, valid acc 94.02%, test acc 88.63%\n","epoch 127, loss 116.730, train acc 97.26%, valid acc 94.63%, test acc 90.53%\n","epoch 128, loss 116.779, train acc 97.09%, valid acc 94.70%, test acc 90.46%\n","epoch 129, loss 116.685, train acc 97.36%, valid acc 94.29%, test acc 89.85%\n","epoch 130, loss 116.696, train acc 97.40%, valid acc 94.70%, test acc 91.01%\n","epoch 131, loss 116.673, train acc 97.45%, valid acc 94.70%, test acc 90.97%\n","epoch 132, loss 116.613, train acc 97.65%, valid acc 94.97%, test acc 90.50%\n","epoch 133, loss 116.752, train acc 97.19%, valid acc 94.83%, test acc 89.55%\n","epoch 134, loss 116.670, train acc 97.48%, valid acc 94.83%, test acc 90.50%\n","epoch 135, loss 116.676, train acc 97.45%, valid acc 94.43%, test acc 90.53%\n","epoch 136, loss 116.723, train acc 97.28%, valid acc 94.90%, test acc 90.63%\n","epoch 137, loss 116.673, train acc 97.45%, valid acc 94.36%, test acc 90.43%\n","epoch 138, loss 116.626, train acc 97.62%, valid acc 94.56%, test acc 90.63%\n","epoch 139, loss 116.581, train acc 97.77%, valid acc 94.90%, test acc 90.91%\n","epoch 140, loss 116.649, train acc 97.52%, valid acc 95.17%, test acc 90.13%\n","epoch 141, loss 116.719, train acc 97.31%, valid acc 93.95%, test acc 89.99%\n","epoch 142, loss 116.699, train acc 97.40%, valid acc 95.04%, test acc 90.33%\n","epoch 143, loss 116.671, train acc 97.40%, valid acc 94.70%, test acc 89.68%\n","epoch 144, loss 116.774, train acc 97.14%, valid acc 94.97%, test acc 90.67%\n","epoch 145, loss 116.568, train acc 97.79%, valid acc 95.17%, test acc 90.63%\n","epoch 146, loss 116.585, train acc 97.76%, valid acc 95.17%, test acc 90.80%\n","epoch 147, loss 116.601, train acc 97.69%, valid acc 94.63%, test acc 91.18%\n","epoch 148, loss 116.674, train acc 97.47%, valid acc 94.97%, test acc 90.77%\n","epoch 149, loss 116.635, train acc 97.55%, valid acc 94.70%, test acc 91.14%\n","epoch 150, loss 116.629, train acc 97.62%, valid acc 94.49%, test acc 90.36%\n"]}],"source":["TYPE = 'group_lasso'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"tG4kwbQFLdag","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639704736612,"user_tz":300,"elapsed":5058615,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"}},"outputId":"8f84dc45-e076-44e4-eabd-b871bfc8bdda"},"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate 0.00010, batch size 32, node size 128, kernal size 5\n","epoch 1, loss 131.788, train acc 44.69%, valid acc 62.34%, test acc 61.55%\n","epoch 2, loss 126.685, train acc 64.70%, valid acc 66.15%, test acc 64.51%\n","epoch 3, loss 124.338, train acc 72.52%, valid acc 74.58%, test acc 70.51%\n","epoch 4, loss 123.346, train acc 75.46%, valid acc 75.32%, test acc 71.97%\n","epoch 5, loss 122.963, train acc 76.79%, valid acc 75.32%, test acc 73.43%\n","epoch 6, loss 122.690, train acc 77.71%, valid acc 76.55%, test acc 73.40%\n","epoch 7, loss 122.560, train acc 78.32%, valid acc 76.68%, test acc 73.33%\n","epoch 8, loss 121.311, train acc 82.32%, valid acc 88.58%, test acc 85.95%\n","epoch 9, loss 119.005, train acc 90.19%, valid acc 90.55%, test acc 85.71%\n","epoch 10, loss 118.534, train acc 91.63%, valid acc 91.16%, test acc 85.37%\n","epoch 11, loss 118.157, train acc 92.74%, valid acc 90.41%, test acc 86.19%\n","epoch 12, loss 117.870, train acc 93.78%, valid acc 93.07%, test acc 87.34%\n","epoch 13, loss 117.767, train acc 94.03%, valid acc 93.00%, test acc 87.31%\n","epoch 14, loss 117.695, train acc 94.22%, valid acc 93.07%, test acc 87.41%\n","epoch 15, loss 117.548, train acc 94.68%, valid acc 93.07%, test acc 87.44%\n","epoch 16, loss 117.579, train acc 94.63%, valid acc 92.59%, test acc 87.65%\n","epoch 17, loss 117.403, train acc 95.17%, valid acc 92.73%, test acc 88.70%\n","epoch 18, loss 117.313, train acc 95.46%, valid acc 93.61%, test acc 88.46%\n","epoch 19, loss 117.262, train acc 95.65%, valid acc 94.22%, test acc 89.82%\n","epoch 20, loss 117.288, train acc 95.54%, valid acc 93.75%, test acc 88.36%\n","epoch 21, loss 117.161, train acc 95.90%, valid acc 93.81%, test acc 89.51%\n","epoch 22, loss 117.241, train acc 95.72%, valid acc 94.02%, test acc 88.87%\n","epoch 23, loss 117.170, train acc 95.97%, valid acc 93.88%, test acc 89.04%\n","epoch 24, loss 117.180, train acc 95.97%, valid acc 93.75%, test acc 89.41%\n","epoch 25, loss 117.190, train acc 95.85%, valid acc 93.47%, test acc 88.09%\n","epoch 26, loss 117.144, train acc 96.04%, valid acc 93.81%, test acc 89.07%\n","epoch 27, loss 117.061, train acc 96.24%, valid acc 92.39%, test acc 87.72%\n","epoch 28, loss 117.122, train acc 95.99%, valid acc 93.61%, test acc 89.14%\n","epoch 29, loss 117.108, train acc 95.99%, valid acc 93.95%, test acc 89.68%\n","epoch 30, loss 117.122, train acc 96.02%, valid acc 94.83%, test acc 90.26%\n","epoch 31, loss 117.033, train acc 96.34%, valid acc 94.77%, test acc 89.89%\n","epoch 32, loss 117.112, train acc 96.11%, valid acc 94.22%, test acc 89.07%\n","epoch 33, loss 117.091, train acc 96.19%, valid acc 93.95%, test acc 89.07%\n","epoch 34, loss 117.009, train acc 96.38%, valid acc 94.36%, test acc 90.30%\n","epoch 35, loss 116.994, train acc 96.43%, valid acc 92.66%, test acc 89.72%\n","epoch 36, loss 117.075, train acc 96.19%, valid acc 94.49%, test acc 89.96%\n","epoch 37, loss 117.161, train acc 95.92%, valid acc 93.95%, test acc 89.55%\n","epoch 38, loss 117.163, train acc 95.83%, valid acc 94.09%, test acc 90.06%\n","epoch 39, loss 117.029, train acc 96.33%, valid acc 94.22%, test acc 89.96%\n","epoch 40, loss 117.091, train acc 96.14%, valid acc 94.43%, test acc 89.72%\n","epoch 41, loss 117.042, train acc 96.31%, valid acc 94.29%, test acc 89.41%\n","epoch 42, loss 116.993, train acc 96.45%, valid acc 94.09%, test acc 88.46%\n","epoch 43, loss 116.997, train acc 96.41%, valid acc 94.43%, test acc 89.48%\n","epoch 44, loss 117.035, train acc 96.28%, valid acc 94.29%, test acc 88.80%\n","epoch 45, loss 116.937, train acc 96.63%, valid acc 94.22%, test acc 89.48%\n","epoch 46, loss 116.975, train acc 96.46%, valid acc 94.77%, test acc 90.02%\n","epoch 47, loss 117.125, train acc 95.99%, valid acc 93.75%, test acc 88.90%\n","epoch 48, loss 117.220, train acc 95.68%, valid acc 94.36%, test acc 89.07%\n","epoch 49, loss 117.241, train acc 95.61%, valid acc 93.68%, test acc 89.18%\n","epoch 50, loss 117.000, train acc 96.46%, valid acc 94.77%, test acc 90.53%\n","epoch 51, loss 117.063, train acc 96.12%, valid acc 94.70%, test acc 89.92%\n","epoch 52, loss 116.920, train acc 96.65%, valid acc 94.56%, test acc 90.57%\n","epoch 53, loss 116.907, train acc 96.72%, valid acc 94.83%, test acc 90.13%\n","epoch 54, loss 116.926, train acc 96.67%, valid acc 93.68%, test acc 89.41%\n","epoch 55, loss 117.015, train acc 96.41%, valid acc 93.88%, test acc 90.13%\n","epoch 56, loss 117.026, train acc 96.29%, valid acc 94.22%, test acc 89.85%\n","epoch 57, loss 117.011, train acc 96.38%, valid acc 94.22%, test acc 90.97%\n","epoch 58, loss 117.022, train acc 96.34%, valid acc 94.15%, test acc 90.50%\n","epoch 59, loss 116.963, train acc 96.51%, valid acc 94.56%, test acc 90.09%\n","epoch 60, loss 117.037, train acc 96.29%, valid acc 94.49%, test acc 90.23%\n","epoch 61, loss 117.015, train acc 96.33%, valid acc 94.15%, test acc 88.80%\n","epoch 62, loss 116.977, train acc 96.48%, valid acc 94.36%, test acc 90.77%\n","epoch 63, loss 116.932, train acc 96.60%, valid acc 94.29%, test acc 89.51%\n","epoch 64, loss 116.889, train acc 96.79%, valid acc 94.77%, test acc 90.77%\n","epoch 65, loss 116.903, train acc 96.72%, valid acc 94.70%, test acc 90.46%\n","epoch 66, loss 116.873, train acc 96.84%, valid acc 94.83%, test acc 90.23%\n","epoch 67, loss 117.002, train acc 96.38%, valid acc 94.22%, test acc 89.55%\n","epoch 68, loss 116.904, train acc 96.72%, valid acc 94.77%, test acc 89.92%\n","epoch 69, loss 116.986, train acc 96.45%, valid acc 93.54%, test acc 89.92%\n","epoch 70, loss 116.917, train acc 96.70%, valid acc 94.43%, test acc 89.48%\n","epoch 71, loss 116.943, train acc 96.60%, valid acc 94.02%, test acc 88.97%\n","epoch 72, loss 116.957, train acc 96.53%, valid acc 94.02%, test acc 90.80%\n","epoch 73, loss 116.890, train acc 96.80%, valid acc 94.15%, test acc 89.92%\n","epoch 74, loss 116.875, train acc 96.79%, valid acc 94.49%, test acc 90.50%\n","epoch 75, loss 116.933, train acc 96.60%, valid acc 94.29%, test acc 90.74%\n","epoch 76, loss 116.982, train acc 96.48%, valid acc 94.36%, test acc 90.80%\n","epoch 77, loss 116.868, train acc 96.84%, valid acc 93.68%, test acc 90.13%\n","epoch 78, loss 116.884, train acc 96.80%, valid acc 94.36%, test acc 90.36%\n","epoch 79, loss 116.919, train acc 96.65%, valid acc 94.49%, test acc 89.89%\n","epoch 80, loss 116.978, train acc 96.46%, valid acc 94.43%, test acc 90.50%\n","epoch 81, loss 116.804, train acc 96.99%, valid acc 94.36%, test acc 89.28%\n","epoch 82, loss 116.885, train acc 96.74%, valid acc 94.56%, test acc 89.72%\n","epoch 83, loss 116.831, train acc 96.97%, valid acc 94.49%, test acc 91.08%\n","epoch 84, loss 116.935, train acc 96.57%, valid acc 94.90%, test acc 90.06%\n","epoch 85, loss 116.925, train acc 96.60%, valid acc 94.49%, test acc 90.50%\n","epoch 86, loss 116.851, train acc 96.99%, valid acc 94.70%, test acc 89.89%\n","epoch 87, loss 116.716, train acc 97.33%, valid acc 94.49%, test acc 89.82%\n","epoch 88, loss 116.745, train acc 97.26%, valid acc 94.90%, test acc 90.84%\n","epoch 89, loss 116.768, train acc 97.14%, valid acc 94.90%, test acc 90.87%\n","epoch 90, loss 116.787, train acc 97.08%, valid acc 94.83%, test acc 90.91%\n","epoch 91, loss 116.810, train acc 97.01%, valid acc 94.49%, test acc 90.70%\n","epoch 92, loss 116.779, train acc 97.09%, valid acc 94.43%, test acc 90.36%\n","epoch 93, loss 116.745, train acc 97.21%, valid acc 94.49%, test acc 90.91%\n","epoch 94, loss 116.748, train acc 97.23%, valid acc 94.83%, test acc 90.36%\n","epoch 95, loss 116.710, train acc 97.33%, valid acc 94.63%, test acc 90.60%\n","epoch 96, loss 116.672, train acc 97.52%, valid acc 94.43%, test acc 89.72%\n","epoch 97, loss 116.872, train acc 96.89%, valid acc 94.83%, test acc 89.65%\n","epoch 98, loss 116.828, train acc 96.97%, valid acc 94.36%, test acc 90.33%\n","epoch 99, loss 116.717, train acc 97.31%, valid acc 93.75%, test acc 89.14%\n","epoch 100, loss 116.766, train acc 97.11%, valid acc 94.49%, test acc 90.94%\n","epoch 101, loss 116.755, train acc 97.18%, valid acc 94.49%, test acc 91.18%\n","epoch 102, loss 116.747, train acc 97.19%, valid acc 94.43%, test acc 89.62%\n","epoch 103, loss 116.711, train acc 97.33%, valid acc 95.11%, test acc 91.28%\n","epoch 104, loss 116.817, train acc 96.94%, valid acc 94.49%, test acc 90.91%\n","epoch 105, loss 116.651, train acc 97.50%, valid acc 94.90%, test acc 89.75%\n","epoch 106, loss 116.758, train acc 97.18%, valid acc 94.63%, test acc 90.77%\n","epoch 107, loss 116.632, train acc 97.60%, valid acc 95.17%, test acc 91.14%\n","epoch 108, loss 116.642, train acc 97.60%, valid acc 94.90%, test acc 91.28%\n","epoch 109, loss 116.758, train acc 97.21%, valid acc 93.95%, test acc 90.02%\n","epoch 110, loss 116.832, train acc 96.94%, valid acc 94.49%, test acc 90.53%\n","epoch 111, loss 116.796, train acc 97.02%, valid acc 94.49%, test acc 90.36%\n","epoch 112, loss 116.777, train acc 97.14%, valid acc 93.47%, test acc 88.97%\n","epoch 113, loss 116.700, train acc 97.40%, valid acc 94.22%, test acc 90.40%\n","epoch 114, loss 116.635, train acc 97.60%, valid acc 94.97%, test acc 90.23%\n","epoch 115, loss 116.667, train acc 97.45%, valid acc 94.70%, test acc 90.06%\n","epoch 116, loss 116.636, train acc 97.60%, valid acc 94.83%, test acc 90.94%\n","epoch 117, loss 116.673, train acc 97.45%, valid acc 94.49%, test acc 90.67%\n","epoch 118, loss 116.631, train acc 97.59%, valid acc 94.77%, test acc 89.51%\n","epoch 119, loss 116.709, train acc 97.33%, valid acc 94.63%, test acc 89.62%\n","epoch 120, loss 116.943, train acc 96.57%, valid acc 93.61%, test acc 89.62%\n","epoch 121, loss 116.733, train acc 97.25%, valid acc 94.43%, test acc 90.13%\n","epoch 122, loss 116.768, train acc 97.18%, valid acc 95.11%, test acc 90.40%\n","epoch 123, loss 116.779, train acc 97.13%, valid acc 94.97%, test acc 90.67%\n","epoch 124, loss 116.629, train acc 97.64%, valid acc 95.24%, test acc 91.11%\n","epoch 125, loss 116.638, train acc 97.62%, valid acc 94.49%, test acc 90.74%\n","epoch 126, loss 116.659, train acc 97.48%, valid acc 95.04%, test acc 90.43%\n","epoch 127, loss 116.647, train acc 97.52%, valid acc 94.77%, test acc 91.04%\n","epoch 128, loss 116.673, train acc 97.43%, valid acc 94.43%, test acc 89.82%\n","epoch 129, loss 116.679, train acc 97.43%, valid acc 94.56%, test acc 90.63%\n","epoch 130, loss 116.616, train acc 97.67%, valid acc 94.43%, test acc 91.28%\n","epoch 131, loss 116.803, train acc 97.04%, valid acc 94.83%, test acc 90.16%\n","epoch 132, loss 116.658, train acc 97.53%, valid acc 94.77%, test acc 90.57%\n","epoch 133, loss 116.691, train acc 97.42%, valid acc 94.77%, test acc 90.77%\n","epoch 134, loss 116.760, train acc 97.16%, valid acc 94.70%, test acc 89.04%\n","epoch 135, loss 116.845, train acc 96.89%, valid acc 94.77%, test acc 91.04%\n","epoch 136, loss 116.626, train acc 97.62%, valid acc 94.77%, test acc 90.91%\n","epoch 137, loss 116.645, train acc 97.59%, valid acc 94.77%, test acc 90.91%\n","epoch 138, loss 116.615, train acc 97.67%, valid acc 94.43%, test acc 90.33%\n","epoch 139, loss 116.631, train acc 97.67%, valid acc 94.90%, test acc 90.94%\n","epoch 140, loss 116.621, train acc 97.64%, valid acc 94.77%, test acc 91.11%\n","epoch 141, loss 116.634, train acc 97.57%, valid acc 94.83%, test acc 90.91%\n","epoch 142, loss 116.574, train acc 97.79%, valid acc 94.83%, test acc 91.04%\n","epoch 143, loss 116.556, train acc 97.82%, valid acc 95.17%, test acc 91.11%\n","epoch 144, loss 116.638, train acc 97.60%, valid acc 94.77%, test acc 90.26%\n","epoch 145, loss 116.611, train acc 97.70%, valid acc 94.90%, test acc 90.97%\n","epoch 146, loss 116.543, train acc 97.91%, valid acc 94.22%, test acc 89.92%\n","epoch 147, loss 116.634, train acc 97.57%, valid acc 94.49%, test acc 90.43%\n","epoch 148, loss 116.691, train acc 97.43%, valid acc 93.95%, test acc 90.02%\n","epoch 149, loss 116.613, train acc 97.65%, valid acc 94.90%, test acc 91.01%\n","epoch 150, loss 116.567, train acc 97.81%, valid acc 94.90%, test acc 90.80%\n"]}],"source":["TYPE = 'l1_group_lasso'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OunIW7B2LjvZ","executionInfo":{"status":"ok","timestamp":1639711114749,"user_tz":300,"elapsed":5059570,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"}},"outputId":"8918db98-e3ff-43c0-ff4a-d8ac92126946"},"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate 0.00015, batch size 32, node size 128, kernal size 5\n","epoch 1, loss 130.469, train acc 49.04%, valid acc 72.33%, test acc 69.12%\n","epoch 2, loss 124.098, train acc 73.18%, valid acc 76.07%, test acc 74.01%\n","epoch 3, loss 122.659, train acc 78.10%, valid acc 79.88%, test acc 75.60%\n","epoch 4, loss 121.740, train acc 81.14%, valid acc 80.90%, test acc 77.16%\n","epoch 5, loss 120.759, train acc 84.19%, valid acc 85.11%, test acc 81.10%\n","epoch 6, loss 119.400, train acc 88.71%, valid acc 88.51%, test acc 82.46%\n","epoch 7, loss 118.970, train acc 89.97%, valid acc 91.03%, test acc 85.51%\n","epoch 8, loss 118.432, train acc 91.82%, valid acc 88.92%, test acc 84.56%\n","epoch 9, loss 118.192, train acc 92.54%, valid acc 91.84%, test acc 86.83%\n","epoch 10, loss 117.975, train acc 93.30%, valid acc 91.98%, test acc 87.41%\n","epoch 11, loss 117.964, train acc 93.39%, valid acc 92.93%, test acc 87.61%\n","epoch 12, loss 117.899, train acc 93.49%, valid acc 92.93%, test acc 87.00%\n","epoch 13, loss 117.677, train acc 94.25%, valid acc 92.66%, test acc 86.09%\n","epoch 14, loss 117.598, train acc 94.41%, valid acc 93.61%, test acc 87.75%\n","epoch 15, loss 117.510, train acc 94.76%, valid acc 92.66%, test acc 87.99%\n","epoch 16, loss 117.446, train acc 94.97%, valid acc 93.07%, test acc 87.95%\n","epoch 17, loss 117.524, train acc 94.75%, valid acc 89.80%, test acc 86.87%\n","epoch 18, loss 117.503, train acc 94.75%, valid acc 92.93%, test acc 87.38%\n","epoch 19, loss 117.475, train acc 94.76%, valid acc 93.13%, test acc 87.89%\n","epoch 20, loss 117.356, train acc 95.26%, valid acc 93.61%, test acc 88.33%\n","epoch 21, loss 117.261, train acc 95.49%, valid acc 92.52%, test acc 88.56%\n","epoch 22, loss 117.267, train acc 95.56%, valid acc 93.88%, test acc 88.46%\n","epoch 23, loss 117.312, train acc 95.43%, valid acc 93.41%, test acc 89.07%\n","epoch 24, loss 117.394, train acc 95.14%, valid acc 93.68%, test acc 87.92%\n","epoch 25, loss 117.222, train acc 95.68%, valid acc 92.05%, test acc 88.36%\n","epoch 26, loss 117.383, train acc 95.12%, valid acc 93.54%, test acc 89.31%\n","epoch 27, loss 117.134, train acc 95.97%, valid acc 93.88%, test acc 88.97%\n","epoch 28, loss 117.317, train acc 95.34%, valid acc 93.88%, test acc 88.94%\n","epoch 29, loss 117.408, train acc 95.07%, valid acc 92.79%, test acc 88.12%\n","epoch 30, loss 117.335, train acc 95.24%, valid acc 93.47%, test acc 89.18%\n","epoch 31, loss 117.264, train acc 95.56%, valid acc 93.34%, test acc 89.45%\n","epoch 32, loss 117.308, train acc 95.34%, valid acc 93.61%, test acc 88.50%\n","epoch 33, loss 117.227, train acc 95.70%, valid acc 93.54%, test acc 87.82%\n","epoch 34, loss 117.300, train acc 95.39%, valid acc 93.27%, test acc 88.77%\n","epoch 35, loss 117.094, train acc 96.07%, valid acc 94.09%, test acc 88.90%\n","epoch 36, loss 117.230, train acc 95.60%, valid acc 94.09%, test acc 89.51%\n","epoch 37, loss 117.170, train acc 95.82%, valid acc 94.22%, test acc 89.48%\n","epoch 38, loss 117.075, train acc 96.17%, valid acc 94.02%, test acc 88.63%\n","epoch 39, loss 117.220, train acc 95.65%, valid acc 93.75%, test acc 88.80%\n","epoch 40, loss 117.223, train acc 95.58%, valid acc 93.00%, test acc 88.26%\n","epoch 41, loss 117.061, train acc 96.19%, valid acc 94.22%, test acc 90.06%\n","epoch 42, loss 117.101, train acc 96.11%, valid acc 93.61%, test acc 89.85%\n","epoch 43, loss 117.064, train acc 96.16%, valid acc 93.54%, test acc 90.13%\n","epoch 44, loss 117.089, train acc 96.07%, valid acc 94.22%, test acc 89.58%\n","epoch 45, loss 116.972, train acc 96.51%, valid acc 94.22%, test acc 89.89%\n","epoch 46, loss 116.957, train acc 96.55%, valid acc 94.09%, test acc 90.13%\n","epoch 47, loss 116.930, train acc 96.58%, valid acc 94.70%, test acc 90.30%\n","epoch 48, loss 116.943, train acc 96.51%, valid acc 94.36%, test acc 88.94%\n","epoch 49, loss 116.866, train acc 96.89%, valid acc 94.43%, test acc 90.13%\n","epoch 50, loss 116.933, train acc 96.57%, valid acc 94.36%, test acc 89.35%\n","epoch 51, loss 117.037, train acc 96.24%, valid acc 94.56%, test acc 89.65%\n","epoch 52, loss 117.087, train acc 96.14%, valid acc 94.02%, test acc 89.31%\n","epoch 53, loss 116.921, train acc 96.74%, valid acc 94.36%, test acc 90.63%\n","epoch 54, loss 116.883, train acc 96.75%, valid acc 93.88%, test acc 88.39%\n","epoch 55, loss 116.998, train acc 96.38%, valid acc 94.29%, test acc 89.99%\n","epoch 56, loss 117.030, train acc 96.28%, valid acc 93.68%, test acc 89.62%\n","epoch 57, loss 116.940, train acc 96.62%, valid acc 92.66%, test acc 86.97%\n","epoch 58, loss 116.917, train acc 96.68%, valid acc 93.95%, test acc 88.84%\n","epoch 59, loss 116.962, train acc 96.51%, valid acc 93.95%, test acc 89.85%\n","epoch 60, loss 116.844, train acc 96.89%, valid acc 94.09%, test acc 89.89%\n","epoch 61, loss 116.827, train acc 96.94%, valid acc 94.36%, test acc 89.62%\n","epoch 62, loss 116.810, train acc 96.97%, valid acc 94.29%, test acc 89.99%\n","epoch 63, loss 116.891, train acc 96.74%, valid acc 94.09%, test acc 89.48%\n","epoch 64, loss 117.194, train acc 95.82%, valid acc 92.73%, test acc 87.41%\n","epoch 65, loss 116.944, train acc 96.51%, valid acc 93.81%, test acc 89.96%\n","epoch 66, loss 117.059, train acc 96.17%, valid acc 94.22%, test acc 90.40%\n","epoch 67, loss 116.994, train acc 96.40%, valid acc 94.09%, test acc 89.35%\n","epoch 68, loss 116.952, train acc 96.53%, valid acc 94.15%, test acc 90.09%\n","epoch 69, loss 116.937, train acc 96.62%, valid acc 94.29%, test acc 89.31%\n","epoch 70, loss 116.824, train acc 96.96%, valid acc 94.97%, test acc 90.30%\n","epoch 71, loss 116.808, train acc 96.97%, valid acc 95.04%, test acc 89.35%\n","epoch 72, loss 116.729, train acc 97.26%, valid acc 95.04%, test acc 90.77%\n","epoch 73, loss 116.740, train acc 97.21%, valid acc 95.04%, test acc 90.60%\n","epoch 74, loss 116.708, train acc 97.38%, valid acc 94.77%, test acc 90.33%\n","epoch 75, loss 116.761, train acc 97.14%, valid acc 94.90%, test acc 90.67%\n","epoch 76, loss 116.816, train acc 96.97%, valid acc 94.77%, test acc 90.43%\n","epoch 77, loss 116.778, train acc 97.09%, valid acc 94.15%, test acc 90.63%\n","epoch 78, loss 116.826, train acc 96.91%, valid acc 94.56%, test acc 89.65%\n","epoch 79, loss 116.902, train acc 96.65%, valid acc 93.20%, test acc 90.67%\n","epoch 80, loss 116.798, train acc 97.01%, valid acc 95.04%, test acc 89.85%\n","epoch 81, loss 116.704, train acc 97.33%, valid acc 95.24%, test acc 90.40%\n","epoch 82, loss 116.719, train acc 97.35%, valid acc 93.41%, test acc 88.26%\n","epoch 83, loss 117.183, train acc 95.77%, valid acc 94.29%, test acc 89.35%\n","epoch 84, loss 116.934, train acc 96.62%, valid acc 93.88%, test acc 89.41%\n","epoch 85, loss 116.893, train acc 96.74%, valid acc 94.49%, test acc 90.23%\n","epoch 86, loss 116.807, train acc 96.99%, valid acc 94.15%, test acc 89.72%\n","epoch 87, loss 116.865, train acc 96.77%, valid acc 94.49%, test acc 89.14%\n","epoch 88, loss 116.759, train acc 97.16%, valid acc 94.29%, test acc 90.19%\n","epoch 89, loss 116.632, train acc 97.59%, valid acc 94.77%, test acc 90.33%\n","epoch 90, loss 116.601, train acc 97.69%, valid acc 95.11%, test acc 89.68%\n","epoch 91, loss 116.625, train acc 97.60%, valid acc 94.90%, test acc 90.02%\n","epoch 92, loss 116.607, train acc 97.67%, valid acc 94.49%, test acc 89.72%\n","epoch 93, loss 116.823, train acc 96.92%, valid acc 93.00%, test acc 88.39%\n","epoch 94, loss 116.864, train acc 96.85%, valid acc 93.68%, test acc 89.11%\n","epoch 95, loss 116.792, train acc 97.02%, valid acc 94.90%, test acc 89.99%\n","epoch 96, loss 116.829, train acc 96.96%, valid acc 94.97%, test acc 89.62%\n","epoch 97, loss 116.808, train acc 97.01%, valid acc 94.77%, test acc 89.07%\n","epoch 98, loss 116.655, train acc 97.50%, valid acc 94.83%, test acc 89.65%\n","epoch 99, loss 116.965, train acc 96.45%, valid acc 94.22%, test acc 89.68%\n","epoch 100, loss 116.643, train acc 97.53%, valid acc 94.70%, test acc 90.63%\n","epoch 101, loss 116.614, train acc 97.64%, valid acc 94.36%, test acc 90.50%\n","epoch 102, loss 116.627, train acc 97.59%, valid acc 95.04%, test acc 90.53%\n","epoch 103, loss 116.644, train acc 97.55%, valid acc 95.31%, test acc 90.74%\n","epoch 104, loss 116.639, train acc 97.53%, valid acc 95.11%, test acc 90.36%\n","epoch 105, loss 116.567, train acc 97.79%, valid acc 95.17%, test acc 90.70%\n","epoch 106, loss 116.651, train acc 97.50%, valid acc 94.90%, test acc 90.77%\n","epoch 107, loss 116.610, train acc 97.69%, valid acc 94.63%, test acc 90.06%\n","epoch 108, loss 116.667, train acc 97.45%, valid acc 94.22%, test acc 89.45%\n","epoch 109, loss 116.644, train acc 97.52%, valid acc 94.83%, test acc 90.46%\n","epoch 110, loss 116.593, train acc 97.72%, valid acc 94.56%, test acc 89.11%\n","epoch 111, loss 116.537, train acc 97.87%, valid acc 94.43%, test acc 89.85%\n","epoch 112, loss 116.577, train acc 97.74%, valid acc 94.83%, test acc 90.67%\n","epoch 113, loss 116.727, train acc 97.26%, valid acc 94.43%, test acc 88.80%\n","epoch 114, loss 116.704, train acc 97.33%, valid acc 94.15%, test acc 89.48%\n","epoch 115, loss 116.632, train acc 97.59%, valid acc 94.70%, test acc 89.58%\n","epoch 116, loss 116.651, train acc 97.48%, valid acc 94.77%, test acc 89.72%\n","epoch 117, loss 116.628, train acc 97.59%, valid acc 95.04%, test acc 89.62%\n","epoch 118, loss 116.776, train acc 97.11%, valid acc 94.02%, test acc 90.50%\n","epoch 119, loss 117.040, train acc 96.24%, valid acc 93.68%, test acc 88.60%\n","epoch 120, loss 116.805, train acc 97.02%, valid acc 94.83%, test acc 88.87%\n","epoch 121, loss 116.742, train acc 97.23%, valid acc 93.75%, test acc 88.77%\n","epoch 122, loss 116.738, train acc 97.26%, valid acc 94.15%, test acc 90.36%\n","epoch 123, loss 116.637, train acc 97.59%, valid acc 94.77%, test acc 90.80%\n","epoch 124, loss 116.586, train acc 97.74%, valid acc 94.22%, test acc 90.43%\n","epoch 125, loss 116.588, train acc 97.72%, valid acc 94.29%, test acc 89.85%\n","epoch 126, loss 116.717, train acc 97.33%, valid acc 93.13%, test acc 89.82%\n","epoch 127, loss 116.972, train acc 96.40%, valid acc 94.22%, test acc 89.31%\n","epoch 128, loss 116.679, train acc 97.38%, valid acc 94.70%, test acc 90.02%\n","epoch 129, loss 116.828, train acc 96.91%, valid acc 93.61%, test acc 90.19%\n","epoch 130, loss 116.779, train acc 97.08%, valid acc 94.09%, test acc 88.60%\n","epoch 131, loss 116.587, train acc 97.72%, valid acc 94.29%, test acc 90.16%\n","epoch 132, loss 116.574, train acc 97.77%, valid acc 94.56%, test acc 90.16%\n","epoch 133, loss 116.592, train acc 97.65%, valid acc 95.38%, test acc 89.75%\n","epoch 134, loss 116.596, train acc 97.69%, valid acc 94.97%, test acc 90.36%\n","epoch 135, loss 116.578, train acc 97.76%, valid acc 94.77%, test acc 90.53%\n","epoch 136, loss 116.540, train acc 97.87%, valid acc 94.77%, test acc 90.67%\n","epoch 137, loss 116.516, train acc 97.98%, valid acc 94.77%, test acc 90.63%\n","epoch 138, loss 116.616, train acc 97.64%, valid acc 94.09%, test acc 88.60%\n","epoch 139, loss 116.633, train acc 97.53%, valid acc 93.20%, test acc 88.26%\n","epoch 140, loss 116.721, train acc 97.30%, valid acc 94.49%, test acc 89.45%\n","epoch 141, loss 116.676, train acc 97.42%, valid acc 94.49%, test acc 89.65%\n","epoch 142, loss 116.693, train acc 97.36%, valid acc 94.15%, test acc 89.55%\n","epoch 143, loss 116.649, train acc 97.52%, valid acc 94.22%, test acc 89.79%\n","epoch 144, loss 116.515, train acc 97.96%, valid acc 94.83%, test acc 90.40%\n","epoch 145, loss 116.518, train acc 97.96%, valid acc 94.90%, test acc 90.50%\n","epoch 146, loss 116.740, train acc 97.23%, valid acc 94.83%, test acc 89.21%\n","epoch 147, loss 116.531, train acc 97.91%, valid acc 95.04%, test acc 90.60%\n","epoch 148, loss 116.493, train acc 98.04%, valid acc 95.45%, test acc 90.43%\n","epoch 149, loss 116.518, train acc 97.94%, valid acc 95.11%, test acc 90.26%\n","epoch 150, loss 116.516, train acc 97.93%, valid acc 95.31%, test acc 90.53%\n","[49.03927903417786, 73.18483251147764, 78.09896276143513, 81.14266281244686, 84.1863628634586, 88.70940316272743, 89.96769256929093, 91.82111885733718, 92.53528311511647, 93.30045910559429, 93.38547866009182, 93.48750212548886, 94.25267811596667, 94.40571331406224, 94.76279544295188, 94.96684237374596, 94.74579153205237, 94.74579153205237, 94.76279544295188, 95.25590885903758, 95.49396361163068, 95.5619792552287, 95.42594796803265, 95.13688148274103, 95.68100663152525, 95.11987757184153, 95.97007311681686, 95.34092841353511, 95.068865839143, 95.23890494813807, 95.5619792552287, 95.34092841353511, 95.69801054242475, 95.39194014623364, 96.0720965822139, 95.59598707702771, 95.81703791872131, 96.17412004761096, 95.64699880972624, 95.57898316612821, 96.19112395851046, 96.10610440401292, 96.15711613671144, 96.0720965822139, 96.5141982656011, 96.5482060874001, 96.58221390919911, 96.5141982656011, 96.88828430539024, 96.56520999829961, 96.24213569120897, 96.14011222581193, 96.73524910729468, 96.75225301819418, 96.37816697840503, 96.276143513008, 96.61622173099813, 96.68423737459615, 96.5141982656011, 96.88828430539024, 96.93929603808876, 96.97330385988778, 96.73524910729468, 95.81703791872131, 96.5141982656011, 96.17412004761096, 96.39517088930454, 96.5312021765006, 96.61622173099813, 96.95629994898827, 96.97330385988778, 97.26237034517939, 97.21135861248086, 97.38139772147593, 97.14334296888285, 96.97330385988778, 97.09233123618432, 96.90528821628975, 96.65022955279714, 97.00731168168679, 97.33038598877742, 97.34738989967693, 95.76602618602278, 96.61622173099813, 96.73524910729468, 96.99030777078728, 96.76925692909369, 97.16034687978235, 97.58544465227003, 97.68746811766707, 97.60244856316953, 97.67046420676756, 96.92229212718925, 96.85427648359122, 97.02431559258629, 96.95629994898827, 97.00731168168679, 97.50042509777249, 96.44618262200306, 97.5344329195715, 97.63645638496854, 97.58544465227003, 97.551436830471, 97.5344329195715, 97.7894915830641, 97.50042509777249, 97.68746811766707, 97.44941336507397, 97.517429008672, 97.72147593946607, 97.87451113756164, 97.73847985036558, 97.26237034517939, 97.33038598877742, 97.58544465227003, 97.48342118687297, 97.58544465227003, 97.10933514708383, 96.24213569120897, 97.02431559258629, 97.22836252338038, 97.26237034517939, 97.58544465227003, 97.73847985036558, 97.72147593946607, 97.33038598877742, 96.39517088930454, 97.38139772147593, 96.90528821628975, 97.07532732528482, 97.72147593946607, 97.7724876721646, 97.65346029586804, 97.68746811766707, 97.7554837612651, 97.87451113756164, 97.97653460295868, 97.63645638496854, 97.5344329195715, 97.2963781669784, 97.41540554327496, 97.36439381057643, 97.517429008672, 97.95953069205918, 97.95953069205918, 97.22836252338038, 97.90851895936065, 98.04455024655671, 97.94252678115967, 97.92552287026015]\n","[72.33174711080898, 76.07070020394289, 79.87763426240653, 80.89734874235214, 85.11216859279402, 88.5112168592794, 91.02651257647858, 88.91910265125765, 91.84228416043509, 91.97824609109449, 92.9299796057104, 92.9299796057104, 92.65805574439158, 93.60978925900748, 92.65805574439158, 93.06594153636982, 89.80285520054385, 92.9299796057104, 93.13392250169953, 93.60978925900748, 92.52209381373216, 93.88171312032631, 93.40584636301836, 93.67777022433718, 92.0462270564242, 93.54180829367778, 93.88171312032631, 93.88171312032631, 92.79401767505098, 93.47382732834807, 93.33786539768865, 93.60978925900748, 93.54180829367778, 93.26988443235894, 94.08565601631543, 94.08565601631543, 94.22161794697485, 94.01767505098573, 93.74575118966689, 92.99796057104011, 94.22161794697485, 93.60978925900748, 93.54180829367778, 94.22161794697485, 94.22161794697485, 94.08565601631543, 94.6974847042828, 94.35757987763427, 94.42556084296398, 94.35757987763427, 94.56152277362338, 94.01767505098573, 94.35757987763427, 93.88171312032631, 94.28959891230456, 93.67777022433718, 92.65805574439158, 93.94969408565602, 93.94969408565602, 94.08565601631543, 94.35757987763427, 94.28959891230456, 94.08565601631543, 92.72603670972128, 93.8137321549966, 94.22161794697485, 94.08565601631543, 94.15363698164514, 94.28959891230456, 94.96940856560163, 95.03738953093134, 95.03738953093134, 95.03738953093134, 94.76546566961251, 94.90142760027193, 94.76546566961251, 94.15363698164514, 94.56152277362338, 93.20190346702923, 95.03738953093134, 95.24133242692047, 93.40584636301836, 94.28959891230456, 93.88171312032631, 94.49354180829367, 94.15363698164514, 94.49354180829367, 94.28959891230456, 94.76546566961251, 95.10537049626105, 94.90142760027193, 94.49354180829367, 92.99796057104011, 93.67777022433718, 94.90142760027193, 94.96940856560163, 94.76546566961251, 94.83344663494222, 94.22161794697485, 94.6974847042828, 94.35757987763427, 95.03738953093134, 95.30931339225017, 95.10537049626105, 95.17335146159076, 94.90142760027193, 94.62950373895309, 94.22161794697485, 94.83344663494222, 94.56152277362338, 94.42556084296398, 94.83344663494222, 94.42556084296398, 94.15363698164514, 94.6974847042828, 94.76546566961251, 95.03738953093134, 94.01767505098573, 93.67777022433718, 94.83344663494222, 93.74575118966689, 94.15363698164514, 94.76546566961251, 94.22161794697485, 94.28959891230456, 93.13392250169953, 94.22161794697485, 94.6974847042828, 93.60978925900748, 94.08565601631543, 94.28959891230456, 94.56152277362338, 95.37729435757987, 94.96940856560163, 94.76546566961251, 94.76546566961251, 94.76546566961251, 94.08565601631543, 93.20190346702923, 94.49354180829367, 94.49354180829367, 94.15363698164514, 94.22161794697485, 94.83344663494222, 94.90142760027193, 94.83344663494222, 95.03738953093134, 95.44527532290958, 95.10537049626105, 95.30931339225017]\n","[69.12114014251782, 74.00746521886664, 75.60230743128605, 77.16321683067527, 81.09942314217848, 82.4567356633865, 85.5106888361045, 84.56057007125891, 86.83406854428232, 87.41092636579573, 87.61452324397692, 87.00373260943333, 86.08754665761792, 87.75025449609772, 87.98778418730913, 87.95385137427893, 86.86800135731252, 87.37699355276553, 87.88598574821853, 88.32711231761112, 88.56464200882253, 88.46284356973193, 89.07363420427554, 87.91991856124872, 88.36104513064133, 89.31116389548694, 88.97183576518493, 88.93790295215473, 88.12351543942992, 89.17543264336614, 89.44689514760773, 88.49677638276214, 87.81812012215812, 88.76823888700373, 88.90397013912454, 89.51476077366814, 89.48082796063794, 88.63250763488293, 88.80217170003394, 88.25924669155073, 90.05768578215134, 89.85408890397014, 90.12555140821173, 89.58262639972854, 89.88802171700034, 90.12555140821173, 90.29521547336275, 88.93790295215473, 90.12555140821173, 89.34509670851713, 89.65049202578894, 89.31116389548694, 90.63454360366474, 88.39497794367153, 89.98982015609094, 89.61655921275874, 86.96979979640312, 88.83610451306413, 89.85408890397014, 89.88802171700034, 89.61655921275874, 89.98982015609094, 89.48082796063794, 87.41092636579573, 89.95588734306074, 90.39701391245335, 89.34509670851713, 90.09161859518154, 89.31116389548694, 90.29521547336275, 89.34509670851713, 90.77027485578554, 90.60061079063455, 90.32914828639294, 90.66847641669494, 90.43094672548354, 90.63454360366474, 89.65049202578894, 90.66847641669494, 89.85408890397014, 90.39701391245335, 88.25924669155073, 89.34509670851713, 89.41296233457754, 90.22734984730234, 89.71835765184935, 89.14149983033593, 90.19341703427214, 90.32914828639294, 89.68442483881914, 90.02375296912113, 89.71835765184935, 88.39497794367153, 89.10756701730574, 89.98982015609094, 89.61655921275874, 89.07363420427554, 89.65049202578894, 89.68442483881914, 90.63454360366474, 90.49881235154395, 90.53274516457414, 90.73634204275534, 90.36308109942314, 90.70240922972515, 90.77027485578554, 90.05768578215134, 89.44689514760773, 90.46487953851374, 89.10756701730574, 89.85408890397014, 90.66847641669494, 88.80217170003394, 89.48082796063794, 89.58262639972854, 89.71835765184935, 89.61655921275874, 90.49881235154395, 88.59857482185274, 88.87003732609433, 88.76823888700373, 90.36308109942314, 90.80420766881575, 90.43094672548354, 89.85408890397014, 89.82015609093993, 89.31116389548694, 90.02375296912113, 90.19341703427214, 88.59857482185274, 90.15948422124194, 90.15948422124194, 89.75229046487954, 90.36308109942314, 90.53274516457414, 90.66847641669494, 90.63454360366474, 88.59857482185274, 88.25924669155073, 89.44689514760773, 89.65049202578894, 89.54869358669833, 89.78622327790974, 90.39701391245335, 90.49881235154395, 89.20936545639634, 90.60061079063455, 90.43094672548354, 90.26128266033254, 90.53274516457414]\n"]}],"source":["TYPE = 'l0_group_lasso'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)\n","print(train_acc)\n","print(valid_acc)\n","print(test_acc)\n","file_name = 'data'+str(k)+'.txt'\n","with open(file_name, 'w') as f:\n","    for i in train_acc:\n","      f.write(\"%f \" % i)\n","    f.write('\\n')\n","    for i in valid_acc:\n","      f.write(\"%f \" % i)\n","    f.write('\\n')\n","    for i in test_acc:\n","      f.write(\"%f \" % i)\n","    f.write('\\n')"]},{"cell_type":"markdown","metadata":{"id":"iJdjJI71Lwax"},"source":["## Results after Pruning the above Models"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8594,"status":"ok","timestamp":1639711717706,"user":{"displayName":"Shao Yubo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14299479550668088872"},"user_tz":300},"id":"Pql44kXZLw8B","outputId":"19b16926-dc74-40d8-ddf1-b0fcf758bd2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Here are the results for No penalty - 4 128 0.0001:\n","Accuracy of the network on the 2947 test data: 91.52 % before compression\n","Sparity for the compressed model: 18.68 %\n","Accuracy of the network on the 2947 test data: 89.21 % after compression\n","\n","Here are the results for l0 norm - 4 128 0.0001:\n","Accuracy of the network on the 2947 test data: 91.52 % before compression\n","Sparity for the compressed model: 18.68 %\n","Accuracy of the network on the 2947 test data: 89.21 % after compression\n","\n","Here are the results for l1 norm - 4 128 0.0001:\n","Accuracy of the network on the 2947 test data: 90.46 % before compression\n","Sparity for the compressed model: 18.17 %\n","Accuracy of the network on the 2947 test data: 88.06 % after compression\n","\n","Here are the results for l2 norm - 4 128 0.0001:\n","Accuracy of the network on the 2947 test data: 91.01 % before compression\n","Sparity for the compressed model: 18.94 %\n","Accuracy of the network on the 2947 test data: 89.24 % after compression\n","\n","Here are the results for group lasso - 4 128 0.0001:\n","Accuracy of the network on the 2947 test data: 90.80 % before compression\n","Sparity for the compressed model: 18.87 %\n","Accuracy of the network on the 2947 test data: 88.36 % after compression\n","\n","Here are the results for l1 group lasso - 4 128 0.0001:\n","Accuracy of the network on the 2947 test data: 91.11 % before compression\n","Sparity for the compressed model: 17.60 %\n","Accuracy of the network on the 2947 test data: 88.53 % after compression\n","\n","Here are the results for l0 group lasso - 4 128 0.0001 (BEST):\n","Accuracy of the network on the 2947 test data: 91.65 % before compression\n","Sparity for the compressed model: 16.81 %\n","Accuracy of the network on the 2947 test data: 89.21 % after compression\n","\n","Here are the results for l0 group lasso - 4 128 0.00005:\n","Accuracy of the network on the 2947 test data: 89.85 % before compression\n","Sparity for the compressed model: 12.60 %\n","Accuracy of the network on the 2947 test data: 81.51 % after compression\n","\n","Here are the results for l0 group lasso - 4 128 0.00015:\n","Accuracy of the network on the 2947 test data: 90.43 % before compression\n","Sparity for the compressed model: 25.33 %\n","Accuracy of the network on the 2947 test data: 89.58 % after compression\n","\n","Here are the results for l0 group lasso - 4 128 0.0002:\n","Accuracy of the network on the 2947 test data: 90.26 % before compression\n","Sparity for the compressed model: 23.70 %\n","Accuracy of the network on the 2947 test data: 89.45 % after compression\n","\n","Here are the results for l0 group lasso - 4 128 0.00001:\n","Accuracy of the network on the 2947 test data: 87.21 % before compression\n","Sparity for the compressed model: 9.48 %\n","Accuracy of the network on the 2947 test data: 50.02 % after compression\n","\n","Here are the results for l0 group lasso - 4 256 0.0001:\n","Accuracy of the network on the 2947 test data: 90.43 % before compression\n","Sparity for the compressed model: 8.12 %\n","Accuracy of the network on the 2947 test data: 88.87 % after compression\n","\n","Here are the results for l0 group lasso - 4 64 0.0001:\n","Accuracy of the network on the 2947 test data: 62.78 % before compression\n","Sparity for the compressed model: 38.23 %\n","Accuracy of the network on the 2947 test data: 62.47 % after compression\n","\n","Here are the results for l0 group lasso - 0 128 0.0001:\n","Accuracy of the network on the 2947 test data: 90.23 % before compression\n","Sparity for the compressed model: 19.13 %\n","Accuracy of the network on the 2947 test data: 87.82 % after compression\n","\n","Here are the results for l0 group lasso - 1 128 0.0001:\n","Accuracy of the network on the 2947 test data: 90.77 % before compression\n","Sparity for the compressed model: 18.77 %\n","Accuracy of the network on the 2947 test data: 89.24 % after compression\n","\n","Here are the results for l0 group lasso - 2 128 0.0001:\n","Accuracy of the network on the 2947 test data: 89.89 % before compression\n","Sparity for the compressed model: 18.60 %\n","Accuracy of the network on the 2947 test data: 87.21 % after compression\n","\n","Here are the results for l0 group lasso - 3 128 0.0001:\n","Accuracy of the network on the 2947 test data: 91.35 % before compression\n","Sparity for the compressed model: 19.84 %\n","Accuracy of the network on the 2947 test data: 88.84 % after compression\n","\n"]}],"source":["PRUNE_THRESHOLD = 0.04\n","\n","class ThresholdPruning(prune.BasePruningMethod):\n","    PRUNING_TYPE = \"unstructured\"\n","\n","    def __init__(self, threshold):\n","        self.threshold = threshold\n","\n","    def compute_mask(self, tensor, default_mask):\n","      return torch.abs(tensor) > self.threshold\n","\n","PATHS = {'No penalty - 4 128 0.0001':            PATH + '/model/final/lr0.0001/no_penalty4.ptl',\n","         'l0 norm - 4 128 0.0001':               PATH + '/model/final/lr0.0001/l0_norm4.ptl',\n","         'l1 norm - 4 128 0.0001':               PATH + '/model/final/lr0.0001/l1_norm4.ptl',\n","         'l2 norm - 4 128 0.0001':               PATH + '/model/final/lr0.0001/l2_norm4.ptl',\n","         'group lasso - 4 128 0.0001':           PATH + '/model/final/lr0.0001/group_lasso4.ptl',\n","         'l1 group lasso - 4 128 0.0001':        PATH + '/model/final/lr0.0001/l1_group_lasso4.ptl',\n","         'l0 group lasso - 4 128 0.0001 (BEST)': PATH + '/model/final/lr0.0001/l0_group_lasso4.ptl',\n","         'l0 group lasso - 4 128 0.00005':       PATH + '/model/final/lr0.00005/l0_group_lasso4.ptl',\n","         'l0 group lasso - 4 128 0.00015':       PATH + '/model/final/lr0.00015/l0_group_lasso4.ptl',\n","         'l0 group lasso - 4 128 0.0002':        PATH + '/model/final/lr0.0002/l0_group_lasso4.ptl',\n","         'l0 group lasso - 4 128 0.00001':       PATH + '/model/final/lr0.00001/l0_group_lasso4.ptl',\n","         'l0 group lasso - 4 256 0.0001':        PATH + '/model/final/256node/l0_group_lasso4.ptl',\n","         'l0 group lasso - 4 64 0.0001':         PATH + '/model/final/64node/l0_group_lasso4.ptl',\n","         'l0 group lasso - 0 128 0.0001':        PATH + '/model/final/lr0.0001/l0_group_lasso0.ptl',\n","         'l0 group lasso - 1 128 0.0001':        PATH + '/model/final/lr0.0001/l0_group_lasso1.ptl',\n","         'l0 group lasso - 2 128 0.0001':        PATH + '/model/final/lr0.0001/l0_group_lasso2.ptl',\n","         'l0 group lasso - 3 128 0.0001':        PATH + '/model/final/lr0.0001/l0_group_lasso3.ptl',\n","        }\n","\n","for name in PATHS:\n","  print('Here are the results for {}:'.format(name))\n","  # load the model\n","  net = torch.load(PATHS[name])\n","\n","  # display the results before compressed model\n","  test_correct = 0\n","  test_total = 0\n","  with torch.no_grad():\n","    for data in testloader:\n","      inputs, labels = data\n","      inputs, labels = inputs.cuda(0), labels.cuda(0)\n","      outputs = net(inputs)\n","      _, predicted = torch.max(outputs.data, 1)\n","      test_total += labels.size(0)\n","      test_correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n","    test_acc = 100 * test_correct / test_total\n","  print('Accuracy of the network on the %d test data: %.2f %% before compression' % (test_total, test_acc))\n","\n","  # prune the model\n","  parameters_to_prune = []\n","  for na, child in net.features.named_children():\n","    if int(na) % 2 == 0:\n","      parameters_to_prune.append((child, \"weight\"))\n","  if name == 'l0 group lasso 256':\n","    prune.global_unstructured(parameters_to_prune, pruning_method=ThresholdPruning, threshold=PRUNE_THRESHOLD)\n","  else:\n","    prune.global_unstructured(parameters_to_prune, pruning_method=ThresholdPruning, threshold=PRUNE_THRESHOLD)\n","\n","  # calculate the sparsity\n","  total_weight = 0\n","  total_nonzero = 0\n","  for na, child in net.features.named_children():\n","    if int(na) % 2 == 0:\n","      total_weight += torch.numel(child.weight)\n","      total_nonzero += torch.count_nonzero(child.weight)\n","  print('Sparity for the compressed model: %.2f %%' % (100*float(total_nonzero / total_weight)))\n","\n","  # display the results after compressed model\n","  test_correct = 0\n","  test_total = 0\n","  with torch.no_grad():\n","    for data in testloader:\n","      inputs, labels = data\n","      inputs, labels = inputs.cuda(0), labels.cuda(0)\n","      outputs = net(inputs)\n","      _, predicted = torch.max(outputs.data, 1)\n","      test_total += labels.size(0)\n","      test_correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n","    test_acc = 100 * test_correct / test_total\n","  print('Accuracy of the network on the %d test data: %.2f %% after compression\\n' % (test_total, test_acc))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"ucihar_dataset.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}