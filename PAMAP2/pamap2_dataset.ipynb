{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pamap2_dataset.ipynb","provenance":[],"collapsed_sections":["ZSWX9EHW97uU"],"machine_shape":"hm","authorship_tag":"ABX9TyPpSXI4HFMOlHpo68k4ozqb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"28xFqxTcxvpz"},"source":["## Connect Google Drive and GPU\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CexARwSGxGbm","executionInfo":{"status":"ok","timestamp":1639797366698,"user_tz":300,"elapsed":18882,"user":{"displayName":"Yubo Shao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18198364614828690729"}},"outputId":"2cb055d5-0e23-461d-a9bd-5222cb34af18"},"source":["%reset\n","\n","# connect google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# connect colab gpu\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n","Mounted at /content/drive\n","Sat Dec 18 03:16:05 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"P8kydhB6xzBa"},"source":["## Import Needed Libraries, Paramaters and Functions"]},{"cell_type":"code","metadata":{"id":"7lbyFQSnxylK","executionInfo":{"status":"ok","timestamp":1639797441775,"user_tz":300,"elapsed":6645,"user":{"displayName":"Yubo Shao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18198364614828690729"}}},"source":["import sys\n","import csv\n","import time\n","import os.path\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.nn.utils import prune\n","import torchvision\n","import matplotlib.pyplot as plt\n","from torch.utils.mobile_optimizer import optimize_for_mobile\n","from scipy import stats\n","from sklearn.utils import shuffle\n","\n","SEED = 10\n","WINDOW_SIZE = 128\n","FEATURE_SIZE = 40\n","LABEL_SIZE = 12\n","BATCH_SIZE = 3\n","PATH = '/content/drive/MyDrive/CNNPaper'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ca_WAZ8Qxdp3","executionInfo":{"status":"ok","timestamp":1639797442066,"user_tz":300,"elapsed":300,"user":{"displayName":"Yubo Shao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18198364614828690729"}}},"source":["def dataCleaning(dataCollection):\n","  dataCollection = dataCollection.drop(['handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4',\n","                      'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4',\n","                      'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4'],\n","                      axis = 1)  # removal of orientation columns as they are not needed\n","  dataCollection = dataCollection.drop(dataCollection[dataCollection.activityID == 0].index) #removal of any row of activity 0 as it is transient activity which it is not used\n","  dataCollection = dataCollection.apply(pd.to_numeric, errors = 'coerce') #removal of non numeric data in cells\n","  dataCollection = dataCollection.interpolate() #removal of any remaining NaN value cells by constructing new data points in known set of data points\n","  dataCollection.reset_index(drop = True, inplace = True)\n","  for i in range(0,4):\n","    dataCollection[\"heartrate\"].iloc[i]=100  \n","  return dataCollection\n","\n","def read_data():\n","  if os.path.isfile(PATH + '/data/PAMAP2/data.cvs'):\n","    print(\"Start reading data ...\")\n","    dataCollection = pd.read_csv(PATH + '/data/PAMAP2/data.cvs')\n","    print(\"Finish reading data ...\")\n","  else:\n","    print(\"Start reading data ...\")\n","    list_of_files = ['/data/PAMAP2/Protocol/subject101.dat',\n","              '/data/PAMAP2/Protocol/subject102.dat',\n","              '/data/PAMAP2/Protocol/subject103.dat',\n","              '/data/PAMAP2/Protocol/subject104.dat',\n","              '/data/PAMAP2/Protocol/subject105.dat',\n","              '/data/PAMAP2/Protocol/subject106.dat',\n","              '/data/PAMAP2/Protocol/subject107.dat',\n","              '/data/PAMAP2/Protocol/subject108.dat',\n","              '/data/PAMAP2/Protocol/subject109.dat' ]\n","    subjectID = [1,2,3,4,5,6,7,8,9]\n","    activityIDdict = {0: 'transient',\n","              1: 'lying',\n","              2: 'sitting',\n","              3: 'standing',\n","              4: 'walking',\n","              5: 'running',\n","              6: 'cycling',\n","              7: 'Nordic_walking',\n","              9: 'watching_TV',\n","              10: 'computer_work',\n","              11: 'car driving',\n","              12: 'ascending_stairs',\n","              13: 'descending_stairs',\n","              16: 'vacuum_cleaning',\n","              17: 'ironing',\n","              18: 'folding_laundry',\n","              19: 'house_cleaning',\n","              20: 'playing_soccer',\n","              24: 'rope_jumping'}\n","\n","    colNames = [\"timestamp\", \"activityID\",\"heartrate\"]\n","\n","    IMUhand = ['handTemperature', \n","          'handAcc16_1', 'handAcc16_2', 'handAcc16_3', \n","          'handAcc6_1', 'handAcc6_2', 'handAcc6_3', \n","          'handGyro1', 'handGyro2', 'handGyro3', \n","          'handMagne1', 'handMagne2', 'handMagne3',\n","          'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4']\n","\n","    IMUchest = ['chestTemperature', \n","          'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3', \n","          'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3', \n","          'chestGyro1', 'chestGyro2', 'chestGyro3', \n","          'chestMagne1', 'chestMagne2', 'chestMagne3',\n","          'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4']\n","\n","    IMUankle = ['ankleTemperature', \n","          'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3', \n","          'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3', \n","          'ankleGyro1', 'ankleGyro2', 'ankleGyro3', \n","          'ankleMagne1', 'ankleMagne2', 'ankleMagne3',\n","          'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4']\n","\n","    columns = colNames + IMUhand + IMUchest + IMUankle\n","\n","    dataCollection = pd.DataFrame()\n","    for file in list_of_files:\n","        procData = pd.read_table(PATH + file, header=None, sep='\\s+')\n","        procData.columns = columns\n","        procData['subject_id'] = int(file[-5])\n","        dataCollection = dataCollection.append(procData, ignore_index=True)\n","\n","    dataCollection.reset_index(drop=True, inplace=True)\n","    dataCollection = dataCleaning(dataCollection)\n","    dataCollection.to_csv('data.cvs', index=False)\n","    print(\"Finish reading data ...\")\n","  return dataCollection\n","\n","def feature_normalize(data):\n","  \"\"\"\n","    Normalize the feature data\n","    Paramater:\n","      data: a list of floats\n","    Return:\n","      a list of floats with normalized data\n","  \"\"\"\n","  mu = np.mean(data, axis=0)\n","  sigma = np.std(data, axis=0)\n","  return (data - mu) / sigma\n","\n","\n","def dataset_normalize(dataset):\n","  \"\"\"\n","    Normalize the whole dataset\n","    Paramater:\n","      dataset: a DataFrame with the data and labels \n","    Return:\n","      a DataFrame with the normalized data and labels \n","  \"\"\"\n","  dataset.dropna(axis=0, how='any', inplace=True)\n","  for col in dataset.columns:\n","    if col != 'timestamp' and col != 'activityID' and col != 'subject_id':\n","      dataset[col] = feature_normalize(dataset[col])\n","  return dataset\n","\n","def windows(data, size):\n","  \"\"\"\n","    Obatin the starting index and ending index according to window size\n","    Paramater:\n","      data: a list of floats\n","      size: int\n","    Return:\n","      Starting index, ending index\n","  \"\"\"\n","  start = 0\n","  while start < data.count():\n","    yield int(start), int(start + size)\n","    start += (size / 2)\n","\n","def dataset_segmentation(data):\n","  \"\"\"\n","    Dataset segmentation according the window size\n","    Paramater:\n","      data: a list of floats\n","    Return:\n","      segments and labels \n","  \"\"\"\n","  print(\"Start segmentation with window size: \", WINDOW_SIZE)\n","  segments = np.empty((0, WINDOW_SIZE, FEATURE_SIZE))\n","  labels = np.empty((0))\n","  size = data['timestamp'].count()\n","  for (start, end) in windows(data['timestamp'], WINDOW_SIZE):\n","      temp = []\n","      for col in data.columns:\n","        if col != 'timestamp' and col != 'activityID' and col != 'subject_id':\n","          array = data[col][start:end].to_numpy().tolist()\n","          temp.append(array)\n","      if len(data[\"timestamp\"][start:end]) == WINDOW_SIZE:\n","        segments = np.vstack([segments, np.dstack(temp)])\n","        labels = np.append(labels, stats.mode(data[\"activityID\"][start:end])[0][0])\n","  labels = np.asarray(pd.get_dummies(labels), dtype = np.int8)\n","  segments = segments.reshape(len(segments), FEATURE_SIZE, WINDOW_SIZE)\n","  print(\"Finish segmentation ...\")\n","  return segments, labels\n","\n","def train_valid_test_split(segments, classes, test_x, test_y, k_fold):\n","  \"\"\"\n","    Split train, valid and test datase\n","    Paramater:\n","      segments: a list of input data\n","      classes: a list of classes data\n","      k: k fold cross validation\n","    Return:\n","      segments and labels \n","  \"\"\"\n","  print(\"Start dataset split... \")\n","  seg_len = len(segments)\n","  idx_val = [0, int(seg_len/5*1), int(seg_len/5*2), int(seg_len/5*3), int(seg_len/5*4), seg_len]\n","  train_range1 = range(0, idx_val[k_fold])\n","  valid_range = range(idx_val[k_fold], idx_val[k_fold+1])\n","  train_range2 = range(idx_val[k_fold+1], seg_len)\n","\n","  train_x = np.concatenate((segments[train_range1], segments[train_range2]), axis=0)\n","  train_y = np.concatenate((classes[train_range1], classes[train_range2]), axis=0)\n","  valid_x = segments[valid_range]\n","  valid_y = classes[valid_range]\n","\n","  # get train data\n","  train_data = []\n","  for i in range(len(train_x)):\n","    train_data.append([train_x[i], train_y[i]])\n","  \n","  # get valid data\n","  valid_data = []\n","  for i in range(len(valid_x)):\n","    valid_data.append([valid_x[i], valid_y[i]])\n","  \n","  # get test data\n","  test_data = []\n","  for i in range(len(test_x)):\n","    test_data.append([test_x[i], test_y[i]])\n","  print(len(train_data))\n","  print(len(valid_data))\n","  print(len(test_data))\n","\n","  # generate DataLoader for each dataset\n","  trainloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n","  validloader = torch.utils.data.DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE)\n","  testloader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE)\n","  \n","  print(\"Finish dataset split... \")\n","  return trainloader, validloader, testloader\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Load and Save Train, Test, Valid Dataset\n","\n","\n","\n"],"metadata":{"id":"ZSWX9EHW97uU"}},{"cell_type":"code","metadata":{"id":"dYOjY12143Iv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639658455357,"user_tz":300,"elapsed":4953997,"user":{"displayName":"Yubo Shao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18198364614828690729"}},"outputId":"054323fe-bf9b-4b9e-c85f-cfbbf6c10f28"},"source":["TRAIN_LOADER_PATH = PATH + '/model/train_loader'\n","VALID_LOAER_PATH = PATH + '/model/valid_loader'\n","TEST_LOADER_PATH = PATH + '/model/test_loader'\n","\n","dataset = dataset_normalize(read_data())\n","segments, classes = dataset_segmentation(dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Start reading data ...\n","Finish reading data ...\n","Start segmentation with window size:  128\n","Finish segmentation ...\n"]}]},{"cell_type":"code","source":["np.random.seed(SEED)\n","segments, classes = shuffle(segments, classes)\n","test_x = segments[range(int(len(segments)*0.8), len(segments))]\n","test_y = classes[range(int(len(classes)*0.8), len(classes))]\n","total_x = segments[range(0, int(len(segments)*0.8))]\n","total_y = classes[range(0, int(len(classes)*0.8))]\n","print(len(test_x))\n","print(len(test_y))\n","print(len(total_x))\n","print(len(total_y))\n","\n","cross_valid_range = 5\n","\n","for k in range(cross_valid_range):\n","  print(\"Start spliting for k = \" + str(k))\n","  trainloader, validloader, testloader = train_valid_test_split(total_x, total_y, test_x, test_y, k)\n","  CROSS_TRAIN_LOADER_PATH = TRAIN_LOADER_PATH + str(k) + '.pkl'\n","  CROSS_VALID_LOADER_PATH = VALID_LOAER_PATH + str(k) + '.pkl'\n","  CROSS_TEST_LOADER_PATH = TEST_LOADER_PATH + str(k) + '.pkl'\n","  torch.save(trainloader, CROSS_TRAIN_LOADER_PATH)\n","  torch.save(validloader, CROSS_VALID_LOADER_PATH)\n","  torch.save(testloader, CROSS_TEST_LOADER_PATH)\n","  print(\"Finish data loading...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hqg4hp82-Q3Y","executionInfo":{"status":"ok","timestamp":1639658773604,"user_tz":300,"elapsed":118401,"user":{"displayName":"Yubo Shao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18198364614828690729"}},"outputId":"488c6b56-87d0-43a3-c7a7-a131c284d532"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6072\n","6072\n","24284\n","24284\n","Start spliting for k = 0\n","Start dataset split... \n","19428\n","4856\n","6072\n","Finish dataset split... \n","Finish data loading...\n","Start spliting for k = 1\n","Start dataset split... \n","19427\n","4857\n","6072\n","Finish dataset split... \n","Finish data loading...\n","Start spliting for k = 2\n","Start dataset split... \n","19427\n","4857\n","6072\n","Finish dataset split... \n","Finish data loading...\n","Start spliting for k = 3\n","Start dataset split... \n","19427\n","4857\n","6072\n","Finish dataset split... \n","Finish data loading...\n","Start spliting for k = 4\n","Start dataset split... \n","19427\n","4857\n","6072\n","Finish dataset split... \n","Finish data loading...\n"]}]},{"cell_type":"markdown","source":["# Load CNN Model and Other Helper Functions"],"metadata":{"id":"1EbXHbJ7-ae4"}},{"cell_type":"code","source":["NODE_SIZE = 128\n","KERNAL_SIZE = 10\n","LEARNING_RATE = 0.0002\n","\n","k = 0\n","\n","TRAIN_LOADER_PATH = PATH + '/model/train_loader'\n","VALID_LOAER_PATH = PATH + '/model/valid_loader'\n","TEST_LOADER_PATH = PATH + '/model/test_loader'\n","CROSS_TRAIN_LOADER_PATH = TRAIN_LOADER_PATH + str(k) + '.pkl'\n","CROSS_VALID_LOADER_PATH = VALID_LOAER_PATH + str(k) + '.pkl'\n","CROSS_TEST_LOADER_PATH = TEST_LOADER_PATH + str(k) + '.pkl'\n","trainloader = torch.load(CROSS_TRAIN_LOADER_PATH)\n","validloader = torch.load(CROSS_VALID_LOADER_PATH)\n","testloader = torch.load(CROSS_TEST_LOADER_PATH)\n","\n","class CNN(nn.Module):\n","  def __init__(self):\n","    super(CNN, self).__init__()\n","\n","    # Convolutional Layers\n","    self.features = nn.Sequential(\n","      nn.Conv1d(FEATURE_SIZE, NODE_SIZE, kernel_size=KERNAL_SIZE, bias=False),\n","      nn.ReLU(),\n","      nn.Conv1d(NODE_SIZE, NODE_SIZE, kernel_size=KERNAL_SIZE, bias=False),\n","      nn.ReLU(),\n","      nn.Conv1d(NODE_SIZE, NODE_SIZE, kernel_size=KERNAL_SIZE, bias=False),\n","      nn.ReLU(),\n","      nn.Conv1d(NODE_SIZE, NODE_SIZE, kernel_size=KERNAL_SIZE, bias=False),\n","      nn.ReLU(),\n","      nn.Conv1d(NODE_SIZE, NODE_SIZE, kernel_size=KERNAL_SIZE, bias=False),\n","      nn.ReLU(),\n","    )\n","  \n","    self.fc1 = nn.Linear(NODE_SIZE*(WINDOW_SIZE-5*(KERNAL_SIZE-1)), 100)\n","    self.fc2 = nn.Linear(100, LABEL_SIZE)\n","    self.max = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = self.features(x)\n","    x = x.view(x.shape[0], -1)\n","    x = F.relu(self.fc1(x))\n","    x = self.fc2(x)\n","    x = self.max(x)\n","    return x\n","\n","def train_save_CNN_model(TYPE, EPOCH_SIZE):\n","  # manually set random seed\n","  torch.backends.cudnn.deterministic = True\n","  torch.manual_seed(SEED)\n","\n","  # set gpu device\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  net = CNN().double().to(device)\n","\n","  # pick the criterion and optimizer\n","  criterion = nn.MultiLabelSoftMarginLoss()\n","  optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n","\n","  print(\"Learning rate %.4f, batch size %d, node size %d, kernal size %d\" % (LEARNING_RATE, BATCH_SIZE, NODE_SIZE, KERNAL_SIZE))\n","\n","  # initialization\n","  train_acc_list = []\n","  val_acc_list = []\n","  test_acc_list = []\n","  accuray = 0\n","\n","  # start to train with epoches\n","  for epoch in range(EPOCH_SIZE):\n","    running_loss = 0.0\n","    train_total = 0\n","    train_correct = 0\n","    valid_total = 0\n","    valid_correct = 0\n","    test_total = 0\n","    test_correct = 0\n","\n","    # for the training dataset\n","    for i, data in enumerate(trainloader, 0):\n","      inputs, labels = data\n","      inputs, labels = inputs.cuda(0), labels.cuda(0)\n","      optimizer.zero_grad()\n","      outputs = net(inputs)\n","      train_total += labels.size(0)\n","      train_correct += (torch.max(outputs, 1)[1] == torch.max(labels, 1)[1]).sum().item()\n","      loss = criterion(outputs, labels)\n","      if TYPE == 'l0_norm':\n","        # add group lasso regularization\n","        lgl = 1e-10\n","        cnt = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            cnt = cnt + param.detach().nonzero().size(0)\n","            #cnt = cnt + len(param.detach()[param.detach() > 1e-2]) + len(param.detach()[param.detach() < -1e-2])\n","        loss = loss + lgl * cnt\n","      elif TYPE == 'l1_norm':\n","        # add group lasso regularization\n","        lgl = 0.000001\n","        regularization = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            regularization = regularization + torch.norm(param, 1)\n","        loss = loss + lgl * regularization\n","      elif TYPE == 'l2_norm':\n","        lgl = 0.000001\n","        regularization = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            regularization = regularization + torch.norm(param)\n","        loss = loss + lgl * regularization\n","      elif TYPE == 'group_lasso':\n","        # add group lasso regularization\n","        lgl = 0.000001\n","        regularization = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            for i in range(param.shape[0]):\n","              regularization = regularization + torch.norm(param[i,:,:])\n","        loss = loss + lgl * regularization\n","      elif TYPE == 'l1_group_lasso':\n","        lgl = 0.000001\n","        alpha = 0.90\n","        group_lasso_regularization = torch.tensor([0]).cuda(0)\n","        lasso_regularization = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            for i in range(param.shape[0]):\n","              group_lasso_regularization = group_lasso_regularization + torch.norm(param[i,:,:])\n","            lasso_regularization = lasso_regularization + torch.norm(param, 1)\n","        loss = loss + (1-alpha) * lgl * group_lasso_regularization + alpha * lgl * lasso_regularization\n","      elif TYPE == 'l0_group_lasso':\n","        l0 = 1e-8\n","        lg = 0.4*1e-4\n","        cnt = torch.tensor([0]).cuda(0)\n","        group_lasso_regularization = torch.tensor([0]).cuda(0)\n","        lasso_regularization = torch.tensor([0]).cuda(0)\n","        for name, param in net.named_parameters():\n","          if \"features\" in name:\n","            for i in range(param.shape[0]):\n","              group_lasso_regularization = group_lasso_regularization + torch.norm(param[i,:,:])\n","            cnt += param.detach().nonzero().size(0)\n","        loss = loss + lg * group_lasso_regularization + l0 * cnt\n","      loss.backward()\n","      optimizer.step()\n","      running_loss += loss.item()\n","\n","    # for the validation dataset\n","    for data in validloader:\n","      inputs, labels = data\n","      inputs, labels = inputs.cuda(0), labels.cuda(0)\n","      outputs = net(inputs)\n","      _, predicted = torch.max(outputs.data, 1)\n","      valid_total += labels.size(0)\n","      valid_correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n","    \n","    # for the test dataset\n","    for data in testloader:\n","      inputs, labels = data\n","      inputs, labels = inputs.cuda(0), labels.cuda(0)\n","      outputs = net(inputs)\n","      _, predicted = torch.max(outputs.data, 1)\n","      test_total += labels.size(0)\n","      test_correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n","    \n","    # obtain the results for training, validation, test dataset\n","    train_acc = 100 * train_correct / train_total\n","    valid_acc = 100 * valid_correct / valid_total\n","    test_acc = 100 * test_correct / test_total\n","    train_acc_list.append(train_acc)\n","    val_acc_list.append(valid_acc)\n","    test_acc_list.append(test_acc)\n","    print(\"epoch %d, loss %.3f, train acc %.2f%%, valid acc %.2f%%, test acc %.2f%%\" % (epoch+1, running_loss, train_acc, valid_acc, test_acc))\n","    \n","    # save the best model\n","    if valid_acc > accuray:\n","      accuray = valid_acc\n","      torch.save(net, PATH + '/model/' + TYPE + str(k) + \".ptl\")\n","      torch.jit.save(torch.jit.script(net), PATH + '/model/' + TYPE + str(k) + \"_git.ptl\")\n","    \n","  return train_acc_list, val_acc_list, test_acc_list"],"metadata":{"id":"JavmnjK--huZ","executionInfo":{"status":"ok","timestamp":1639814565052,"user_tz":300,"elapsed":12686,"user":{"displayName":"Yubo Shao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18198364614828690729"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Results for CNN Model"],"metadata":{"id":"czSNT82R-ulP"}},{"cell_type":"code","source":["TYPE = 'no_penalty'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"],"metadata":{"id":"_3c63xqyBD7n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TYPE = 'l0_norm'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"],"metadata":{"id":"-uPhfeDeispe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TYPE = 'l1_norm'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"],"metadata":{"id":"Zuipx8Leis0-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TYPE = 'l2_norm'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"],"metadata":{"id":"z4divxnQis-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TYPE = 'group_lasso'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"],"metadata":{"id":"iMsQoLw_izl-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TYPE = 'l1_group_lasso'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)"],"metadata":{"id":"ZgFRk0pAi1C-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TYPE = 'l0_group_lasso'\n","EPOCH_SIZE = 150\n","train_acc, valid_acc, test_acc = train_save_CNN_model(TYPE, EPOCH_SIZE)\n","print(train_acc)\n","print(valid_acc)\n","print(test_acc)\n","file_name = 'data'+str(k)+'.txt'\n","with open(file_name, 'w') as f:\n","    for i in train_acc:\n","      f.write(\"%f \" % i)\n","    f.write('\\n')\n","    for i in valid_acc:\n","      f.write(\"%f \" % i)\n","    f.write('\\n')\n","    for i in test_acc:\n","      f.write(\"%f \" % i)\n","    f.write('\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I37ScZ1Y-477","executionInfo":{"status":"ok","timestamp":1639830248176,"user_tz":300,"elapsed":15683148,"user":{"displayName":"Yubo Shao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18198364614828690729"}},"outputId":"ff650dac-92ec-4f04-f4ca-bf636615c04c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate 0.0002, batch size 32, node size 128, kernal size 10\n","epoch 1, loss 431.656, train acc 62.46%, valid acc 78.19%, test acc 78.80%\n","epoch 2, loss 421.160, train acc 82.19%, valid acc 85.03%, test acc 85.95%\n","epoch 3, loss 418.079, train acc 86.76%, valid acc 87.62%, test acc 87.93%\n","epoch 4, loss 416.500, train acc 88.80%, valid acc 87.79%, test acc 88.11%\n","epoch 5, loss 415.645, train acc 89.68%, valid acc 87.01%, test acc 87.30%\n","epoch 6, loss 414.863, train acc 90.65%, valid acc 89.91%, test acc 90.65%\n","epoch 7, loss 414.207, train acc 91.41%, valid acc 89.52%, test acc 90.09%\n","epoch 8, loss 413.810, train acc 91.87%, valid acc 90.40%, test acc 91.45%\n","epoch 9, loss 413.425, train acc 92.19%, valid acc 90.86%, test acc 91.83%\n","epoch 10, loss 413.131, train acc 92.61%, valid acc 90.84%, test acc 91.80%\n","epoch 11, loss 412.816, train acc 92.93%, valid acc 91.25%, test acc 92.09%\n","epoch 12, loss 412.559, train acc 93.29%, valid acc 91.25%, test acc 92.51%\n","epoch 13, loss 412.509, train acc 93.22%, valid acc 90.92%, test acc 91.83%\n","epoch 14, loss 412.196, train acc 93.59%, valid acc 90.40%, test acc 92.41%\n","epoch 15, loss 411.960, train acc 93.81%, valid acc 92.03%, test acc 92.59%\n","epoch 16, loss 411.773, train acc 93.95%, valid acc 91.95%, test acc 93.02%\n","epoch 17, loss 411.588, train acc 94.16%, valid acc 91.99%, test acc 92.57%\n","epoch 18, loss 411.461, train acc 94.17%, valid acc 91.99%, test acc 92.85%\n","epoch 19, loss 411.319, train acc 94.32%, valid acc 92.03%, test acc 92.90%\n","epoch 20, loss 411.291, train acc 94.28%, valid acc 91.80%, test acc 92.41%\n","epoch 21, loss 411.256, train acc 94.28%, valid acc 92.28%, test acc 92.87%\n","epoch 22, loss 411.042, train acc 94.53%, valid acc 91.95%, test acc 92.67%\n","epoch 23, loss 410.950, train acc 94.66%, valid acc 92.69%, test acc 93.51%\n","epoch 24, loss 410.746, train acc 94.91%, valid acc 92.85%, test acc 93.43%\n","epoch 25, loss 410.661, train acc 95.01%, valid acc 92.03%, test acc 93.07%\n","epoch 26, loss 410.652, train acc 94.98%, valid acc 92.42%, test acc 93.17%\n","epoch 27, loss 410.448, train acc 95.34%, valid acc 93.62%, test acc 94.32%\n","epoch 28, loss 410.302, train acc 95.56%, valid acc 93.57%, test acc 94.22%\n","epoch 29, loss 410.241, train acc 95.53%, valid acc 93.82%, test acc 94.19%\n","epoch 30, loss 410.256, train acc 95.61%, valid acc 93.78%, test acc 94.38%\n","epoch 31, loss 410.019, train acc 95.91%, valid acc 93.68%, test acc 94.04%\n","epoch 32, loss 409.928, train acc 95.95%, valid acc 93.53%, test acc 93.92%\n","epoch 33, loss 410.011, train acc 95.93%, valid acc 93.82%, test acc 94.53%\n","epoch 34, loss 409.855, train acc 96.05%, valid acc 94.19%, test acc 94.33%\n","epoch 35, loss 409.881, train acc 95.95%, valid acc 94.05%, test acc 94.43%\n","epoch 36, loss 409.813, train acc 96.07%, valid acc 94.11%, test acc 94.50%\n","epoch 37, loss 409.679, train acc 96.15%, valid acc 94.09%, test acc 94.60%\n","epoch 38, loss 409.704, train acc 96.09%, valid acc 93.82%, test acc 93.97%\n","epoch 39, loss 409.693, train acc 96.09%, valid acc 93.88%, test acc 94.19%\n","epoch 40, loss 409.754, train acc 96.04%, valid acc 94.11%, test acc 94.42%\n","epoch 41, loss 409.953, train acc 95.83%, valid acc 94.05%, test acc 94.35%\n","epoch 42, loss 409.624, train acc 96.12%, valid acc 94.42%, test acc 94.80%\n","epoch 43, loss 409.531, train acc 96.20%, valid acc 94.44%, test acc 94.71%\n","epoch 44, loss 409.513, train acc 96.17%, valid acc 94.32%, test acc 94.43%\n","epoch 45, loss 409.523, train acc 96.19%, valid acc 93.95%, test acc 94.45%\n","epoch 46, loss 409.540, train acc 96.13%, valid acc 94.30%, test acc 94.70%\n","epoch 47, loss 409.481, train acc 96.15%, valid acc 94.13%, test acc 94.63%\n","epoch 48, loss 409.415, train acc 96.22%, valid acc 93.10%, test acc 93.68%\n","epoch 49, loss 409.522, train acc 96.18%, valid acc 94.56%, test acc 94.48%\n","epoch 50, loss 409.406, train acc 96.23%, valid acc 94.28%, test acc 94.29%\n","epoch 51, loss 409.362, train acc 96.24%, valid acc 94.05%, test acc 94.38%\n","epoch 52, loss 409.466, train acc 96.19%, valid acc 94.01%, test acc 94.30%\n","epoch 53, loss 409.368, train acc 96.23%, valid acc 93.90%, test acc 93.86%\n","epoch 54, loss 409.339, train acc 96.29%, valid acc 93.90%, test acc 94.27%\n","epoch 55, loss 409.347, train acc 96.31%, valid acc 94.32%, test acc 94.61%\n","epoch 56, loss 409.249, train acc 96.36%, valid acc 94.40%, test acc 94.65%\n","epoch 57, loss 409.288, train acc 96.27%, valid acc 94.28%, test acc 94.50%\n","epoch 58, loss 409.282, train acc 96.32%, valid acc 94.42%, test acc 94.93%\n","epoch 59, loss 409.415, train acc 96.22%, valid acc 94.46%, test acc 94.73%\n","epoch 60, loss 409.256, train acc 96.37%, valid acc 94.58%, test acc 94.89%\n","epoch 61, loss 409.194, train acc 96.39%, valid acc 94.01%, test acc 94.33%\n","epoch 62, loss 409.256, train acc 96.29%, valid acc 94.40%, test acc 94.68%\n","epoch 63, loss 409.246, train acc 96.35%, valid acc 94.32%, test acc 94.80%\n","epoch 64, loss 409.335, train acc 96.29%, valid acc 94.32%, test acc 94.75%\n","epoch 65, loss 409.155, train acc 96.44%, valid acc 94.32%, test acc 94.60%\n","epoch 66, loss 409.199, train acc 96.41%, valid acc 94.09%, test acc 94.40%\n","epoch 67, loss 409.095, train acc 96.46%, valid acc 94.15%, test acc 94.60%\n","epoch 68, loss 409.184, train acc 96.37%, valid acc 94.03%, test acc 94.05%\n","epoch 69, loss 409.127, train acc 96.43%, valid acc 94.01%, test acc 94.25%\n","epoch 70, loss 409.140, train acc 96.47%, valid acc 94.25%, test acc 94.52%\n","epoch 71, loss 409.090, train acc 96.49%, valid acc 94.44%, test acc 94.65%\n","epoch 72, loss 409.121, train acc 96.42%, valid acc 94.44%, test acc 94.52%\n","epoch 73, loss 409.080, train acc 96.46%, valid acc 94.30%, test acc 94.70%\n","epoch 74, loss 409.108, train acc 96.41%, valid acc 93.95%, test acc 94.24%\n","epoch 75, loss 409.103, train acc 96.41%, valid acc 94.25%, test acc 94.43%\n","epoch 76, loss 409.046, train acc 96.49%, valid acc 94.50%, test acc 94.81%\n","epoch 77, loss 409.023, train acc 96.48%, valid acc 94.07%, test acc 94.09%\n","epoch 78, loss 409.154, train acc 96.39%, valid acc 94.34%, test acc 94.80%\n","epoch 79, loss 409.039, train acc 96.49%, valid acc 94.56%, test acc 94.68%\n","epoch 80, loss 409.046, train acc 96.42%, valid acc 94.23%, test acc 94.71%\n","epoch 81, loss 409.020, train acc 96.45%, valid acc 94.34%, test acc 94.76%\n","epoch 82, loss 408.972, train acc 96.49%, valid acc 94.63%, test acc 94.71%\n","epoch 83, loss 408.982, train acc 96.45%, valid acc 94.34%, test acc 94.55%\n","epoch 84, loss 409.075, train acc 96.40%, valid acc 93.51%, test acc 94.24%\n","epoch 85, loss 409.103, train acc 96.37%, valid acc 94.73%, test acc 94.76%\n","epoch 86, loss 408.957, train acc 96.52%, valid acc 94.58%, test acc 94.85%\n","epoch 87, loss 408.976, train acc 96.45%, valid acc 94.46%, test acc 94.71%\n","epoch 88, loss 408.965, train acc 96.48%, valid acc 94.44%, test acc 94.52%\n","epoch 89, loss 409.013, train acc 96.42%, valid acc 94.38%, test acc 94.58%\n","epoch 90, loss 408.922, train acc 96.51%, valid acc 94.54%, test acc 94.75%\n","epoch 91, loss 408.888, train acc 96.54%, valid acc 94.28%, test acc 94.57%\n","epoch 92, loss 409.009, train acc 96.43%, valid acc 94.28%, test acc 94.85%\n","epoch 93, loss 409.025, train acc 96.40%, valid acc 94.34%, test acc 94.52%\n","epoch 94, loss 408.925, train acc 96.48%, valid acc 94.25%, test acc 94.60%\n","epoch 95, loss 408.935, train acc 96.45%, valid acc 94.50%, test acc 94.81%\n","epoch 96, loss 408.864, train acc 96.52%, valid acc 94.71%, test acc 95.08%\n","epoch 97, loss 408.859, train acc 96.52%, valid acc 94.46%, test acc 94.65%\n","epoch 98, loss 408.900, train acc 96.50%, valid acc 94.46%, test acc 94.81%\n","epoch 99, loss 408.918, train acc 96.49%, valid acc 94.05%, test acc 94.22%\n","epoch 100, loss 408.940, train acc 96.43%, valid acc 94.48%, test acc 94.71%\n","epoch 101, loss 408.848, train acc 96.55%, valid acc 94.73%, test acc 94.86%\n","epoch 102, loss 408.819, train acc 96.57%, valid acc 94.40%, test acc 94.66%\n","epoch 103, loss 408.822, train acc 96.54%, valid acc 94.46%, test acc 94.75%\n","epoch 104, loss 408.805, train acc 96.54%, valid acc 94.30%, test acc 94.30%\n","epoch 105, loss 408.883, train acc 96.47%, valid acc 94.38%, test acc 94.66%\n","epoch 106, loss 408.822, train acc 96.51%, valid acc 93.72%, test acc 94.05%\n","epoch 107, loss 409.000, train acc 96.39%, valid acc 94.30%, test acc 94.66%\n","epoch 108, loss 408.841, train acc 96.48%, valid acc 94.36%, test acc 94.66%\n","epoch 109, loss 408.795, train acc 96.55%, valid acc 94.58%, test acc 94.94%\n","epoch 110, loss 408.780, train acc 96.56%, valid acc 94.25%, test acc 94.83%\n","epoch 111, loss 408.830, train acc 96.49%, valid acc 94.30%, test acc 94.58%\n","epoch 112, loss 408.822, train acc 96.54%, valid acc 94.65%, test acc 94.48%\n","epoch 113, loss 408.741, train acc 96.63%, valid acc 94.60%, test acc 94.85%\n","epoch 114, loss 408.745, train acc 96.56%, valid acc 94.65%, test acc 94.70%\n","epoch 115, loss 408.822, train acc 96.56%, valid acc 94.52%, test acc 94.61%\n","epoch 116, loss 408.837, train acc 96.52%, valid acc 94.56%, test acc 94.78%\n","epoch 117, loss 408.785, train acc 96.56%, valid acc 94.30%, test acc 94.55%\n","epoch 118, loss 408.789, train acc 96.58%, valid acc 94.73%, test acc 94.73%\n","epoch 119, loss 408.738, train acc 96.57%, valid acc 94.73%, test acc 94.76%\n","epoch 120, loss 408.712, train acc 96.61%, valid acc 94.65%, test acc 94.85%\n","epoch 121, loss 408.741, train acc 96.59%, valid acc 94.50%, test acc 94.63%\n","epoch 122, loss 408.700, train acc 96.59%, valid acc 94.71%, test acc 94.65%\n","epoch 123, loss 408.712, train acc 96.57%, valid acc 94.28%, test acc 94.66%\n","epoch 124, loss 408.861, train acc 96.50%, valid acc 94.65%, test acc 94.88%\n","epoch 125, loss 408.718, train acc 96.57%, valid acc 94.21%, test acc 94.68%\n","epoch 126, loss 408.750, train acc 96.52%, valid acc 94.32%, test acc 94.66%\n","epoch 127, loss 408.825, train acc 96.53%, valid acc 94.30%, test acc 94.55%\n","epoch 128, loss 408.731, train acc 96.56%, valid acc 94.71%, test acc 94.98%\n","epoch 129, loss 408.682, train acc 96.61%, valid acc 94.48%, test acc 94.81%\n","epoch 130, loss 408.688, train acc 96.62%, valid acc 94.65%, test acc 94.96%\n","epoch 131, loss 408.672, train acc 96.63%, valid acc 94.11%, test acc 94.81%\n","epoch 132, loss 408.757, train acc 96.52%, valid acc 94.58%, test acc 94.78%\n","epoch 133, loss 408.675, train acc 96.63%, valid acc 94.34%, test acc 94.70%\n","epoch 134, loss 408.676, train acc 96.59%, valid acc 94.75%, test acc 94.93%\n","epoch 135, loss 408.690, train acc 96.61%, valid acc 94.65%, test acc 94.83%\n","epoch 136, loss 408.657, train acc 96.64%, valid acc 94.63%, test acc 94.89%\n","epoch 137, loss 408.682, train acc 96.60%, valid acc 94.32%, test acc 94.58%\n","epoch 138, loss 408.886, train acc 96.56%, valid acc 94.58%, test acc 94.91%\n","epoch 139, loss 408.635, train acc 96.66%, valid acc 94.77%, test acc 94.89%\n","epoch 140, loss 408.608, train acc 96.66%, valid acc 94.52%, test acc 94.70%\n","epoch 141, loss 408.669, train acc 96.60%, valid acc 94.54%, test acc 94.78%\n","epoch 142, loss 408.702, train acc 96.59%, valid acc 94.71%, test acc 94.94%\n","epoch 143, loss 408.596, train acc 96.69%, valid acc 94.09%, test acc 94.07%\n","epoch 144, loss 408.644, train acc 96.61%, valid acc 94.63%, test acc 95.01%\n","epoch 145, loss 408.591, train acc 96.66%, valid acc 94.73%, test acc 94.63%\n","epoch 146, loss 408.645, train acc 96.61%, valid acc 94.65%, test acc 94.45%\n","epoch 147, loss 408.747, train acc 96.61%, valid acc 94.67%, test acc 94.63%\n","epoch 148, loss 408.613, train acc 96.68%, valid acc 94.75%, test acc 94.85%\n","epoch 149, loss 408.593, train acc 96.66%, valid acc 94.65%, test acc 95.09%\n","epoch 150, loss 408.591, train acc 96.66%, valid acc 94.73%, test acc 94.99%\n","[62.46139592340951, 82.18550545604282, 86.7562281243566, 88.8048177887585, 89.68499073502161, 90.65266625488985, 91.40930615606341, 91.8674078649372, 92.1916821082973, 92.61375334568663, 92.93288037883467, 93.28803788346715, 93.21597694049825, 93.591723285979, 93.8130533250978, 93.94688079061149, 94.16306361951823, 94.17335803994236, 94.32262713609224, 94.28144945439571, 94.28144945439571, 94.5336627547869, 94.66234301008853, 94.90940910026765, 95.00720609429689, 94.9763228330245, 95.33662754786906, 95.55795758698785, 95.53222153592753, 95.61457689932057, 95.91311509162034, 95.94914556310479, 95.9337039324686, 96.04694255713403, 95.94914556310479, 96.07267860819435, 96.14988676137533, 96.08812023883056, 96.08812023883056, 96.04179534692197, 95.8307597282273, 96.124150710315, 96.19621165328392, 96.16532839201153, 96.1859172328598, 96.12929792052708, 96.14988676137533, 96.22194770434425, 96.17562281243566, 96.2270949145563, 96.24253654519251, 96.1859172328598, 96.2270949145563, 96.29400864731316, 96.30945027794935, 96.36092238007001, 96.2734198064649, 96.32489190858554, 96.21680049413219, 96.36606959028207, 96.39180564134239, 96.29400864731316, 96.3454807494338, 96.29400864731316, 96.43813053325098, 96.41239448219065, 96.4638665843113, 96.36606959028207, 96.43298332303891, 96.47416100473544, 96.48960263537163, 96.41754169240272, 96.45871937409923, 96.41239448219065, 96.41239448219065, 96.4947498455837, 96.4793082149475, 96.39180564134239, 96.4947498455837, 96.42268890261478, 96.45357216388717, 96.4947498455837, 96.45357216388717, 96.40210006176652, 96.37121680049414, 96.52048589664402, 96.45357216388717, 96.4793082149475, 96.41754169240272, 96.51019147621989, 96.54107473749228, 96.42783611282685, 96.40210006176652, 96.4793082149475, 96.45357216388717, 96.52048589664402, 96.52048589664402, 96.49989705579576, 96.48960263537163, 96.43298332303891, 96.55136915791641, 96.5668107885526, 96.53592752728021, 96.54107473749228, 96.47416100473544, 96.50504426600783, 96.39180564134239, 96.48445542515957, 96.55136915791641, 96.55651636812847, 96.48960263537163, 96.54107473749228, 96.63372452130945, 96.56166357834054, 96.56166357834054, 96.52048589664402, 96.55651636812847, 96.57710520897673, 96.5668107885526, 96.60798847024913, 96.58739962940086, 96.59254683961294, 96.5668107885526, 96.49989705579576, 96.57195799876467, 96.52048589664402, 96.52563310685609, 96.56166357834054, 96.60798847024913, 96.62343010088532, 96.63372452130945, 96.52048589664402, 96.63372452130945, 96.59254683961294, 96.60798847024913, 96.63887173152152, 96.60284126003705, 96.56166357834054, 96.65946057236978, 96.66460778258184, 96.60284126003705, 96.58739962940086, 96.6851966234301, 96.61313568046118, 96.65946057236978, 96.61313568046118, 96.60798847024913, 96.68004941321803, 96.66460778258184, 96.65946057236978]\n","[78.19192751235585, 85.02883031301482, 87.62355848434926, 87.78830313014826, 87.00576606260296, 89.90939044481054, 89.5181219110379, 90.40362438220758, 90.85667215815486, 90.83607907742999, 91.24794069192751, 91.24794069192751, 90.91845140032949, 90.40362438220758, 92.03047775947282, 91.94810543657331, 91.98929159802306, 91.98929159802306, 92.03047775947282, 91.80395387149917, 92.27759472817134, 91.94810543657331, 92.68945634266886, 92.85420098846788, 92.03047775947282, 92.42174629324548, 93.61614497528831, 93.57495881383855, 93.82207578253707, 93.78088962108731, 93.67792421746293, 93.53377265238879, 93.82207578253707, 94.19275123558484, 94.04859967051071, 94.11037891268533, 94.08978583196046, 93.82207578253707, 93.88385502471169, 94.11037891268533, 94.04859967051071, 94.41927512355848, 94.43986820428336, 94.3163097199341, 93.94563426688633, 94.29571663920923, 94.13097199341021, 93.10131795716639, 94.56342668863262, 94.27512355848435, 94.04859967051071, 94.00741350906095, 93.90444810543657, 93.90444810543657, 94.3163097199341, 94.39868204283361, 94.27512355848435, 94.41927512355848, 94.46046128500824, 94.5840197693575, 94.00741350906095, 94.39868204283361, 94.3163097199341, 94.3163097199341, 94.3163097199341, 94.08978583196046, 94.15156507413509, 94.02800658978583, 94.00741350906095, 94.25453047775947, 94.43986820428336, 94.43986820428336, 94.29571663920923, 93.94563426688633, 94.25453047775947, 94.501647446458, 94.06919275123559, 94.33690280065898, 94.56342668863262, 94.2339373970346, 94.33690280065898, 94.62520593080725, 94.33690280065898, 93.51317957166393, 94.72817133443164, 94.5840197693575, 94.46046128500824, 94.43986820428336, 94.37808896210873, 94.54283360790774, 94.27512355848435, 94.27512355848435, 94.33690280065898, 94.25453047775947, 94.501647446458, 94.70757825370676, 94.46046128500824, 94.46046128500824, 94.04859967051071, 94.48105436573312, 94.72817133443164, 94.39868204283361, 94.46046128500824, 94.29571663920923, 94.37808896210873, 93.71911037891269, 94.29571663920923, 94.35749588138385, 94.5840197693575, 94.25453047775947, 94.29571663920923, 94.64579901153212, 94.60461285008238, 94.64579901153212, 94.52224052718287, 94.56342668863262, 94.29571663920923, 94.72817133443164, 94.72817133443164, 94.64579901153212, 94.501647446458, 94.70757825370676, 94.27512355848435, 94.64579901153212, 94.21334431630972, 94.3163097199341, 94.29571663920923, 94.70757825370676, 94.48105436573312, 94.64579901153212, 94.11037891268533, 94.5840197693575, 94.33690280065898, 94.7487644151565, 94.64579901153212, 94.62520593080725, 94.3163097199341, 94.5840197693575, 94.76935749588138, 94.52224052718287, 94.54283360790774, 94.70757825370676, 94.08978583196046, 94.62520593080725, 94.72817133443164, 94.64579901153212, 94.666392092257, 94.7487644151565, 94.64579901153212, 94.72817133443164]\n","[78.80434782608695, 85.95191040843214, 87.92819499341239, 88.10935441370223, 87.30237154150197, 90.6455862977602, 90.08563899868248, 91.45256916996047, 91.83135704874836, 91.79841897233202, 92.09486166007905, 92.50658761528327, 91.83135704874836, 92.40777338603425, 92.58893280632411, 93.0171277997365, 92.57246376811594, 92.85243741765481, 92.90184453227931, 92.40777338603425, 92.86890645586298, 92.67127799736495, 93.51119894598155, 93.42885375494072, 93.066534914361, 93.16534914361002, 94.31818181818181, 94.21936758893281, 94.18642951251647, 94.3840579710145, 94.03820816864295, 93.92292490118577, 94.53227931488802, 94.33465085638998, 94.433465085639, 94.49934123847167, 94.59815546772069, 93.97233201581028, 94.18642951251647, 94.41699604743083, 94.35111989459816, 94.7957839262187, 94.71343873517786, 94.433465085639, 94.44993412384717, 94.6969696969697, 94.63109354413702, 93.67588932806323, 94.4828722002635, 94.28524374176548, 94.3840579710145, 94.30171277997366, 93.8570487483531, 94.26877470355731, 94.61462450592886, 94.64756258234519, 94.49934123847167, 94.92753623188406, 94.72990777338603, 94.89459815546772, 94.33465085638998, 94.68050065876153, 94.7957839262187, 94.7463768115942, 94.59815546772069, 94.40052700922266, 94.59815546772069, 94.05467720685112, 94.25230566534914, 94.51581027667984, 94.64756258234519, 94.51581027667984, 94.6969696969697, 94.23583662714097, 94.433465085639, 94.81225296442688, 94.08761528326745, 94.7957839262187, 94.68050065876153, 94.71343873517786, 94.76284584980237, 94.71343873517786, 94.54874835309617, 94.23583662714097, 94.76284584980237, 94.84519104084322, 94.71343873517786, 94.51581027667984, 94.58168642951252, 94.7463768115942, 94.56521739130434, 94.84519104084322, 94.51581027667984, 94.59815546772069, 94.81225296442688, 95.07575757575758, 94.64756258234519, 94.81225296442688, 94.21936758893281, 94.71343873517786, 94.86166007905139, 94.66403162055336, 94.7463768115942, 94.30171277997366, 94.66403162055336, 94.05467720685112, 94.66403162055336, 94.66403162055336, 94.94400527009223, 94.82872200263505, 94.58168642951252, 94.4828722002635, 94.84519104084322, 94.6969696969697, 94.61462450592886, 94.77931488801055, 94.54874835309617, 94.72990777338603, 94.76284584980237, 94.84519104084322, 94.63109354413702, 94.64756258234519, 94.66403162055336, 94.87812911725955, 94.68050065876153, 94.66403162055336, 94.54874835309617, 94.97694334650856, 94.81225296442688, 94.96047430830039, 94.81225296442688, 94.77931488801055, 94.6969696969697, 94.92753623188406, 94.82872200263505, 94.89459815546772, 94.58168642951252, 94.91106719367589, 94.89459815546772, 94.6969696969697, 94.77931488801055, 94.94400527009223, 94.07114624505928, 95.0098814229249, 94.63109354413702, 94.44993412384717, 94.63109354413702, 94.84519104084322, 95.09222661396575, 94.99341238471673]\n"]}]},{"cell_type":"markdown","source":["# Results after Pruning the above Models"],"metadata":{"id":"HN48kt-K2mpC"}},{"cell_type":"code","source":["PRUNE_THRESHOLD = 0.01\n","\n","class ThresholdPruning(prune.BasePruningMethod):\n","    PRUNING_TYPE = \"unstructured\"\n","\n","    def __init__(self, threshold):\n","        self.threshold = threshold\n","\n","    def compute_mask(self, tensor, default_mask):\n","      return torch.abs(tensor) > self.threshold\n","\n","PATHS = { 'No penalty - 0 128 0.0001':     PATH + '/model/final/lr0.0001/no_penalty0.ptl',\n","      'l0 norm - 0 128 0.0001':       PATH + '/model/final/lr0.0001/l0_norm0.ptl',\n","      'l1 norm - 0 128 0.0001':       PATH + '/model/final/lr0.0001/l1_norm0.ptl',\n","      'l2 norm - 0 128 0.0001':       PATH + '/model/final/lr0.0001/l2_norm0.ptl',\n","      'group lasso - 0 128 0.0001':     PATH + '/model/final/lr0.0001/group_lasso0.ptl',\n","      'l1 group lasso - 0 128 0.0001':   PATH + '/model/final/lr0.0001/l1_group_lasso0.ptl',\n","      'l0 group lasso - 0 128 0.0001 (*)': PATH + '/model/final/lr0.0001/l0_group_lasso0.ptl',\n","      'l0 group lasso - 0 128 0.00005':   PATH + '/model/final/lr0.00005/l0_group_lasso0.ptl',\n","      'l0 group lasso - 0 128 0.00015':   PATH + '/model/final/lr0.00015/l0_group_lasso0.ptl',\n","      'l0 group lasso - 0 128 0.0002':   PATH + '/model/final/lr0.0002/l0_group_lasso0.ptl',\n","      'l0 group lasso - 0 128 0.00001':   PATH + '/model/final/lr0.00001/l0_group_lasso0.ptl',\n","      'l0 group lasso - 0 256 0.0001':   PATH + '/model/final/256node/l0_group_lasso0.ptl',\n","      'l0 group lasso - 0 64 0.0001':   PATH + '/model/final/64node/l0_group_lasso0.ptl',\n","      'l0 group lasso - 1 128 0.0001':   PATH + '/model/final/lr0.0001/l0_group_lasso1.ptl',\n","      'l0 group lasso - 2 128 0.0001':   PATH + '/model/final/lr0.0001/l0_group_lasso2.ptl',\n","      'l0 group lasso - 3 128 0.0001':   PATH + '/model/final/lr0.0001/l0_group_lasso3.ptl',\n","      'l0 group lasso - 4 128 0.0001':   PATH + '/model/final/lr0.0001/l0_group_lasso4.ptl',\n","    }\n","\n","for name in PATHS:\n","  print('Here are the results for {}:'.format(name))\n","  # load the model\n","  net = torch.load(PATHS[name])\n","\n","  # display the results before compressed model\n","  test_correct = 0\n","  test_total = 0\n","  with torch.no_grad():\n","    for data in testloader:\n","      inputs, labels = data\n","      inputs, labels = inputs.cuda(0), labels.cuda(0)\n","      outputs = net(inputs)\n","      _, predicted = torch.max(outputs.data, 1)\n","      test_total += labels.size(0)\n","      test_correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n","    test_acc = 100 * test_correct / test_total\n","  print('Accuracy of the network on the %d test data: %.2f %% before compression' % (test_total, test_acc))\n","\n","  # prune the model\n","  parameters_to_prune = []\n","  for name, child in net.features.named_children():\n","    if int(name) % 2 == 0:\n","      parameters_to_prune.append((child, \"weight\"))\n","  prune.global_unstructured(parameters_to_prune, pruning_method=ThresholdPruning, threshold=PRUNE_THRESHOLD)\n","\n","  # calculate the sparsity\n","  total_weight = 0\n","  total_nonzero = 0\n","  for name, child in net.features.named_children():\n","    if int(name) % 2 == 0:\n","      total_weight += torch.numel(child.weight)\n","      total_nonzero += torch.count_nonzero(child.weight)\n","  print('Sparity for the compressed model: %.2f %%' % (100*float(total_nonzero / total_weight)))\n","\n","  # display the results after compressed model\n","  test_correct = 0\n","  test_total = 0\n","  with torch.no_grad():\n","    for data in testloader:\n","      inputs, labels = data\n","      inputs, labels = inputs.cuda(0), labels.cuda(0)\n","      outputs = net(inputs)\n","      _, predicted = torch.max(outputs.data, 1)\n","      test_total += labels.size(0)\n","      test_correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n","    test_acc = 100 * test_correct / test_total\n","  print('Accuracy of the network on the %d test data: %.2f %% after compression\\n' % (test_total, test_acc))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"64evT_NP2sdg","executionInfo":{"status":"ok","timestamp":1639830863843,"user_tz":300,"elapsed":20374,"user":{"displayName":"Yubo Shao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18198364614828690729"}},"outputId":"f63ac3e6-ce49-4320-83a8-924f1f8c3b45"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Here are the results for No penalty - 0 128 0.0001:\n","Accuracy of the network on the 6072 test data: 93.15 % before compression\n","Sparity for the compressed model: 69.27 %\n","Accuracy of the network on the 6072 test data: 93.07 % after compression\n","\n","Here are the results for l0 norm - 0 128 0.0001:\n","Accuracy of the network on the 6072 test data: 93.15 % before compression\n","Sparity for the compressed model: 69.27 %\n","Accuracy of the network on the 6072 test data: 93.07 % after compression\n","\n","Here are the results for l1 norm - 0 128 0.0001:\n","Accuracy of the network on the 6072 test data: 95.22 % before compression\n","Sparity for the compressed model: 1.46 %\n","Accuracy of the network on the 6072 test data: 95.29 % after compression\n","\n","Here are the results for l2 norm - 0 128 0.0001:\n","Accuracy of the network on the 6072 test data: 92.08 % before compression\n","Sparity for the compressed model: 65.32 %\n","Accuracy of the network on the 6072 test data: 92.09 % after compression\n","\n","Here are the results for group lasso - 0 128 0.0001:\n","Accuracy of the network on the 6072 test data: 93.30 % before compression\n","Sparity for the compressed model: 61.78 %\n","Accuracy of the network on the 6072 test data: 93.28 % after compression\n","\n","Here are the results for l1 group lasso - 0 128 0.0001:\n","Accuracy of the network on the 6072 test data: 96.87 % before compression\n","Sparity for the compressed model: 2.67 %\n","Accuracy of the network on the 6072 test data: 97.20 % after compression\n","\n","Here are the results for l0 group lasso - 0 128 0.0001 (*):\n","Accuracy of the network on the 6072 test data: 96.89 % before compression\n","Sparity for the compressed model: 1.26 %\n","Accuracy of the network on the 6072 test data: 96.95 % after compression\n","\n","Here are the results for l0 group lasso - 0 128 0.00005:\n","Accuracy of the network on the 6072 test data: 94.25 % before compression\n","Sparity for the compressed model: 3.90 %\n","Accuracy of the network on the 6072 test data: 93.89 % after compression\n","\n","Here are the results for l0 group lasso - 0 128 0.00015:\n","Accuracy of the network on the 6072 test data: 96.57 % before compression\n","Sparity for the compressed model: 1.12 %\n","Accuracy of the network on the 6072 test data: 96.62 % after compression\n","\n","Here are the results for l0 group lasso - 0 128 0.0002:\n","Accuracy of the network on the 6072 test data: 94.89 % before compression\n","Sparity for the compressed model: 0.68 %\n","Accuracy of the network on the 6072 test data: 94.99 % after compression\n","\n","Here are the results for l0 group lasso - 0 128 0.00001:\n","Accuracy of the network on the 6072 test data: 93.63 % before compression\n","Sparity for the compressed model: 7.93 %\n","Accuracy of the network on the 6072 test data: 85.80 % after compression\n","\n","Here are the results for l0 group lasso - 1 128 0.0001:\n","Accuracy of the network on the 6072 test data: 92.29 % before compression\n","Sparity for the compressed model: 1.27 %\n","Accuracy of the network on the 6072 test data: 92.28 % after compression\n","\n","Here are the results for l0 group lasso - 2 128 0.0001:\n","Accuracy of the network on the 6072 test data: 96.49 % before compression\n","Sparity for the compressed model: 1.81 %\n","Accuracy of the network on the 6072 test data: 96.28 % after compression\n","\n","Here are the results for l0 group lasso - 3 128 0.0001:\n","Accuracy of the network on the 6072 test data: 95.08 % before compression\n","Sparity for the compressed model: 1.20 %\n","Accuracy of the network on the 6072 test data: 94.99 % after compression\n","\n","Here are the results for l0 group lasso - 4 128 0.0001:\n","Accuracy of the network on the 6072 test data: 94.81 % before compression\n","Sparity for the compressed model: 1.46 %\n","Accuracy of the network on the 6072 test data: 94.81 % after compression\n","\n"]}]}]}